{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953226f9",
   "metadata": {},
   "source": [
    "# First version of AE with clustering loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f30b30",
   "metadata": {},
   "source": [
    "## Import useful modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be2d3346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scanpy in /shared/home/tberthet/.local/lib/python3.12/site-packages (1.10.1)\n",
      "Requirement already satisfied: anndata>=0.8 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.10.7)\n",
      "Requirement already satisfied: h5py>=3.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (3.11.0)\n",
      "Requirement already satisfied: joblib in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (1.4.2)\n",
      "Requirement already satisfied: legacy-api-wrap>=1.4 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (1.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (3.8.4)\n",
      "Requirement already satisfied: natsort in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (8.4.0)\n",
      "Requirement already satisfied: networkx>=2.7 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (3.3)\n",
      "Requirement already satisfied: numba>=0.56 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.59.1)\n",
      "Requirement already satisfied: numpy>=1.23 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from scanpy) (1.26.4)\n",
      "Requirement already satisfied: packaging>=21.3 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from scanpy) (23.2)\n",
      "Requirement already satisfied: pandas>=1.5 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from scanpy) (2.2.0)\n",
      "Requirement already satisfied: patsy in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.5.6)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.5.12)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.8 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (1.13.0)\n",
      "Requirement already satisfied: seaborn>=0.13 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.13.2)\n",
      "Requirement already satisfied: session-info in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (1.0.0)\n",
      "Requirement already satisfied: statsmodels>=0.13 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.14.2)\n",
      "Requirement already satisfied: tqdm in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (4.66.4)\n",
      "Requirement already satisfied: umap-learn!=0.5.0,>=0.5 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.5.6)\n",
      "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from anndata>=0.8->scanpy) (1.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (2.8.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from numba>=0.56->scanpy) (0.42.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas>=1.5->scanpy) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas>=1.5->scanpy) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scikit-learn>=0.24->scanpy) (3.5.0)\n",
      "Requirement already satisfied: six in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from patsy->scanpy) (1.16.0)\n",
      "Requirement already satisfied: stdlib-list in /shared/home/tberthet/.local/lib/python3.12/site-packages (from session-info->scanpy) (0.10.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in /shared/home/tberthet/.local/lib/python3.12/site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /shared/home/tberthet/.local/lib/python3.12/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (69.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: rich in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (1.26.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /shared/home/tberthet/.local/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: igraph in /shared/home/tberthet/.local/lib/python3.12/site-packages (0.11.5)\n",
      "Requirement already satisfied: texttable>=1.6.2 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from igraph) (1.7.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: leidenalg in /shared/home/tberthet/.local/lib/python3.12/site-packages (0.10.2)\n",
      "Requirement already satisfied: igraph<0.12,>=0.10.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from leidenalg) (0.11.5)\n",
      "Requirement already satisfied: texttable>=1.6.2 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from igraph<0.12,>=0.10.0->leidenalg) (1.7.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement csv (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for csv\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement random (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for random\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scanpy\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip3 install igraph\n",
    "!pip3 install leidenalg\n",
    "!pip install os\n",
    "!pip install csv\n",
    "!pip install random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ae1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 20:52:18.333692: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-18 20:52:19.276829: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-18 20:52:19.563556: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-18 20:52:27.729029: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Layer\n",
    "from keras.models import load_model, Model\n",
    "from keras import backend as K\n",
    "from keras.losses import KLDivergence\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, accuracy_score, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import seaborn as sns\n",
    "from layers import ConstantDispersionLayer, SliceLayer, ColWiseMultLayer\n",
    "import keras\n",
    "from keras.layers import Layer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9baf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c088e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8432bf",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eaf695",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4287976f",
   "metadata": {},
   "source": [
    "On importe le dataset baron et on applique le prétraitement habituel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b855d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"./dataset/barondata_rawcounts.csv\"\n",
    "data_baron=pd.read_csv(filename, sep=';', comment=\"#\", index_col=0)\n",
    "data_baron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e162be",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"./dataset/barondata_annotations.csv\"\n",
    "annotations_baron=pd.read_csv(filename, sep=';', comment=\"#\", index_col=0)\n",
    "annotations_baron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ann=sc.AnnData(data_baron.T)\n",
    "data_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8599d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ann.obs['label'] = annotations_baron['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98b9b4",
   "metadata": {},
   "source": [
    "### Filter data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b8b136",
   "metadata": {},
   "source": [
    "On filtre les données de manière peu stricte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a97bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_cells(data_ann, min_genes=1)\n",
    "sc.pp.filter_genes(data_ann, min_cells=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d666545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ann.raw = data_ann.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbcce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d30f5",
   "metadata": {},
   "source": [
    "### Normalize and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219882fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(data_ann)\n",
    "data_ann.obs['size_factors'] = data_ann.obs.n_genes / np.median(data_ann.obs.n_genes)\n",
    "#data_ann.obs['size_factors'] = 1.0\n",
    "sc.pp.log1p(data_ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038d051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(data_ann, n_top_genes=2000, batch_key=\"label\")\n",
    "sc.pl.highly_variable_genes(data_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490890e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.scale(data_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb6129",
   "metadata": {},
   "source": [
    "### Explore the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b31b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ann.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930af5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ann.n_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744468b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ann.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2814ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ann.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca4c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ann.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6701e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ann.raw.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e453889",
   "metadata": {},
   "outputs": [],
   "source": [
    "highly_variable_genes = data_ann.var[data_ann.var['highly_variable']].index.tolist()\n",
    "count_data_hvg = data_ann[:, highly_variable_genes].X\n",
    "count_data_hvg=count_data_hvg.toarray()\n",
    "count_data_hvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3942d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_count_hvg=data_ann.raw[:,highly_variable_genes].X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbb7e32",
   "metadata": {},
   "source": [
    "## Create autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b527479-ce6c-4bf1-b518-4f159ac35a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contrastive_encoder(input_dim, dims, dropout=0.8):\n",
    "    Inputs = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dropout(rate=dropout)(Inputs)  # L'argument input_shape n'est pas nécessaire ici\n",
    "    for i in range(len(dims) - 1):\n",
    "        x = layers.Dense(dims[i], kernel_initializer='glorot_uniform')(x)\n",
    "        x = layers.BatchNormalization(epsilon=1e-5, momentum=0.1)(x)\n",
    "        x = layers.ReLU()(x)\n",
    "    \n",
    "    # Dernière couche sans activation pour obtenir les embeddings\n",
    "    x = layers.Dense(dims[-1],  kernel_initializer='glorot_uniform')(x)\n",
    "    x = layers.Lambda(lambda y: tf.nn.l2_normalize(y, axis=1))(x)\n",
    "    model = Model(Inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6343118-ae3e-45b4-83b2-16212e8b6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SupConLoss(features, labels=None, mask=None, temperature=0.07, base_temperature=0.07, contrast_mode='all'): \n",
    "    if len(features.shape) < 3:\n",
    "        raise ValueError('`features` needs to be [bsz, n_views, ...], at least 3 dimensions are required')\n",
    "    if len(features.shape) > 3:\n",
    "        features = tf.reshape(features, [tf.shape(features)[0], tf.shape(features)[1], -1]) \n",
    "    batch_size = tf.shape(features)[0]\n",
    "    if labels is not None and mask is not None:\n",
    "        raise ValueError('Cannot define both `labels` and `mask`')\n",
    "    elif labels is None and mask is None:\n",
    "        mask = tf.eye(batch_size, dtype=tf.float32)\n",
    "    elif labels is not None:\n",
    "        labels = tf.reshape(labels, (-1, 1))\n",
    "        if labels.shape[0] != batch_size:\n",
    "            raise ValueError('Num of labels does not match num of features')\n",
    "        mask = tf.cast(tf.equal(labels, tf.transpose(labels)), dtype=tf.float32)\n",
    "    else:\n",
    "        mask = tf.eye(batch_size, dtype=tf.float32)\n",
    "    contrast_count = features.shape[1]\n",
    "    contrast_feature = tf.reshape(tf.concat(tf.unstack(features, axis=1), axis=0), [-1, tf.shape(features)[2]])\n",
    "    if contrast_mode == 'one':\n",
    "        anchor_feature = features[:, 0]\n",
    "        anchor_count = 1\n",
    "    elif contrast_mode == \"all\":\n",
    "        anchor_feature = contrast_feature\n",
    "        anchor_count = contrast_count\n",
    "    else:\n",
    "        raise ValueError(f'Unknown mode : {contrast_mode}')\n",
    "        \n",
    "    anchor_dot_contrast = tf.math.divide(tf.linalg.matmul(anchor_feature, contrast_feature, transpose_b=True), temperature)\n",
    "    logits_max = tf.reduce_max(anchor_dot_contrast, axis=1, keepdims=True)\n",
    "    logits = anchor_dot_contrast - logits_max\n",
    "    mask = tf.tile(mask, [anchor_count, contrast_count])\n",
    "    logits_mask = tf.ones_like(mask) - tf.eye(batch_size * anchor_count, dtype=tf.float32)\n",
    "    mask *= logits_mask\n",
    "    exp_logits = tf.exp(logits) * logits_mask\n",
    "    log_prob = logits - tf.math.log(tf.reduce_sum(exp_logits, axis=1, keepdims=True))\n",
    "\n",
    "    mean_log_prob_pos = tf.reduce_sum(mask * log_prob, axis=1) / tf.reduce_sum(mask, axis=1)\n",
    "\n",
    "    loss = -(temperature / base_temperature) * mean_log_prob_pos\n",
    "    loss = tf.reshape(loss, [anchor_count, batch_size])\n",
    "    loss = tf.reduce_mean(loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07efb1ec-6e32-45e2-a341-ad69ca77ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_kmeans(encoder, x_counts, obs,n='auto',  plot=False):\n",
    "    y=obs\n",
    "    ari=[]\n",
    "    nmi=[]\n",
    "    ca=[]\n",
    "    x=[]\n",
    "    if n==\"auto\":\n",
    "        for n in range (1,20):\n",
    "            kmeans=KMeans(n_clusters=n, n_init=30, verbose=0)\n",
    "            y_pred=kmeans.fit_predict(encoder.predict(x_counts, verbose=0))\n",
    "            ari.append(adjusted_rand_score(y, y_pred))\n",
    "            nmi.append(normalized_mutual_info_score(y, y_pred))\n",
    "            ca.append(cluster_acc(y, y_pred))\n",
    "            x.append(n)\n",
    "        somme_metriques = [x + y + z for x, y, z in zip(ari, nmi, ca)]\n",
    "        n=(somme_metriques.index(max(somme_metriques))+1)\n",
    "    \n",
    "    kmeans=KMeans(n_clusters=n, n_init=20)\n",
    "    y_pred=kmeans.fit_predict(encoder.predict(x_counts))\n",
    "    \n",
    "    if plot==True:\n",
    "        predict_data=encoder.predict(x_counts)\n",
    "        adata_latent = sc.AnnData(predict_data)\n",
    "        obs_df = pd.DataFrame({'label': y})\n",
    "        adata_latent.obs=obs_df\n",
    "        adata_latent.obs[\"kmeans\"]=y_pred\n",
    "        sc.pp.neighbors(adata_latent)\n",
    "        sc.tl.umap(adata_latent)\n",
    "        sc.pl.umap(adata_latent, color='label')\n",
    "        plt.plot(x,ari)\n",
    "        plt.plot(x,nmi)\n",
    "        plt.plot(x,ca)\n",
    "        plt.xlabel(\"nombre de clusters\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.legend(labels=[\"ARI\", \"NMI\", \"CA\"])\n",
    "        ari = adjusted_rand_score(y, y_pred)\n",
    "        print(\"Indice de Rand ajusté (ARI) :\", ari)\n",
    "        nmi = normalized_mutual_info_score(y, y_pred)\n",
    "        print(\"Normalized mutual info (NMI) :\", nmi)\n",
    "        ca=cluster_acc(y, y_pred)\n",
    "        print(\"Clustering accuracy (CA) :\", ca)\n",
    "        sc.pl.umap( adata_latent, color=[\"kmeans\"], legend_loc=\"on data\")\n",
    "        plt.plot()\n",
    "    return y_pred, n, kmeans.cluster_centers_\n",
    "\n",
    "def auto_leiden(encoder, x_counts, y, res=\"auto\", plot=False):\n",
    "    predict_data=encoder.predict(x_counts, verbose=0)\n",
    "    adata_latent = sc.AnnData(predict_data)\n",
    "    obs_df = pd.DataFrame({'label': y})\n",
    "    adata_latent.obs=obs_df\n",
    "    sc.pp.neighbors(adata_latent, use_rep='X')\n",
    "    sc.tl.umap(adata_latent)\n",
    "    list_ari=[]\n",
    "    list_nmi=[]\n",
    "    list_ca=[]\n",
    "    x=[]\n",
    "    \n",
    "    if res==\"auto\":\n",
    "        #search for the best resolution\n",
    "        for i in range (1,10):\n",
    "            sc.tl.leiden(adata_latent, key_added=\"leiden\", resolution=i/100)\n",
    "            predict_cluster=adata_latent.obs[\"leiden\"]\n",
    "            list_ari.append(adjusted_rand_score(y, predict_cluster))\n",
    "            list_nmi.append(normalized_mutual_info_score(y, predict_cluster))\n",
    "            list_ca.append(cluster_acc(y, predict_cluster))\n",
    "            x.append(i/100)\n",
    "        for i in range (1,11):\n",
    "            sc.tl.leiden(adata_latent, key_added=\"leiden\", resolution=i/10)\n",
    "            predict_cluster=adata_latent.obs[\"leiden\"]\n",
    "            list_ari.append(adjusted_rand_score(y, predict_cluster))\n",
    "            list_nmi.append(normalized_mutual_info_score(y, predict_cluster))\n",
    "            list_ca.append(cluster_acc(y, predict_cluster))\n",
    "            x.append(i/10)\n",
    "        somme_metriques = [x + y + z for x, y, z in zip(list_ari, list_nmi, list_ca)]\n",
    "        res=x[somme_metriques.index(max(somme_metriques))]\n",
    "        print(\"La résolution est de : \", res)\n",
    "    #compute for the best resolution\n",
    "    sc.tl.leiden(adata_latent, key_added=\"leiden_res_%.4f\" % (res), resolution=res)\n",
    "    predict=adata_latent.obs[\"leiden_res_%.4f\" % (res)]\n",
    "    \n",
    "    \n",
    "    #compute cluster center for initialization\n",
    "    init_pred=np.asarray(predict,dtype=int)\n",
    "    features=pd.DataFrame(adata_latent.X,index=np.arange(0,adata_latent.shape[0]))\n",
    "    Group=pd.Series(init_pred,index=np.arange(0,adata_latent.shape[0]),name=\"Group\")\n",
    "    Mergefeature=pd.concat([features,Group],axis=1)\n",
    "    cluster_centers=np.asarray(Mergefeature.groupby(\"Group\").mean())\n",
    "    n_clusters=len(np.unique(init_pred))\n",
    "    \n",
    "    #set of plot if required\n",
    "    if plot==True:\n",
    "        sc.pl.umap(adata_latent, color='label')\n",
    "        plt.plot(x,list_ari)\n",
    "        plt.plot(x,list_nmi)\n",
    "        plt.plot(x,list_ca)\n",
    "        plt.xlabel(\"nombre de clusters\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.legend(labels=[\"ARI\", \"NMI\", \"CA\"])\n",
    "        plt.plot()\n",
    "        sc.pl.umap( adata_latent, color=[\"leiden_res_%.4f\" % (res)], legend_loc=\"on data\")\n",
    "        ari = adjusted_rand_score(y, predict)\n",
    "        print(\"Indice de Rand ajusté (ARI) :\", ari)\n",
    "        nmi = normalized_mutual_info_score(y, predict)\n",
    "        print(\"Normalized mutual info (NMI) :\", nmi)\n",
    "        ca=cluster_acc(y, predict)\n",
    "        print(\"Clustering accuracy (CA) :\", ca)\n",
    " \n",
    "        #crosstab = pd.crosstab(predict,y)\n",
    "        #sns.heatmap(crosstab, annot=True, cmap='Blues')\n",
    "        #plt.ylabel('Clusters prédits')\n",
    "        #plt.xlabel('Annotations réelles')\n",
    "        #plt.title('Matrice de confusion')\n",
    "        #plt.show()\n",
    "    return res, predict, n_clusters, cluster_centers\n",
    "\n",
    "def cluster_embedding(model, X, y, method=None, res='auto', n='auto', plot=False):\n",
    "    if method=='leiden':\n",
    "        res, predict, n_clusters, cluster_centers=auto_leiden(encoder=model, x_counts=X, y=y, res=res, plot=plot)\n",
    "        return res, predict, n_clusters, cluster_centers\n",
    "    elif method=='kmeans':\n",
    "        y_pred, n_max, cluster_centers=auto_kmeans(encoder=model, x_counts=X, obs=y,n=n,  plot=plot)\n",
    "        return res, y_pred, n_max, cluster_centers\n",
    "    else:\n",
    "        raise ValueError(f'Unknown method : {method}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68133a2-7d95-42c7-94c9-00b61d3e7f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy. Require scikit-learn installed\n",
    "    # Arguments\n",
    "        y: true labels, numpy.array with shape `(n_samples,)`\n",
    "        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
    "    # Return\n",
    "        accuracy, in [0,1]\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "   \n",
    "    y_pred = np.asarray(y_pred)\n",
    "    \n",
    "    # Assurez-vous que les étiquettes sont de type str\n",
    "    y_true= y_true.astype(str)\n",
    "    y_pred = y_pred.astype(str)\n",
    "    \n",
    "    # Trouver les étiquettes uniques\n",
    "    labels = np.unique(np.concatenate((y_true, y_pred)))\n",
    "    n_labels = len(labels)\n",
    "\n",
    "    # Construire la matrice de coût (matrice de confusion)\n",
    "    cost_matrix = np.zeros((n_labels, n_labels), dtype=int)\n",
    "    for i, label_true in enumerate(labels):\n",
    "        for j, label_pred in enumerate(labels):\n",
    "            cost_matrix[i, j] = np.sum((y_true == label_true) & (y_pred == label_pred))\n",
    "\n",
    "    # Résoudre le problème de correspondance bipartite optimal\n",
    "    row_ind, col_ind = linear_assignment(cost_matrix.max() - cost_matrix)\n",
    "\n",
    "    # Calculer la précision\n",
    "    accuracy = np.sum([cost_matrix[i, j] for i, j in zip(row_ind, col_ind)]) / y_true.size\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33279965-f488-455d-abe5-a03c6d37d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_to_csv(history, filename):\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    with open(filename, mode='a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            writer.writerow(history.keys())\n",
    "        writer.writerow(history.values())\n",
    "        \n",
    "def check_existing_filename(filename):\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    counter = 1\n",
    "    while os.path.exists(filename):\n",
    "        filename = f\"{base}_{counter}{ext}\"\n",
    "        counter += 1\n",
    "    return filename\n",
    "\n",
    "def save_plot_umap(model, x, y, y_pred, res, epoch, pdf_pages, train_val=\"train\"):\n",
    "    #Récupération des données et projection dans l'espace latent \n",
    "    predict_data=model.predict(x, verbose=0)\n",
    "    obs_df = pd.DataFrame({'label': y})\n",
    "    \n",
    "    #Préparation des données pour Scanpy\n",
    "    adata_latent = sc.AnnData(X=predict_data)\n",
    "    adata_latent.obs = obs_df\n",
    "    adata_latent.obs['predict'] = y_pred.astype(str)\n",
    "\n",
    "    sc.pp.neighbors(adata_latent, use_rep='X')\n",
    "    sc.tl.umap(adata_latent)\n",
    "    \n",
    "    # Génération du UMAP avec Scanpy\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    sc.pl.umap(adata_latent, color='label', ax=axs[0], show=False)\n",
    "    axs[0].set_title(f'UMAP projection - Labels ({train_val}) (Res: {res}, Iter: {epoch})')\n",
    "    sc.pl.umap(adata_latent, color='predict', ax=axs[1], show=False)\n",
    "    axs[1].set_title(f'UMAP projection - Predictions ({train_val}) (Res: {res}, Iter: {epoch})')\n",
    "\n",
    "    pdf_pages.savefig(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a103a-c691-4b8f-821c-962cb8737292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x_counts, y):\n",
    "    train_idx, temp_idx = train_test_split(np.arange(len(y)), stratify=y, test_size=0.3, random_state=42)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, stratify=y[temp_idx], test_size=0.5, random_state=42)\n",
    "    x_train=x_counts[train_idx]\n",
    "    x_val=x_counts[val_idx]\n",
    "    x_test=x_counts[test_idx]\n",
    "    y_train=y[train_idx]\n",
    "    y_val=y[val_idx]\n",
    "    y_test=y[test_idx]\n",
    "    print(\"Size of train set : \", x_train.shape)\n",
    "    print(\"Size of val set : \", x_val.shape)\n",
    "    print(\"Size of test set : \", x_test.shape)\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beb0121-8e29-4c81-ab78-c11d4ec7d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test = split(count_data_hvg, data_ann.obs['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb7c64-9b41-4c10-a92e-73854ffefea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_hyperparameters(lr_space, dropout_space, batch_size_space, noise_space, temperature_space):\n",
    "    lr=random.choice(lr_space)\n",
    "    dropout=random.choice(dropout_space)\n",
    "    batch_size=random.choice(batch_size_space)\n",
    "    noise=random.choice(noise_space)\n",
    "    temperature=random.choice(temperature_space)\n",
    "    return lr, dropout, batch_size, noise, temperature, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f8149b-54ba-467e-9830-c41dc6fa4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_scheduler(epoch, lr, epochs=500, lr_decay_rate=0.1):\n",
    "    eta_min = lr * (lr_decay_rate ** 3)\n",
    "    new_lr = eta_min + (lr - eta_min) * (1 + math.cos(math.pi * epoch / 500)) / 2\n",
    "    return new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, Y=None, n='auto', res='auto', nb_epochs=30, lr=0.4, \n",
    "                temperature=0.07, dropout=0.9, evaluate_training=False, eval_interval=1, \n",
    "                layers=[256, 64, 32], noise=0, method='leiden', batch_size=200, \n",
    "               X_test=None, Y_test=None, early_stopping=True, plot_loss=False):\n",
    "    dims = [X.shape[1]]+layers\n",
    "    model= create_contrastive_encoder(input_dim=X.shape[1], dims=layers, dropout=dropout)\n",
    "    model.summary()\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    val_losses=[]\n",
    "    losses=[]\n",
    "    idx=np.arange(len(X))\n",
    "    idx_test=np.arange(len(X_test))\n",
    "    \n",
    "    #Création du dictionnaire pour le monitoring\n",
    "    history={\n",
    "        \"dropout\": dropout,\n",
    "        \"noise\": noise, \n",
    "        \"lr\": lr,\n",
    "        'batch_size' : batch_size,\n",
    "        'temperature' : temperature, \n",
    "        \"loss\":[],\n",
    "        \"val_loss\":[]\n",
    "    }\n",
    "\n",
    "    \n",
    "    for epoch in range (nb_epochs):\n",
    "        lr = cosine_scheduler(epoch, lr, epochs=nb_epochs, lr_decay_rate=0.1)\n",
    "        optimizer.learning_rate.assign(lr)\n",
    "        np.random.shuffle(idx)\n",
    "        np.random.shuffle(idx_test)\n",
    "        loss_=0\n",
    "        val_loss_=0\n",
    "        for pre_index in range (len(X)//batch_size+1):\n",
    "            c_idx=np.arange(pre_index*batch_size, min(len(X), (pre_index+1)*batch_size))\n",
    "            if len(c_idx)==0:\n",
    "                continue\n",
    "            c_idx=idx[c_idx]\n",
    "            c_inp=X[c_idx]\n",
    "            if noise is None or noise == 0 :\n",
    "                input1=tf.convert_to_tensor(c_inp, dtype=tf.float32)\n",
    "                input2=tf.convert_to_tensor(c_inp, dtype=tf.float32)\n",
    "            else : \n",
    "                noise_vec = np.random.normal(loc=0, scale=noise, size=c_inp.shape)\n",
    "                input1 = tf.convert_to_tensor(c_inp + noise_vec, dtype=tf.float32)\n",
    "                noise_vec = np.random.normal(loc=0, scale=noise, size=c_inp.shape)\n",
    "                input2 = tf.convert_to_tensor(c_inp + noise_vec, dtype=tf.float32)\n",
    "            \n",
    "            with tf.GradientTape() as tape :\n",
    "                anchors_output=model(input1,  training=True)\n",
    "                neighbors_output=model(input2,  training=True)\n",
    "                features = tf.stack([anchors_output, neighbors_output], axis=1)\n",
    "                total_loss= SupConLoss(features=features, temperature=temperature)\n",
    "                loss_+=total_loss.numpy()\n",
    "            \n",
    "            gradients = tape.gradient(total_loss, model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        \n",
    "        print(f\"{epoch}). Loss : {loss_}\")\n",
    "\n",
    "        #to obtain test value if train test split\n",
    "        if X_test is not None : \n",
    "            for pre_index_test in range (len(X_test)//batch_size+1):\n",
    "                c_idx_test=np.arange(pre_index_test*batch_size, min(len(X_test), (pre_index_test+1)*batch_size))\n",
    "                if len(c_idx_test)==0:\n",
    "                    continue\n",
    "                c_idx_test=idx_test[c_idx_test]\n",
    "                c_inp_test=X_test[c_idx_test]\n",
    "                if noise is None or noise == 0 :\n",
    "                    input1_test=tf.convert_to_tensor(c_inp_test, dtype=tf.float32)\n",
    "                    input2_test=tf.convert_to_tensor(c_inp_test, dtype=tf.float32)\n",
    "                else : \n",
    "                    noise_vec_test = np.random.normal(loc=0, scale=noise, size=c_inp_test.shape)\n",
    "                    input1_test = tf.convert_to_tensor(c_inp_test + noise_vec_test, dtype=tf.float32)\n",
    "                    noise_vec_test = np.random.normal(loc=0, scale=noise, size=c_inp_test.shape)\n",
    "                    input2_test = tf.convert_to_tensor(c_inp_test + noise_vec_test, dtype=tf.float32)\n",
    "            \n",
    "                with tf.GradientTape() as tape :\n",
    "                    anchors_output_test=model(input1_test,  training=True)\n",
    "                    neighbors_output_test=model(input2_test,  training=True)\n",
    "                    features_test = tf.stack([anchors_output_test, neighbors_output_test], axis=1)\n",
    "                    total_val_loss= SupConLoss(features=features_test, temperature=temperature)\n",
    "                    val_loss_+=total_val_loss.numpy()\n",
    "        print(f\"val_loss : {val_loss_}\")\n",
    "        \n",
    "        losses.append(loss_)\n",
    "        val_losses.append(val_loss_)\n",
    "        \n",
    "\n",
    "        if early_stopping and X_test is not None:\n",
    "            indice_max=val_losses.index(min(val_losses))\n",
    "            if abs(indice_max-len(val_losses)-1)>5:\n",
    "                break\n",
    "            \n",
    "    if plot_loss:\n",
    "        x=[i for i in range (len(losses))]\n",
    "        plt.plot(x, losses)\n",
    "        plt.plot(x, val_losses)\n",
    "        plt.legend(labels=['loss', 'val loss'])\n",
    "        plt.plot()\n",
    "    \n",
    "    if evaluate_training and Y is not None :\n",
    "        #result = model.predict(X)\n",
    "        res, result, n_cluster, cluster_centers =cluster_embedding(model, X, Y, method=method, res=res, n=n, plot=False)\n",
    "        ca=np.round(cluster_acc(Y, result), 5)\n",
    "        nmi=np.round(normalized_mutual_info_score(Y, result), 5)\n",
    "        ari=np.round(adjusted_rand_score(Y, result), 5)\n",
    "        print( f\"ARI {ari}, NMI: {nmi}, CA : {ca}, clusters : {n_cluster}\")\n",
    "        history[\"res\"]=res\n",
    "        history[\"clusters\"]=n_cluster\n",
    "        history['NMI final']=nmi\n",
    "        history['ARI final']=ari\n",
    "        history['CA final']=ca\n",
    "    \n",
    "    if evaluate_training and Y_test is not None :\n",
    "        test_embedding=model.predict(X_test, verbose=0)\n",
    "        distances=euclidean_distances(test_embedding, cluster_centers)\n",
    "        test_clusters=np.argmin(distances, axis=1)\n",
    "        val_ca=np.round(cluster_acc(Y_test, test_clusters), 5)\n",
    "        val_nmi=np.round(normalized_mutual_info_score(Y_test, test_clusters), 5)\n",
    "        val_ari=np.round(adjusted_rand_score(Y_test, test_clusters), 5)\n",
    "        print( f\"val_ARI {val_ari}, val_NMI: {val_nmi}, val_CA : {val_ca}\")\n",
    "        history['val_NMI final']=val_nmi\n",
    "        history['val_ARI final']=val_ari\n",
    "        history['val_CA final']=val_ca\n",
    "                \n",
    "    history[\"loss\"]=losses\n",
    "    history[\"val_loss\"]=val_losses\n",
    "    \n",
    "    history['final_loss']=loss_\n",
    "    history['final_val_loss']=val_loss_\n",
    "        \n",
    "    #save dictionnary\n",
    "    save_results_to_csv(history, \"data/contrastive-sc/random_search/contrastive_sc_random_search_2.csv\")\n",
    "\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e23cb-61f6-4f46-a334-5aa64514f00b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13). Loss : 17.120649367570877\n",
      "val_loss : 5.6755316480994225\n",
      "14). Loss : 17.14497748017311\n",
      "val_loss : 5.974091640673578\n",
      "15). Loss : 15.280142799019814\n",
      "val_loss : 5.77702128875535\n",
      "16). Loss : 14.851214721798897\n",
      "val_loss : 5.646068215370178\n",
      "17). Loss : 14.70672331750393\n",
      "val_loss : 5.786845583468676\n",
      "18). Loss : 13.786629781126976\n",
      "val_loss : 5.140639309372318\n",
      "19). Loss : 13.082439005374908\n",
      "val_loss : 5.121720978291705\n",
      "20). Loss : 13.182932063937187\n",
      "val_loss : 5.553546100854874\n",
      "21). Loss : 12.691943660378456\n",
      "val_loss : 5.567655688151717\n",
      "22). Loss : 12.427534207701683\n",
      "val_loss : 5.601148154004477\n",
      "23). Loss : 12.433687254786491\n",
      "val_loss : 5.7195089012384415\n",
      "La résolution est de :  0.09\n",
      "ARI 0.72088, NMI: 0.74959, CA : 0.7139, clusters : 4\n",
      "val_ARI 0.631, val_NMI: 0.60804, val_CA : 0.66693\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_31\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_31\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_30          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_31          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_15 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m512,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_30          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_30 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_31          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_31 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_16 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">532,064</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m532,064\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,424</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m531,424\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 6355.84725189209\n",
      "val_loss : 1329.9649600982666\n",
      "1). Loss : 6071.407236099243\n",
      "val_loss : 1297.7890310287476\n",
      "2). Loss : 5984.029846191406\n",
      "val_loss : 1293.8582401275635\n",
      "3). Loss : 5929.626020431519\n",
      "val_loss : 1273.8979358673096\n",
      "4). Loss : 5889.638328552246\n",
      "val_loss : 1267.4373817443848\n",
      "5). Loss : 5869.586986541748\n",
      "val_loss : 1268.0800590515137\n",
      "6). Loss : 5846.642015457153\n",
      "val_loss : 1264.9873332977295\n",
      "7). Loss : 5841.575332641602\n",
      "val_loss : 1255.1091117858887\n",
      "8). Loss : 5815.020164489746\n",
      "val_loss : 1264.1143293380737\n",
      "9). Loss : 5803.222026824951\n",
      "val_loss : 1253.9511823654175\n",
      "10). Loss : 5813.588333129883\n",
      "val_loss : 1257.0627298355103\n",
      "11). Loss : 5795.918163299561\n",
      "val_loss : 1250.4213018417358\n",
      "12). Loss : 5792.484609603882\n",
      "val_loss : 1247.0557765960693\n",
      "13). Loss : 5795.6067905426025\n",
      "val_loss : 1250.4004249572754\n",
      "14). Loss : 5787.079444885254\n",
      "val_loss : 1250.298978805542\n",
      "15). Loss : 5785.388214111328\n",
      "val_loss : 1247.7082452774048\n",
      "16). Loss : 5783.041084289551\n",
      "val_loss : 1258.5382862091064\n",
      "La résolution est de :  0.01\n",
      "ARI 0.85122, NMI: 0.81407, CA : 0.84912, clusters : 5\n",
      "val_ARI 0.83067, val_NMI: 0.79101, val_CA : 0.84202\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_33\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_33\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_32          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_16 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m512,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_32          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_32 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_33 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_17 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">532,064</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m532,064\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,424</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m531,424\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 625.2942733764648\n",
      "val_loss : 183.35991668701172\n",
      "1). Loss : 606.3112869262695\n",
      "val_loss : 182.92965698242188\n",
      "2). Loss : 604.7776947021484\n",
      "val_loss : 182.5763397216797\n",
      "3). Loss : 601.2488861083984\n",
      "val_loss : 180.6205291748047\n",
      "4). Loss : 595.6664886474609\n",
      "val_loss : 179.6627960205078\n",
      "5). Loss : 592.7132797241211\n",
      "val_loss : 178.12942504882812\n",
      "6). Loss : 590.7220687866211\n",
      "val_loss : 178.20208740234375\n",
      "7). Loss : 590.0520706176758\n",
      "val_loss : 178.01651000976562\n",
      "8). Loss : 589.2676391601562\n",
      "val_loss : 177.61874389648438\n",
      "9). Loss : 588.9482803344727\n",
      "val_loss : 177.65831756591797\n",
      "10). Loss : 588.5195159912109\n",
      "val_loss : 177.5399932861328\n",
      "11). Loss : 588.6207046508789\n",
      "val_loss : 177.60114288330078\n",
      "12). Loss : 588.3018493652344\n",
      "val_loss : 177.34300231933594\n",
      "13). Loss : 587.6727142333984\n",
      "val_loss : 177.33440399169922\n",
      "14). Loss : 587.4494247436523\n",
      "val_loss : 177.21602630615234\n",
      "15). Loss : 587.2899322509766\n",
      "val_loss : 177.07125091552734\n",
      "16). Loss : 586.9260406494141\n",
      "val_loss : 177.0270538330078\n",
      "17). Loss : 586.4386672973633\n",
      "val_loss : 176.96669006347656\n",
      "18). Loss : 586.697639465332\n",
      "val_loss : 176.8130340576172\n",
      "19). Loss : 586.6715393066406\n",
      "val_loss : 176.79705810546875\n",
      "20). Loss : 586.4986877441406\n",
      "val_loss : 176.92922973632812\n",
      "21). Loss : 586.0286102294922\n",
      "val_loss : 176.8567657470703\n",
      "22). Loss : 586.0338287353516\n",
      "val_loss : 176.52295684814453\n",
      "23). Loss : 585.9212417602539\n",
      "val_loss : 176.71483612060547\n",
      "24). Loss : 586.0084228515625\n",
      "val_loss : 176.52609252929688\n",
      "25). Loss : 585.8983840942383\n",
      "val_loss : 176.5948715209961\n",
      "26). Loss : 585.3606109619141\n",
      "val_loss : 176.82477569580078\n",
      "29). Loss : 49.19890868663788\n",
      "val_loss : 10.76496909558773\n",
      "30). Loss : 49.15207755565643\n",
      "val_loss : 10.880988135933876\n",
      "31). Loss : 49.0519805252552\n",
      "val_loss : 10.652113884687424\n",
      "32). Loss : 48.81154268980026\n",
      "val_loss : 10.850089251995087\n",
      "33). Loss : 48.81142783164978\n",
      "val_loss : 10.351530559360981\n",
      "34). Loss : 48.64745309948921\n",
      "val_loss : 10.432264305651188\n",
      "35). Loss : 48.173456490039825\n",
      "val_loss : 10.48090950679034\n",
      "36). Loss : 48.28826701641083\n",
      "val_loss : 10.443473413586617\n",
      "37). Loss : 48.038324892520905\n",
      "val_loss : 10.573390260338783\n",
      "La résolution est de :  0.07\n",
      "ARI 0.90693, NMI: 0.85579, CA : 0.88129, clusters : 6\n",
      "val_ARI 0.8505, val_NMI: 0.80805, val_CA : 0.86148\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_43\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_43\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_42          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_43          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_21 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m512,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_42          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_42 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_43          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_43 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_65 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_22 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">532,064</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m532,064\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,424</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m531,424\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 4205.024690628052\n",
      "val_loss : 860.6725168228149\n",
      "1). Loss : 3886.825860977173\n",
      "val_loss : 820.6593532562256\n",
      "2). Loss : 3795.1356086730957\n",
      "val_loss : 814.0997667312622\n",
      "3). Loss : 3751.8771991729736\n",
      "val_loss : 813.4287004470825\n",
      "4). Loss : 3744.4086894989014\n",
      "val_loss : 802.85431432724\n",
      "5). Loss : 3708.0950622558594\n",
      "val_loss : 797.6269793510437\n",
      "6). Loss : 3694.6132736206055\n",
      "val_loss : 797.8047952651978\n",
      "7). Loss : 3676.3925828933716\n",
      "val_loss : 794.3619718551636\n",
      "8). Loss : 3679.109935760498\n",
      "val_loss : 791.5552968978882\n",
      "9). Loss : 3670.9018878936768\n",
      "val_loss : 791.7158517837524\n",
      "10). Loss : 3653.28067779541\n",
      "val_loss : 786.1202068328857\n",
      "11). Loss : 3647.91411113739\n",
      "val_loss : 784.6579322814941\n",
      "12). Loss : 3632.7123947143555\n",
      "val_loss : 789.9535889625549\n",
      "13). Loss : 3629.4862565994263\n",
      "val_loss : 781.159294128418\n",
      "14). Loss : 3637.089817047119\n",
      "val_loss : 785.1092672348022\n",
      "15). Loss : 3625.3859434127808\n",
      "val_loss : 783.3853669166565\n",
      "16). Loss : 3605.44375705719\n",
      "val_loss : 776.3378233909607\n",
      "17). Loss : 3600.9784383773804\n",
      "val_loss : 781.8166694641113\n",
      "18). Loss : 3585.9728679656982\n",
      "val_loss : 779.0275745391846\n",
      "19). Loss : 3596.210322380066\n",
      "val_loss : 777.5459079742432\n",
      "20). Loss : 3590.0538692474365\n",
      "val_loss : 779.3368439674377\n",
      "La résolution est de :  0.04\n",
      "ARI 0.90761, NMI: 0.86435, CA : 0.8988, clusters : 7\n",
      "val_ARI 0.87481, val_NMI: 0.84385, val_CA : 0.88327\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_45\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_45\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_44          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_45          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_22 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_66 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m512,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_44          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_44 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_67 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_45          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_45 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_68 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_23 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">532,064</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m532,064\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,424</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m531,424\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 432.7084655761719\n",
      "val_loss : 127.02635955810547\n",
      "1). Loss : 419.02000427246094\n",
      "val_loss : 126.16389083862305\n",
      "2). Loss : 417.15956115722656\n",
      "val_loss : 125.14630126953125\n",
      "3). Loss : 411.9918899536133\n",
      "val_loss : 123.64171981811523\n",
      "4). Loss : 407.9770050048828\n",
      "val_loss : 122.9583511352539\n",
      "5). Loss : 406.3186950683594\n",
      "val_loss : 122.03153991699219\n",
      "6). Loss : 405.09156036376953\n",
      "val_loss : 122.30563735961914\n",
      "7). Loss : 404.6875915527344\n",
      "val_loss : 121.83051681518555\n",
      "8). Loss : 403.8561782836914\n",
      "val_loss : 121.79024124145508\n",
      "9). Loss : 403.67608642578125\n",
      "val_loss : 121.33050155639648\n",
      "10). Loss : 403.3200912475586\n",
      "val_loss : 121.4670639038086\n",
      "11). Loss : 402.73160552978516\n",
      "val_loss : 121.50164413452148\n",
      "12). Loss : 402.31844329833984\n",
      "val_loss : 120.89207077026367\n",
      "13). Loss : 402.00936126708984\n",
      "val_loss : 121.38740539550781\n",
      "14). Loss : 401.40061950683594\n",
      "val_loss : 120.52289581298828\n",
      "15). Loss : 401.0635223388672\n",
      "val_loss : 120.77856063842773\n",
      "16). Loss : 400.9656982421875\n",
      "val_loss : 120.63788604736328\n",
      "17). Loss : 400.4252395629883\n",
      "val_loss : 120.80445861816406\n",
      "18). Loss : 400.17417907714844\n",
      "val_loss : 120.36188125610352\n",
      "19). Loss : 399.2690734863281\n",
      "val_loss : 120.30693435668945\n",
      "20). Loss : 399.3079376220703\n",
      "val_loss : 119.88297271728516\n",
      "21). Loss : 398.9087371826172\n",
      "val_loss : 120.05596923828125\n",
      "22). Loss : 398.1917724609375\n",
      "val_loss : 120.23834228515625\n",
      "23). Loss : 398.5124816894531\n",
      "val_loss : 119.35526657104492\n",
      "24). Loss : 398.40213775634766\n",
      "val_loss : 119.72895812988281\n",
      "25). Loss : 398.17315673828125\n",
      "val_loss : 119.68804550170898\n",
      "26). Loss : 397.4999313354492\n",
      "val_loss : 119.70802688598633\n",
      "27). Loss : 397.7700881958008\n",
      "val_loss : 119.42759323120117\n",
      "La résolution est de :  0.02\n",
      "ARI 0.91959, NMI: 0.87199, CA : 0.88296, clusters : 6\n",
      "val_ARI 0.90746, val_NMI: 0.8576, val_CA : 0.88093\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_47\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_47\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_46          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_47          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_23 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_69 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m512,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_46          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_46 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_70 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_47          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_47 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_71 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_24 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">532,064</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m532,064\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,424</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m531,424\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 1538.6226406097412\n",
      "val_loss : 325.11610412597656\n",
      "1). Loss : 1459.7889785766602\n",
      "val_loss : 314.65944242477417\n",
      "2). Loss : 1431.3162536621094\n",
      "val_loss : 309.734787940979\n",
      "3). Loss : 1420.1761226654053\n",
      "val_loss : 305.6290440559387\n",
      "4). Loss : 1412.2917575836182\n",
      "val_loss : 307.8145332336426\n",
      "val_loss : 9.312317609786987\n",
      "40). Loss : 37.549394369125366\n",
      "val_loss : 9.332636594772339\n",
      "41). Loss : 37.38203716278076\n",
      "val_loss : 9.155445337295532\n",
      "42). Loss : 37.410417556762695\n",
      "val_loss : 9.259468793869019\n",
      "43). Loss : 37.188103914260864\n",
      "val_loss : 9.294489860534668\n",
      "44). Loss : 37.03579807281494\n",
      "val_loss : 9.102741956710815\n",
      "45). Loss : 36.76392126083374\n",
      "val_loss : 9.076099157333374\n",
      "46). Loss : 36.72773790359497\n",
      "val_loss : 9.180888652801514\n",
      "47). Loss : 36.56409549713135\n",
      "val_loss : 8.93022608757019\n",
      "48). Loss : 36.5739803314209\n",
      "val_loss : 9.089439153671265\n",
      "49). Loss : 36.434837102890015\n",
      "val_loss : 9.194214582443237\n",
      "50). Loss : 36.35139012336731\n",
      "val_loss : 9.113436460494995\n",
      "51). Loss : 36.29516315460205\n",
      "val_loss : 9.127246141433716\n",
      "La résolution est de :  0.02\n",
      "ARI 0.86566, NMI: 0.85366, CA : 0.78826, clusters : 5\n",
      "val_ARI 0.85331, val_NMI: 0.84074, val_CA : 0.78288\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_59\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_59\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_58          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_59          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_29 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_87 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m512,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_58          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_58 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_88 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_59          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_59 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_89 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_30 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">532,064</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m532,064\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,424</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m531,424\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 686.2830238342285\n",
      "val_loss : 141.24694347381592\n",
      "1). Loss : 632.4523048400879\n",
      "val_loss : 135.17850923538208\n",
      "2). Loss : 603.0831394195557\n",
      "val_loss : 129.01914501190186\n",
      "3). Loss : 586.4278764724731\n",
      "val_loss : 125.61242485046387\n",
      "4). Loss : 578.927677154541\n",
      "val_loss : 125.55359601974487\n",
      "5). Loss : 568.4321031570435\n",
      "val_loss : 122.42246627807617\n",
      "6). Loss : 561.6129388809204\n",
      "val_loss : 121.55987620353699\n",
      "7). Loss : 555.1460723876953\n",
      "val_loss : 118.18225181102753\n",
      "8). Loss : 550.1816339492798\n",
      "val_loss : 118.38769316673279\n",
      "9). Loss : 545.2155380249023\n",
      "val_loss : 118.1803150177002\n",
      "10). Loss : 540.0489730834961\n",
      "val_loss : 116.61391830444336\n",
      "11). Loss : 535.4301309585571\n",
      "val_loss : 113.83977347612381\n",
      "12). Loss : 531.7800855636597\n",
      "val_loss : 116.76909732818604\n",
      "13). Loss : 531.8097877502441\n",
      "val_loss : 117.78520584106445\n",
      "14). Loss : 525.610089302063\n",
      "val_loss : 114.57702732086182\n",
      "15). Loss : 523.7784194946289\n",
      "val_loss : 116.77176809310913\n",
      "La résolution est de :  0.06\n",
      "ARI 0.90623, NMI: 0.85505, CA : 0.87863, clusters : 6\n",
      "val_ARI 0.83915, val_NMI: 0.80341, val_CA : 0.85525\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_61\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_61\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_60          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_61          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_30 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_90 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m512,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_60          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_60 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_91 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_61          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_61 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_92 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_31 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">532,064</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m532,064\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,424</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m531,424\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 6279.10308265686\n",
      "val_loss : 1309.8520021438599\n",
      "1). Loss : 5981.321090698242\n",
      "val_loss : 1280.9282493591309\n",
      "2). Loss : 5886.126167297363\n",
      "val_loss : 1258.0498914718628\n",
      "3). Loss : 5830.309543609619\n",
      "val_loss : 1253.981424331665\n",
      "4). Loss : 5798.7999477386475\n",
      "val_loss : 1246.2342042922974\n",
      "5). Loss : 5779.378307342529\n",
      "val_loss : 1243.3876419067383\n",
      "6). Loss : 5771.461935043335\n",
      "val_loss : 1247.5508880615234\n",
      "7). Loss : 5755.621143341064\n",
      "val_loss : 1244.5563163757324\n",
      "8). Loss : 5759.510133743286\n",
      "val_loss : 1240.1708488464355\n",
      "9). Loss : 5739.112762451172\n",
      "val_loss : 1238.8427667617798\n",
      "10). Loss : 5740.797061920166\n",
      "val_loss : 1240.8601875305176\n",
      "11). Loss : 5725.150331497192\n",
      "val_loss : 1232.7741613388062\n",
      "12). Loss : 5720.195404052734\n",
      "val_loss : 1244.6615562438965\n",
      "13). Loss : 5718.826448440552\n",
      "val_loss : 1241.4097156524658\n",
      "14). Loss : 5717.323143005371\n",
      "val_loss : 1229.9002304077148\n",
      "15). Loss : 5696.561706542969\n",
      "val_loss : 1230.2824001312256\n",
      "16). Loss : 5705.946043014526\n",
      "val_loss : 1228.749659538269\n",
      "17). Loss : 5704.441804885864\n",
      "val_loss : 1231.1568565368652\n",
      "18). Loss : 5690.601240158081\n",
      "val_loss : 1227.6429815292358\n",
      "19). Loss : 5696.6955852508545\n",
      "val_loss : 1229.365234375\n",
      "20). Loss : 5690.723598480225\n",
      "val_loss : 1230.3376426696777\n",
      "21). Loss : 5687.795364379883\n",
      "val_loss : 1227.190426826477\n",
      "22). Loss : 5692.408073425293\n",
      "val_loss : 1232.9849920272827\n",
      "23). Loss : 5688.621208190918\n",
      "val_loss : 1230.502833366394\n",
      "24). Loss : 5660.005187988281\n",
      "val_loss : 1221.1931190490723\n",
      "25). Loss : 5674.344602584839\n",
      "val_loss : 1225.7352800369263\n",
      "26). Loss : 5675.326448440552\n",
      "val_loss : 1224.933325767517\n",
      "27). Loss : 5682.999946594238\n",
      "val_loss : 1224.1641216278076\n",
      "28). Loss : 5673.553298950195\n",
      "val_loss : 1225.0194578170776\n",
      "La résolution est de :  0.01\n",
      "ARI 0.70944, NMI: 0.74541, CA : 0.71157, clusters : 4\n",
      "val_ARI 0.69482, val_NMI: 0.70426, val_CA : 0.70428\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_63\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_63\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_62          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_63          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_31 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_93 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m512,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_62          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_62 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_94 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_63          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_63 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_95 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_32 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">532,064</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m532,064\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,424</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m531,424\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 656.679705619812\n",
      "val_loss : 141.2221965789795\n",
      "1). Loss : 600.994948387146\n",
      "val_loss : 125.47368204593658\n",
      "2). Loss : 577.549069404602\n",
      "val_loss : 123.05786180496216\n",
      "3). Loss : 563.2686042785645\n",
      "val_loss : 123.08029222488403\n",
      "4). Loss : 553.9744644165039\n",
      "val_loss : 119.31127572059631\n",
      "5). Loss : 541.8413591384888\n",
      "val_loss : 117.1607551574707\n",
      "6). Loss : 537.0651540756226\n",
      "val_loss : 114.85660117864609\n",
      "7). Loss : 530.5027942657471\n",
      "val_loss : 116.47752928733826\n",
      "8). Loss : 524.7238922119141\n",
      "val_loss : 116.84601187705994\n",
      "9). Loss : 523.4999523162842\n",
      "val_loss : 113.86054348945618\n",
      "10). Loss : 519.5236310958862\n",
      "val_loss : 111.80449879169464\n",
      "11). Loss : 512.5930519104004\n",
      "val_loss : 111.41497129201889\n",
      "12). Loss : 511.6624822616577\n",
      "val_loss : 111.73022866249084\n",
      "13). Loss : 506.1543769836426\n",
      "val_loss : 111.19528043270111\n",
      "14). Loss : 506.7561149597168\n",
      "val_loss : 115.37827014923096\n",
      "15). Loss : 503.78061962127686\n",
      "val_loss : 109.52564984560013\n",
      "16). Loss : 501.21227169036865\n",
      "val_loss : 110.12647485733032\n",
      "17). Loss : 499.08801651000977\n",
      "val_loss : 110.58799028396606\n",
      "18). Loss : 495.8043909072876\n",
      "val_loss : 108.32049524784088\n",
      "19). Loss : 495.45948696136475\n",
      "val_loss : 110.80389928817749\n",
      "20). Loss : 489.9970073699951\n",
      "val_loss : 109.10675835609436\n",
      "21). Loss : 492.42198181152344\n",
      "val_loss : 106.81719243526459\n",
      "22). Loss : 491.2880620956421\n",
      "val_loss : 105.34483551979065\n",
      "23). Loss : 488.38858795166016\n",
      "val_loss : 108.92130923271179\n",
      "24). Loss : 487.3012819290161\n",
      "val_loss : 108.43190228939056\n",
      "25). Loss : 487.6923952102661\n",
      "val_loss : 111.16378927230835\n",
      "26). Loss : 487.484601020813\n",
      "val_loss : 107.17622947692871\n",
      "La résolution est de :  0.09\n",
      "ARI 0.80368, NMI: 0.81908, CA : 0.84178, clusters : 8\n",
      "val_ARI 0.71457, val_NMI: 0.75441, val_CA : 0.78054\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_65\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_65\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_96 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_64          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_65          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_32 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_96 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m512,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_64          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_64 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_97 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_65          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_65 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_98 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_33 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">532,064</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m532,064\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,424</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m531,424\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 3577.814453125\n",
      "val_loss : 761.7322807312012\n",
      "1). Loss : 3443.8390502929688\n",
      "val_loss : 752.7550029754639\n",
      "2). Loss : 3421.5121002197266\n",
      "val_loss : 754.8136310577393\n",
      "3). Loss : 3409.926544189453\n",
      "val_loss : 748.7923851013184\n",
      "4). Loss : 3407.1565322875977\n",
      "val_loss : 752.6477851867676\n",
      "5). Loss : 3407.643341064453\n",
      "val_loss : 747.9435844421387\n",
      "6). Loss : 3405.918960571289\n",
      "val_loss : 751.1231727600098\n",
      "7). Loss : 3401.294876098633\n",
      "val_loss : 753.4494037628174\n",
      "8). Loss : 3399.5092391967773\n",
      "val_loss : 746.9392108917236\n",
      "9). Loss : 3394.0707092285156\n",
      "val_loss : 746.1513500213623\n",
      "10). Loss : 3394.110794067383\n",
      "val_loss : 744.4034156799316\n",
      "11). Loss : 3390.947525024414\n",
      "val_loss : 744.3400726318359\n",
      "12). Loss : 3387.1792755126953\n",
      "val_loss : 743.5675010681152\n",
      "13). Loss : 3384.7131958007812\n",
      "val_loss : 750.1651840209961\n",
      "14). Loss : 3381.233299255371\n",
      "val_loss : 747.1533088684082\n",
      "15). Loss : 3383.055839538574\n",
      "val_loss : 762.0259323120117\n",
      "16). Loss : 3380.019462585449\n",
      "val_loss : 745.934513092041\n",
      "La résolution est de :  0.01\n",
      "ARI 0.29649, NMI: 0.48077, CA : 0.52568, clusters : 4\n",
      "val_ARI 0.28773, val_NMI: 0.46696, val_CA : 0.50739\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_67\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_67\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_66          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_67          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_33 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m512,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_66          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_66 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_67          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_67 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_101 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_34 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">532,064</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m532,064\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,424</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m531,424\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 1889.9108505249023\n",
      "val_loss : 410.43285942077637\n",
      "1). Loss : 1861.3128509521484\n",
      "val_loss : 412.687313079834\n",
      "2). Loss : 1848.849380493164\n",
      "val_loss : 405.9722213745117\n",
      "3). Loss : 1841.4334335327148\n",
      "val_loss : 411.6027946472168\n",
      "4). Loss : 1835.9502410888672\n",
      "val_loss : 402.6078071594238\n",
      "5). Loss : 1833.3674545288086\n",
      "val_loss : 405.834321975708\n",
      "6). Loss : 1832.61474609375\n",
      "val_loss : 403.5387954711914\n",
      "7). Loss : 1831.9958038330078\n",
      "val_loss : 404.811279296875\n",
      "8). Loss : 1830.6917724609375\n",
      "val_loss : 404.27686882019043\n",
      "La résolution est de :  0.02\n",
      "ARI 0.60618, NMI: 0.69674, CA : 0.61054, clusters : 5\n",
      "val_ARI 0.59592, val_NMI: 0.66912, val_CA : 0.60156\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_69\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_69\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_102 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_68          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_69          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_34 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_34 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_102 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m512,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_68          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_68 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_103 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_69          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_69 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_104 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_35 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">532,064</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m532,064\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,424</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m531,424\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 2885.778497695923\n",
      "val_loss : 608.8997898101807\n",
      "1). Loss : 2733.9154720306396\n",
      "val_loss : 581.6261806488037\n",
      "2). Loss : 2639.2740783691406\n",
      "val_loss : 568.1671333312988\n",
      "3). Loss : 2598.45977973938\n",
      "val_loss : 560.1297292709351\n",
      "4). Loss : 2566.431381225586\n",
      "val_loss : 559.333550453186\n",
      "5). Loss : 2561.643014907837\n",
      "val_loss : 547.4604496955872\n",
      "6). Loss : 2551.9713020324707\n",
      "val_loss : 553.3580532073975\n",
      "7). Loss : 2548.5723838806152\n",
      "val_loss : 548.6881666183472\n",
      "8). Loss : 2533.0450191497803\n",
      "val_loss : 546.0978984832764\n",
      "9). Loss : 2518.330577850342\n",
      "val_loss : 546.8294763565063\n",
      "10). Loss : 2509.4560718536377\n",
      "val_loss : 546.7509183883667\n",
      "11). Loss : 2490.55397605896\n",
      "val_loss : 548.5142335891724\n",
      "12). Loss : 2497.2794036865234\n",
      "val_loss : 540.5748624801636\n",
      "13). Loss : 2498.723300933838\n",
      "val_loss : 539.9237127304077\n",
      "14). Loss : 2489.6599197387695\n",
      "val_loss : 538.5716028213501\n",
      "15). Loss : 2493.829107284546\n",
      "val_loss : 539.8410711288452\n",
      "16). Loss : 2491.929130554199\n",
      "val_loss : 535.4088335037231\n",
      "17). Loss : 2478.461112976074\n",
      "val_loss : 539.7654800415039\n",
      "18). Loss : 2484.869722366333\n",
      "val_loss : 538.1390237808228\n",
      "19). Loss : 2471.6217708587646\n",
      "val_loss : 538.4825992584229\n",
      "20). Loss : 2477.668264389038\n",
      "val_loss : 541.0630798339844\n",
      "La résolution est de :  0.05\n",
      "ARI 0.8786, NMI: 0.83289, CA : 0.85562, clusters : 6\n",
      "val_ARI 0.82984, val_NMI: 0.79524, val_CA : 0.83658\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_71\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_71\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_70          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_71          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_35 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_105 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m512,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_70          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_70 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_106 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_71          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_71 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_107 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_36 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">532,064</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m532,064\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,424</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m531,424\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 1985.062858581543\n",
      "val_loss : 433.14587020874023\n",
      "1). Loss : 1950.321434020996\n",
      "val_loss : 435.0551280975342\n",
      "2). Loss : 1929.3419036865234\n",
      "val_loss : 424.29145431518555\n",
      "3). Loss : 1908.0182495117188\n",
      "val_loss : 423.9562072753906\n",
      "4). Loss : 1900.3156356811523\n",
      "val_loss : 422.81838035583496\n",
      "5). Loss : 1898.1490859985352\n",
      "val_loss : 419.60226821899414\n",
      "6). Loss : 1895.3316268920898\n",
      "val_loss : 418.70822525024414\n",
      "7). Loss : 1895.1084365844727\n",
      "val_loss : 419.0771598815918\n",
      "8). Loss : 1893.4933776855469\n",
      "val_loss : 424.2842502593994\n",
      "9). Loss : 1893.5227279663086\n",
      "val_loss : 416.99343490600586\n",
      "10). Loss : 1890.966079711914\n",
      "val_loss : 419.9924373626709\n",
      "11). Loss : 1890.3002853393555\n",
      "val_loss : 425.01001739501953\n",
      "12). Loss : 1888.8427124023438\n",
      "val_loss : 419.305233001709\n",
      "13). Loss : 1887.0137557983398\n",
      "val_loss : 422.13809967041016\n",
      "La résolution est de :  0.08\n",
      "ARI 0.82696, NMI: 0.75165, CA : 0.82394, clusters : 6\n",
      "val_ARI 0.7471, val_NMI: 0.6954, val_CA : 0.79922\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_73\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_73\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_72          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_73          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_36 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_36 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_108 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m512,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_72          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_72 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_109 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_73          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_73 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_110 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_37 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">532,064</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m532,064\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,424</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m531,424\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 82.54757285118103\n",
      "val_loss : 14.827123492956161\n",
      "1). Loss : 63.99666202068329\n",
      "val_loss : 12.736982211470604\n",
      "2). Loss : 51.95105159282684\n",
      "val_loss : 10.701116502285004\n",
      "3). Loss : 41.620741844177246\n",
      "val_loss : 8.47328908102645\n",
      "4). Loss : 35.148372173309326\n",
      "val_loss : 7.52818099106662\n",
      "5). Loss : 30.272596776485443\n",
      "val_loss : 7.063734412193298\n",
      "6). Loss : 27.022318840026855\n",
      "val_loss : 6.462758779525757\n",
      "7). Loss : 24.233322858810425\n",
      "val_loss : 6.1528272799082515\n",
      "8). Loss : 23.190501809120178\n",
      "val_loss : 5.683576243260177\n",
      "9). Loss : 20.61766368150711\n",
      "val_loss : 5.610681363497861\n",
      "10). Loss : 19.583632946014404\n",
      "val_loss : 5.532586727873422\n",
      "11). Loss : 18.171755760908127\n",
      "val_loss : 5.7399157881736755\n",
      "12). Loss : 17.99454239010811\n",
      "val_loss : 4.950809470261447\n",
      "13). Loss : 16.131360977888107\n",
      "val_loss : 4.550481566366216\n",
      "14). Loss : 15.251209676265717\n",
      "val_loss : 4.693189655430615\n",
      "15). Loss : 14.767751902341843\n",
      "val_loss : 4.654785147735083\n",
      "16). Loss : 14.200105607509613\n",
      "val_loss : 4.420312370572901\n",
      "17). Loss : 13.39307102560997\n",
      "val_loss : 4.614433578099124\n",
      "18). Loss : 13.10262605547905\n",
      "val_loss : 4.139414582934023\n",
      "19). Loss : 12.531501710414886\n",
      "val_loss : 4.395548105239868\n",
      "20). Loss : 11.989791810512543\n",
      "val_loss : 4.4217815228621475\n",
      "21). Loss : 12.133754283189774\n",
      "val_loss : 4.243148607878538\n",
      "22). Loss : 11.884633779525757\n",
      "val_loss : 4.037768449103169\n",
      "23). Loss : 11.019508019089699\n",
      "val_loss : 3.8561799270773918\n",
      "24). Loss : 10.519658669829369\n",
      "val_loss : 3.984974077786319\n",
      "25). Loss : 10.281015664339066\n",
      "val_loss : 3.874893367290497\n",
      "26). Loss : 10.545837476849556\n",
      "val_loss : 4.156905114650726\n",
      "27). Loss : 10.132124572992325\n",
      "val_loss : 4.003280299715698\n"
     ]
    }
   ],
   "source": [
    "for i in range (100):\n",
    "    lr, dropout, batch_size, noise, temperature=sample_hyperparameters(lr_space=[0.004,0.04,0.4,4.0, 0.1,0.2,0.3,0.5,0.6,0.7,0.8],\n",
    "                           dropout_space=[i/10 for i in range (7,10)],\n",
    "                           batch_size_space=[32,64,128,256,512,1024], \n",
    "                            noise_space=[0,0.01,0.05,0.1,0.5,1.0],\n",
    "                            temperature_space=[0.01,0.02,0.05,0.07,0.1,0.2,0.5,0.7,1])\n",
    "    model, results=train_model(x_train, Y=y_train, n='auto', res='auto', nb_epochs=60, lr=lr, \n",
    "                temperature=temperature, dropout=dropout, evaluate_training=True,  eval_interval=1, \n",
    "                layers=[256, 64, 32], noise=noise, method='leiden', batch_size=batch_size, \n",
    "               X_test=x_val, Y_test=y_val, early_stopping=True, plot_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec2af4e-6cd0-4a5d-a89f-a59f29f1da1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_scivar",
   "language": "python",
   "name": "env_scivar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
