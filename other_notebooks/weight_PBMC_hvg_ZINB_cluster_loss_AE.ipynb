{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953226f9",
   "metadata": {},
   "source": [
    "# First version of AE with clustering loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f30b30",
   "metadata": {},
   "source": [
    "## Import useful modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be2d3346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scanpy in /shared/home/tberthet/.local/lib/python3.12/site-packages (1.10.1)\n",
      "Requirement already satisfied: anndata>=0.8 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.10.7)\n",
      "Requirement already satisfied: h5py>=3.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (3.11.0)\n",
      "Requirement already satisfied: joblib in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (1.4.2)\n",
      "Requirement already satisfied: legacy-api-wrap>=1.4 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (1.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (3.8.4)\n",
      "Requirement already satisfied: natsort in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (8.4.0)\n",
      "Requirement already satisfied: networkx>=2.7 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (3.3)\n",
      "Requirement already satisfied: numba>=0.56 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.59.1)\n",
      "Requirement already satisfied: numpy>=1.23 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from scanpy) (1.26.4)\n",
      "Requirement already satisfied: packaging>=21.3 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from scanpy) (23.2)\n",
      "Requirement already satisfied: pandas>=1.5 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from scanpy) (2.2.0)\n",
      "Requirement already satisfied: patsy in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.5.6)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.5.12)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.8 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (1.13.0)\n",
      "Requirement already satisfied: seaborn>=0.13 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.13.2)\n",
      "Requirement already satisfied: session-info in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (1.0.0)\n",
      "Requirement already satisfied: statsmodels>=0.13 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.14.2)\n",
      "Requirement already satisfied: tqdm in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (4.66.4)\n",
      "Requirement already satisfied: umap-learn!=0.5.0,>=0.5 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.5.6)\n",
      "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from anndata>=0.8->scanpy) (1.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (2.8.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from numba>=0.56->scanpy) (0.42.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas>=1.5->scanpy) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas>=1.5->scanpy) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scikit-learn>=0.24->scanpy) (3.5.0)\n",
      "Requirement already satisfied: six in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from patsy->scanpy) (1.16.0)\n",
      "Requirement already satisfied: stdlib-list in /shared/home/tberthet/.local/lib/python3.12/site-packages (from session-info->scanpy) (0.10.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in /shared/home/tberthet/.local/lib/python3.12/site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /shared/home/tberthet/.local/lib/python3.12/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (69.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: rich in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (1.26.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /shared/home/tberthet/.local/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: igraph in /shared/home/tberthet/.local/lib/python3.12/site-packages (0.11.5)\n",
      "Requirement already satisfied: texttable>=1.6.2 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from igraph) (1.7.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: leidenalg in /shared/home/tberthet/.local/lib/python3.12/site-packages (0.10.2)\n",
      "Requirement already satisfied: igraph<0.12,>=0.10.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from leidenalg) (0.11.5)\n",
      "Requirement already satisfied: texttable>=1.6.2 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from igraph<0.12,>=0.10.0->leidenalg) (1.7.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement csv (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for csv\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: h5py in /shared/home/tberthet/.local/lib/python3.12/site-packages (3.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from h5py) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install scanpy\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip3 install igraph\n",
    "!pip3 install leidenalg\n",
    "!pip install os\n",
    "!pip install csv\n",
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "436ae1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 11:37:07.773173: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-06 11:37:08.940331: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-06 11:37:10.067530: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-06 11:37:19.337182: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Layer\n",
    "from keras.models import load_model, Model\n",
    "from keras import backend as K\n",
    "from keras.losses import KLDivergence\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, accuracy_score, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import seaborn as sns\n",
    "from layers import ConstantDispersionLayer, SliceLayer, ColWiseMultLayer\n",
    "import keras\n",
    "from keras.layers import Layer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac9baf76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c088e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8432bf",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eaf695",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4287976f",
   "metadata": {},
   "source": [
    "On importe le dataset baron et on applique le prétraitement habituel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b855d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16643</th>\n",
       "      <th>16644</th>\n",
       "      <th>16645</th>\n",
       "      <th>16646</th>\n",
       "      <th>16647</th>\n",
       "      <th>16648</th>\n",
       "      <th>16649</th>\n",
       "      <th>16650</th>\n",
       "      <th>16651</th>\n",
       "      <th>16652</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4271 rows × 16653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3      4      5      6      7      8      9      \\\n",
       "0       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3       0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0   \n",
       "4       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "4266    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4267    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4268    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0   \n",
       "4269    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4270    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      ...  16643  16644  16645  16646  16647  16648  16649  16650  16651  \\\n",
       "0     ...    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1     ...    0.0   14.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2     ...    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3     ...    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4     ...    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "4266  ...    0.0   10.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0   \n",
       "4267  ...    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4268  ...    1.0   20.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0   \n",
       "4269  ...    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4270  ...    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      16652  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "4266    0.0  \n",
       "4267    0.0  \n",
       "4268    0.0  \n",
       "4269    0.0  \n",
       "4270    0.0  \n",
       "\n",
       "[4271 rows x 16653 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=\"./dataset/10X_PBMC.h5\"\n",
    "with h5py.File(filename, 'r') as f :\n",
    "    data_X=f['X'][:]\n",
    "    data_Y=f['Y'][:]\n",
    "    df_X=pd.DataFrame(data_X)\n",
    "    df_Y=pd.DataFrame(data_Y)\n",
    "    \n",
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "548e15b0-eed4-4834-83e3-198eb480fb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4271 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label\n",
       "0        2\n",
       "1        2\n",
       "2        2\n",
       "3        8\n",
       "4        3\n",
       "...    ...\n",
       "4266     6\n",
       "4267     5\n",
       "4268     7\n",
       "4269     3\n",
       "4270     2\n",
       "\n",
       "[4271 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Y.columns=['label']\n",
    "df_Y[\"label\"]=df_Y['label'].astype(str)\n",
    "df_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba2ed1cc-06f3-4021-ae8b-612f7f80e035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1292\n",
       "2     702\n",
       "3     606\n",
       "4     459\n",
       "5     450\n",
       "6     332\n",
       "7     295\n",
       "8     135\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Y[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e162be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/home/tberthet/.local/lib/python3.12/site-packages/anndata/_core/aligned_df.py:67: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/shared/home/tberthet/.local/lib/python3.12/site-packages/anndata/_core/aligned_df.py:67: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 4271 × 16653"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann=sc.AnnData(df_X)\n",
    "data_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2334f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ann.obs=df_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98b9b4",
   "metadata": {},
   "source": [
    "### Filter data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b8b136",
   "metadata": {},
   "source": [
    "On filtre les données de manière peu stricte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a97bdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/home/tberthet/.local/lib/python3.12/site-packages/anndata/_core/aligned_df.py:67: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "sc.pp.filter_cells(data_ann, min_genes=1)\n",
    "sc.pp.filter_genes(data_ann, min_cells=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d666545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ann.raw = data_ann.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dbcce11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 4271 × 16653\n",
       "    obs: 'label', 'n_genes'\n",
       "    var: 'n_cells'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d30f5",
   "metadata": {},
   "source": [
    "### Normalize and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "219882fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(data_ann)\n",
    "data_ann.obs['size_factors'] = data_ann.obs.n_genes / np.median(data_ann.obs.n_genes)\n",
    "#data_ann.obs['size_factors'] = 1.0\n",
    "sc.pp.log1p(data_ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "038d051f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1280x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc.pp.highly_variable_genes(data_ann, n_top_genes=2000, batch_key=\"label\")\n",
    "sc.pl.highly_variable_genes(data_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "490890e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.scale(data_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb6129",
   "metadata": {},
   "source": [
    "### Explore the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60b31b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       ...,\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., 16.46698363,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "930af5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16653"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann.n_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "744468b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       ...,\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., 16.46698363,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2814ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_cells</th>\n",
       "      <th>highly_variable</th>\n",
       "      <th>means</th>\n",
       "      <th>dispersions</th>\n",
       "      <th>dispersions_norm</th>\n",
       "      <th>highly_variable_nbatches</th>\n",
       "      <th>highly_variable_intersection</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>-0.013101</td>\n",
       "      <td>-0.060134</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.028724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570</td>\n",
       "      <td>False</td>\n",
       "      <td>0.135255</td>\n",
       "      <td>-0.001270</td>\n",
       "      <td>0.209814</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.091207</td>\n",
       "      <td>0.246681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225</td>\n",
       "      <td>False</td>\n",
       "      <td>0.050292</td>\n",
       "      <td>-0.021517</td>\n",
       "      <td>0.112911</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.034340</td>\n",
       "      <td>0.152490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>-0.149268</td>\n",
       "      <td>-0.466780</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.033887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106</td>\n",
       "      <td>False</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>0.030561</td>\n",
       "      <td>0.267766</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>0.106600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16648</th>\n",
       "      <td>322</td>\n",
       "      <td>False</td>\n",
       "      <td>0.070651</td>\n",
       "      <td>0.029831</td>\n",
       "      <td>0.317225</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.050375</td>\n",
       "      <td>0.184955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16649</th>\n",
       "      <td>78</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018880</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.153966</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.011738</td>\n",
       "      <td>0.090542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16650</th>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>-0.250185</td>\n",
       "      <td>-1.141559</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.023021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16651</th>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>-0.137269</td>\n",
       "      <td>-0.271806</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.036117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16652</th>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>0.083313</td>\n",
       "      <td>0.514094</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.068266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16653 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_cells  highly_variable     means  dispersions  dispersions_norm  \\\n",
       "0            9            False  0.002611    -0.013101         -0.060134   \n",
       "1          570            False  0.135255    -0.001270          0.209814   \n",
       "2          225            False  0.050292    -0.021517          0.112911   \n",
       "3           12            False  0.001860    -0.149268         -0.466780   \n",
       "4          106            False  0.024858     0.030561          0.267766   \n",
       "...        ...              ...       ...          ...               ...   \n",
       "16648      322            False  0.070651     0.029831          0.317225   \n",
       "16649       78            False  0.018880     0.000764          0.153966   \n",
       "16650        9            False  0.001481    -0.250185         -1.141559   \n",
       "16651       15            False  0.003912    -0.137269         -0.271806   \n",
       "16652       38             True  0.010352     0.083313          0.514094   \n",
       "\n",
       "       highly_variable_nbatches  highly_variable_intersection      mean  \\\n",
       "0                             0                         False  0.001286   \n",
       "1                             1                         False  0.091207   \n",
       "2                             1                         False  0.034340   \n",
       "3                             0                         False  0.001729   \n",
       "4                             1                         False  0.016371   \n",
       "...                         ...                           ...       ...   \n",
       "16648                         2                         False  0.050375   \n",
       "16649                         2                         False  0.011738   \n",
       "16650                         0                         False  0.001020   \n",
       "16651                         0                         False  0.002027   \n",
       "16652                         3                         False  0.006145   \n",
       "\n",
       "            std  \n",
       "0      0.028724  \n",
       "1      0.246681  \n",
       "2      0.152490  \n",
       "3      0.033887  \n",
       "4      0.106600  \n",
       "...         ...  \n",
       "16648  0.184955  \n",
       "16649  0.090542  \n",
       "16650  0.023021  \n",
       "16651  0.036117  \n",
       "16652  0.068266  \n",
       "\n",
       "[16653 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09ca4c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n_genes</th>\n",
       "      <th>size_factors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>748</td>\n",
       "      <td>0.607636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1052</td>\n",
       "      <td>0.854590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>739</td>\n",
       "      <td>0.600325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>874</td>\n",
       "      <td>0.709992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>951</td>\n",
       "      <td>0.772543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>6</td>\n",
       "      <td>1807</td>\n",
       "      <td>1.467912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>5</td>\n",
       "      <td>1249</td>\n",
       "      <td>1.014622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>7</td>\n",
       "      <td>2223</td>\n",
       "      <td>1.805849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>3</td>\n",
       "      <td>983</td>\n",
       "      <td>0.798538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>2</td>\n",
       "      <td>1211</td>\n",
       "      <td>0.983753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4271 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  n_genes  size_factors\n",
       "0        2      748      0.607636\n",
       "1        2     1052      0.854590\n",
       "2        2      739      0.600325\n",
       "3        8      874      0.709992\n",
       "4        3      951      0.772543\n",
       "...    ...      ...           ...\n",
       "4266     6     1807      1.467912\n",
       "4267     5     1249      1.014622\n",
       "4268     7     2223      1.805849\n",
       "4269     3      983      0.798538\n",
       "4270     2     1211      0.983753\n",
       "\n",
       "[4271 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6701e828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann.raw.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e453889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.18050484,  2.43124879, -0.14809046, ...,  1.56127602,\n",
       "         0.09961133, -0.09001358],\n",
       "       [-0.18050484, -0.53800062, -0.14809046, ...,  1.69599056,\n",
       "         1.66225718, -0.09001358],\n",
       "       [-0.18050484, -0.53800062, -0.14809046, ...,  1.78981483,\n",
       "         1.59504406, -0.09001358],\n",
       "       ...,\n",
       "       [-0.18050484,  1.1276868 , -0.14809046, ...,  0.37132976,\n",
       "         0.64876498, -0.09001358],\n",
       "       [-0.18050484,  1.59388979, -0.14809046, ..., -0.255126  ,\n",
       "        -0.7171908 , -0.09001358],\n",
       "       [-0.18050484, -0.53800062, -0.14809046, ..., -0.74846542,\n",
       "         0.85199629, -0.09001358]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highly_variable_genes = data_ann.var[data_ann.var['highly_variable']].index.tolist()\n",
    "count_data_hvg = data_ann[:, highly_variable_genes].X\n",
    "count_data_hvg=count_data_hvg.toarray()\n",
    "count_data_hvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3942d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_count_hvg=data_ann.raw[:,highly_variable_genes].X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbb7e32",
   "metadata": {},
   "source": [
    "## Create autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ada9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_binomial_loss(y_true, y_pred):\n",
    "    input_shape=int(y_pred.shape[1]/3)\n",
    "    mu = y_pred[:, :input_shape]\n",
    "    pi = y_pred[:, input_shape:input_shape*2]\n",
    "    theta = y_pred[:, input_shape*2:]\n",
    "    y_true = tf.cast(y_true, dtype='float32')\n",
    "    #print(type(mu), mu)\n",
    "    #print(type(pi),pi)\n",
    "    #print(type(theta), theta)\n",
    "    #print(type(y_true), y_true)\n",
    "\n",
    "\n",
    "    eps = 1e-10\n",
    "    t1 = tf.math.lgamma(theta+eps) + tf.math.lgamma(y_true+1.0) - tf.math.lgamma(y_true+theta+eps)\n",
    "    t2 = (theta+y_true) * tf.math.log(1.0 + (mu/(theta+eps))) + (y_true * (tf.math.log(theta+eps) - tf.math.log(mu+eps)))\n",
    "    final=t1 + t2\n",
    "    final = tf.reduce_mean(final)\n",
    "    return final\n",
    "\n",
    "def zero_inflated_negative_binomial_loss(y_true, y_pred):\n",
    "    input_shape=int(y_pred.shape[1]/3)\n",
    "    mu = y_pred[:, :input_shape]\n",
    "    pi = y_pred[:, input_shape:input_shape*2]\n",
    "    theta = y_pred[:, input_shape*2:]\n",
    "    y_true = tf.cast(y_true, dtype='float32')\n",
    "    #print(type(mu), mu)\n",
    "    #print(type(pi),pi)\n",
    "    #print(type(theta), theta)\n",
    "    #print(type(y_true), y_true)\n",
    "\n",
    "\n",
    "    eps = 1e-10\n",
    "    t1 = tf.math.lgamma(theta+eps) + tf.math.lgamma(y_true+1.0) - tf.math.lgamma(y_true+theta+eps)\n",
    "    t2 = (theta+y_true) * tf.math.log(1.0 + (mu/(theta+eps))) + (y_true * (tf.math.log(theta+eps) - tf.math.log(mu+eps)))\n",
    "    final=t1 + t2\n",
    "\n",
    "    nb_case = t1 + t2 - tf.math.log(1.0-pi+eps)\n",
    "    zero_nb = tf.pow(theta/(theta+mu+eps), theta)\n",
    "    zero_case = -tf.math.log(pi + ((1.0-pi)*zero_nb)+eps)\n",
    "    result = tf.where(tf.less(y_true, 1e-8), zero_case, nb_case)\n",
    "    #ridge = self.ridge_lambda*tf.square(self.pi)\n",
    "    #result += ridge\n",
    "    result = tf.reduce_mean(result)\n",
    "    return result\n",
    "\n",
    "MeanAct = lambda x: tf.clip_by_value(tf.keras.backend.exp(x), 1e-5, 1e6)\n",
    "DispAct = lambda x: tf.clip_by_value(tf.keras.backend.softplus(x), 1e-4, 1e4)\n",
    "\n",
    "ColWiseMultLayer = lambda name: layers.Lambda(lambda l: l[0]*(tf.matmul(tf.reshape(l[1], (-1,1)),\n",
    "                                                                 tf.ones((1, l[0].get_shape()[1]),\n",
    "                                                                         dtype=l[1].dtype))), name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4008cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringLayer(Layer):\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters=n_clusters\n",
    "        self.alpha=alpha\n",
    "        self.intial_weights=weights\n",
    "        #self.input_spec=keras.InputSpec(ndim=2) #to specify the expected rank of the input\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim=input_shape[1]\n",
    "        #self.input_spec=keras.InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight(shape=(self.n_clusters, input_dim), initializer='glorot_uniform')\n",
    "        if self.intial_weights is not None :\n",
    "            self.set_weights(self.intial_weights)\n",
    "            del self.intial_weights\n",
    "        self.built=True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        q = 1.0 / (1.0 + (tf.math.reduce_sum(tf.math.square(tf.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = tf.transpose(tf.transpose(q) / tf.math.reduce_sum(q, axis=1))\n",
    "        return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "599b945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder(input_shape, noise):\n",
    "    init='glorot_uniform'\n",
    "    Inputs = layers.Input(shape=(input_shape,), name='Inputs')\n",
    "    sf_layer=layers.Input(shape=(1,), name=\"size_factors\")\n",
    "    x=layers.GaussianNoise(noise)(Inputs)\n",
    "    x=layers.Dense(256, activation='relu',kernel_initializer=init, name='encoder_1' )(x)\n",
    "    x=layers.GaussianNoise(noise)(x)\n",
    "    x=layers.Dense(64, activation='relu',kernel_initializer=init, name='encoder_2' )(x)\n",
    "    x=layers.GaussianNoise(noise)(x)\n",
    "    hidden=layers.Dense(32, activation='relu',kernel_initializer=init, name='encoder_3' )(x)\n",
    "\n",
    "\n",
    "    x=layers.Dense(32, activation='relu',kernel_initializer=init, name='decoder_1' )(hidden)\n",
    "    x=layers.Dense(64, activation='relu',kernel_initializer=init, name='decoder_2' )(x)\n",
    "    x=layers.Dense(256, activation='relu',kernel_initializer=init, name='decoder_3' )(x)\n",
    "    pi=layers.Dense(input_shape, activation=\"sigmoid\",kernel_initializer=init, name='pi')(x)\n",
    "    disp=layers.Dense(input_shape, activation=DispAct,kernel_initializer=init, name='dispersion')(x)\n",
    "    mean=layers.Dense(input_shape, activation=MeanAct,kernel_initializer=init, name='mean')(x)\n",
    "\n",
    "    Outputs=ColWiseMultLayer(name='outputs')([mean, sf_layer])\n",
    "    #Outputs=SliceLayer(0, name='slice')([Outputs, disp, pi])\n",
    "    outputs = layers.Concatenate(axis=1, name='output')([Outputs, pi, disp])\n",
    "\n",
    "    autoencoder=Model([Inputs, sf_layer], outputs, name='autoencoder_ZINB')\n",
    "    autoencoder.compile(optimizer='adam', loss={'output': zero_inflated_negative_binomial_loss})\n",
    "\n",
    "    autoencoder.summary()\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6e8f865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16653"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=data_ann.n_vars\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d774f3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16653"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann.X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93003b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 4271 × 16653\n",
       "    obs: 'label', 'n_genes', 'size_factors'\n",
       "    var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'\n",
       "    uns: 'log1p', 'hvg'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_ann.X)\n",
    "data_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4723f50",
   "metadata": {},
   "source": [
    "On entraîne le modèle sur l'ensemble des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea15ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_latent_space(y_pred, model, count_data_hvg , size_factors, obs):\n",
    "    encoder= Model(inputs=model.input, outputs=model.get_layer(\"encoder_3\").output)\n",
    "    encoder.summary()\n",
    "    predict_data=encoder.predict([count_data_hvg, size_factors])\n",
    "    adata_latent = sc.AnnData(predict_data)\n",
    "    adata_latent.obs=obs\n",
    "    adata_latent.obs['predict']=y_pred\n",
    "    anno=adata_latent.obs['label']\n",
    "    sc.pp.neighbors(adata_latent)\n",
    "    sc.tl.umap(adata_latent)\n",
    "    sc.pl.umap(adata_latent, color=\"label\")\n",
    "    sc.pl.umap(adata_latent, color=\"predict\")\n",
    "    crosstab = pd.crosstab(y_pred,anno)\n",
    "    sns.heatmap(crosstab, annot=True, cmap='Blues')\n",
    "    plt.ylabel('Clusters prédits')\n",
    "    plt.xlabel('Annotations réelles')\n",
    "    plt.title('Matrice de confusion')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d68133a2-7d95-42c7-94c9-00b61d3e7f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy. Require scikit-learn installed\n",
    "    # Arguments\n",
    "        y: true labels, numpy.array with shape `(n_samples,)`\n",
    "        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
    "    # Return\n",
    "        accuracy, in [0,1]\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "   \n",
    "    y_pred = np.asarray(y_pred)\n",
    "    \n",
    "    # Assurez-vous que les étiquettes sont de type str\n",
    "    y_true= y_true.astype(str)\n",
    "    y_pred = y_pred.astype(str)\n",
    "    \n",
    "    # Trouver les étiquettes uniques\n",
    "    labels = np.unique(np.concatenate((y_true, y_pred)))\n",
    "    n_labels = len(labels)\n",
    "\n",
    "    # Construire la matrice de coût (matrice de confusion)\n",
    "    cost_matrix = np.zeros((n_labels, n_labels), dtype=int)\n",
    "    for i, label_true in enumerate(labels):\n",
    "        for j, label_pred in enumerate(labels):\n",
    "            cost_matrix[i, j] = np.sum((y_true == label_true) & (y_pred == label_pred))\n",
    "\n",
    "    # Résoudre le problème de correspondance bipartite optimal\n",
    "    row_ind, col_ind = linear_assignment(cost_matrix.max() - cost_matrix)\n",
    "\n",
    "    # Calculer la précision\n",
    "    accuracy = np.sum([cost_matrix[i, j] for i, j in zip(row_ind, col_ind)]) / y_true.size\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a6b16d8-3dac-4d81-be66-9b7d5b60ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_to_csv(history, filename):\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    with open(filename, mode='a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            writer.writerow(history.keys())\n",
    "        writer.writerow(history.values())\n",
    "        \n",
    "def check_existing_filename(filename):\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    counter = 1\n",
    "    while os.path.exists(filename):\n",
    "        filename = f\"{base}_{counter}{ext}\"\n",
    "        counter += 1\n",
    "    return filename\n",
    "\n",
    "def save_plot_umap(model, x, size_factors, y, y_pred, res, iteration, pdf_pages, train_test=\"train\"):\n",
    "    #Récupération des données et projection dans l'espace latent \n",
    "    encoder= Model(inputs=model.input, outputs=model.get_layer(\"encoder_3\").output)\n",
    "    predict_data=encoder.predict([x, size_factors], verbose=0)\n",
    "    obs_df = pd.DataFrame({'label': y})\n",
    "    \n",
    "    #Préparation des données pour Scanpy\n",
    "    adata_latent = sc.AnnData(X=predict_data)\n",
    "    adata_latent.obs = obs_df\n",
    "    adata_latent.obs['predict'] = y_pred.astype(str)\n",
    "\n",
    "    sc.pp.neighbors(adata_latent)\n",
    "    sc.tl.umap(adata_latent)\n",
    "    \n",
    "    # Génération du UMAP avec Scanpy\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    sc.pl.umap(adata_latent, color='label', ax=axs[0], show=False)\n",
    "    axs[0].set_title(f'UMAP projection - Labels ({train_test}) (Res: {res}, Iter: {iteration})')\n",
    "    sc.pl.umap(adata_latent, color='predict', ax=axs[1], show=False)\n",
    "    axs[1].set_title(f'UMAP projection - Predictions ({train_test}) (Res: {res}, Iter: {iteration})')\n",
    "    \n",
    "\n",
    "    pdf_pages.savefig(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c816ceaf",
   "metadata": {},
   "source": [
    "### Essayons de trouver une bonne valeur de gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "827305a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_distribution(q):\n",
    "    weight = q**2/q.sum(0)\n",
    "    return (weight.T/weight.sum(1)).T\n",
    "\n",
    "def auto_kmeans(encoder, x_counts, size_factors, obs, plot=False):\n",
    "    y=obs[\"label\"]\n",
    "    ari=[]\n",
    "    nmi=[]\n",
    "    x=[]\n",
    "    for n in range (1,20):\n",
    "        kmeans=KMeans(n_clusters=n, n_init=30, verbose=0)\n",
    "        y_pred=kmeans.fit_predict(encoder.predict([x_counts, size_factors]))\n",
    "        ari.append(adjusted_rand_score(y, y_pred))\n",
    "        nmi.append(normalized_mutual_info_score(y, y_pred))\n",
    "        x.append(n)\n",
    "    somme_metriques = [x + y for x, y in zip(ari, nmi)]\n",
    "    n_max=(somme_metriques.index(max(somme_metriques))+1)\n",
    "    \n",
    "    kmeans=KMeans(n_clusters=n_max, n_init=20)\n",
    "    y_pred=kmeans.fit_predict(encoder.predict([x_counts, size_factors]))\n",
    "    \n",
    "    if plot==True:\n",
    "        predict_data=encoder.predict([x_counts, size_factors])\n",
    "        adata_latent = sc.AnnData(predict_data)\n",
    "        adata_latent.obs=obs\n",
    "        adata_latent.obs[\"kmeans\"]=y_pred\n",
    "        sc.pp.neighbors(adata_latent)\n",
    "        sc.tl.umap(adata_latent)\n",
    "        sc.pl.umap(adata_latent, color='label')\n",
    "        plt.plot(x,ari)\n",
    "        plt.xlabel(\"nombre de clusters\")\n",
    "        plt.ylabel(\"ARI\")\n",
    "        plt.plot(x,nmi)\n",
    "        plt.xlabel(\"nombre de clusters\")\n",
    "        plt.ylabel(\"NMI\")\n",
    "        ari = adjusted_rand_score(y, y_pred)\n",
    "        print(\"Indice de Rand ajusté (ARI) :\", ari)\n",
    "        nmi = normalized_mutual_info_score(y, y_pred)\n",
    "        print(\"Normalized mutual info (NMI) :\", nmi)\n",
    "        sc.pl.umap( adata_latent, color=[\"kmeans\"], legend_loc=\"on data\")\n",
    "        plt.plot()\n",
    "    return y_pred, n_max, kmeans.cluster_centers_\n",
    "\n",
    "def auto_leiden(encoder, x_counts, size_factors, y, res=\"auto\", plot=False):\n",
    "    predict_data=encoder.predict([x_counts, size_factors], verbose=0)\n",
    "    adata_latent = sc.AnnData(predict_data)\n",
    "    obs_df = pd.DataFrame({'label': y})\n",
    "    adata_latent.obs=obs_df\n",
    "    sc.pp.neighbors(adata_latent, use_rep='X')\n",
    "    sc.tl.umap(adata_latent)\n",
    "    list_ari=[]\n",
    "    list_nmi=[]\n",
    "    list_ca=[]\n",
    "    x=[]\n",
    "    \n",
    "    if res==\"auto\":\n",
    "        #search for the best resolution\n",
    "        for i in range (1,10):\n",
    "            sc.tl.leiden(adata_latent, key_added=\"leiden\", resolution=i/100)\n",
    "            predict_cluster=adata_latent.obs[\"leiden\"]\n",
    "            list_ari.append(adjusted_rand_score(y, predict_cluster))\n",
    "            list_nmi.append(normalized_mutual_info_score(y, predict_cluster))\n",
    "            list_ca.append(cluster_acc(y, predict_cluster))\n",
    "            x.append(i/100)\n",
    "        for i in range (1,11):\n",
    "            sc.tl.leiden(adata_latent, key_added=\"leiden\", resolution=i/10)\n",
    "            predict_cluster=adata_latent.obs[\"leiden\"]\n",
    "            list_ari.append(adjusted_rand_score(y, predict_cluster))\n",
    "            list_nmi.append(normalized_mutual_info_score(y, predict_cluster))\n",
    "            list_ca.append(cluster_acc(y, predict_cluster))\n",
    "            x.append(i/10)\n",
    "        somme_metriques = [x + y + z for x, y, z in zip(list_ari, list_nmi, list_ca)]\n",
    "        res=x[somme_metriques.index(max(somme_metriques))]\n",
    "        print(\"La résolution est de : \", res)\n",
    "    #compute for the best resolution\n",
    "    sc.tl.leiden(adata_latent, key_added=\"leiden_res_%.4f\" % (res), resolution=res)\n",
    "    predict=adata_latent.obs[\"leiden_res_%.4f\" % (res)]\n",
    "    \n",
    "    \n",
    "    #compute cluster center for initialization\n",
    "    init_pred=np.asarray(predict,dtype=int)\n",
    "    features=pd.DataFrame(adata_latent.X,index=np.arange(0,adata_latent.shape[0]))\n",
    "    Group=pd.Series(init_pred,index=np.arange(0,adata_latent.shape[0]),name=\"Group\")\n",
    "    Mergefeature=pd.concat([features,Group],axis=1)\n",
    "    cluster_centers=np.asarray(Mergefeature.groupby(\"Group\").mean())\n",
    "    n_clusters=len(np.unique(init_pred))\n",
    "    \n",
    "    #set of plot if required\n",
    "    if plot==True:\n",
    "        sc.pl.umap(adata_latent, color='label')\n",
    "        plt.plot(x,list_ari)\n",
    "        plt.plot(x,list_nmi)\n",
    "        plt.plot(x,list_ca)\n",
    "        plt.xlabel(\"nombre de clusters\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.legend(labels=[\"ARI\", \"NMI\", \"CA\"])\n",
    "        sc.pl.umap( adata_latent, color=[\"leiden_res_%.4f\" % (res)], legend_loc=\"on data\")\n",
    "        ari = adjusted_rand_score(y, predict)\n",
    "        print(\"Indice de Rand ajusté (ARI) :\", ari)\n",
    "        nmi = normalized_mutual_info_score(y, predict)\n",
    "        print(\"Normalized mutual info (NMI) :\", nmi)\n",
    "        ca=cluster_acc(y, predict_cluster)\n",
    "        print(\"Clustering accuracy (CA) :\", ca)\n",
    "        plt.plot()\n",
    "        #crosstab = pd.crosstab(predict,y)\n",
    "        #sns.heatmap(crosstab, annot=True, cmap='Blues')\n",
    "        #plt.ylabel('Clusters prédits')\n",
    "        #plt.xlabel('Annotations réelles')\n",
    "        #plt.title('Matrice de confusion')\n",
    "        #plt.show()\n",
    "    return res, predict, n_clusters, cluster_centers\n",
    "    \n",
    "def split(x_counts, raw_counts, size_factors, y):\n",
    "    train_idx, test_idx = train_test_split(np.arange(len(y)), stratify=y, test_size=0.2, random_state=42)\n",
    "    x_train=x_counts[train_idx]\n",
    "    x_test=x_counts[test_idx]\n",
    "    size_factors_train=size_factors[train_idx]\n",
    "    size_factors_test=size_factors[test_idx]\n",
    "    raw_train=raw_counts[train_idx]\n",
    "    raw_test=raw_counts[test_idx]\n",
    "    y_train=y[train_idx]\n",
    "    y_test=y[test_idx]\n",
    "    print(\"Size of train set : \", x_train.shape)\n",
    "    print(\"Size of test set : \", x_test.shape)\n",
    "    return x_train, x_test, size_factors_train, size_factors_test, raw_train, raw_test, y_train, y_test\n",
    "    \n",
    "def fit_and_split(x_counts, obs, size_factors, raw_counts, alpha, n_cluster=\"auto\", res=\"auto\", method=\"leiden\", noise=0.5, batch_size=256,\n",
    "        max_iter=2e4, tol=1e-3, update_interval=140, loss_weights=[1,1],\n",
    "        ae_weights=None, pretrained=False):\n",
    "    print('Update interval', update_interval)\n",
    "    t0 = time.time()\n",
    "    y=obs[\"label\"]\n",
    "    #step 0 split data\n",
    "    x_train, x_test, size_factors_train, size_factors_test, raw_train, raw_test, y_train, y_test=split(x_counts, raw_counts, size_factors, y)\n",
    "    input_shape=x_train.shape[1]\n",
    "    #Step 1 Pretrain \n",
    "    if pretrained==False or ae_weights is None :\n",
    "        print(\"..pretraining autoencoder : \")\n",
    "        autoencoder=create_autoencoder(input_shape, noise)\n",
    "        callback= tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, mode='min', verbose=1)\n",
    "        autoencoder.fit(x=[x_train, size_factors_train], y=raw_train, validation_data=([x_test,size_factors_test], raw_test), batch_size=batch_size, epochs=200, callbacks=[callback])\n",
    "        autoencoder.save_weights(\"./model/weights/pbmc_weight_ae.weights.h5\")\n",
    "        ae_weights=\"./model/weights/pbmc_weight_ae.weights.h5\"\n",
    "    elif ae_weights is not None:\n",
    "            autoencoder=create_autoencoder(input_shape, noise)\n",
    "            autoencoder.load_weights(ae_weights)\n",
    "            print('ae_weights is loaded successfully.')\n",
    "    \n",
    "    ae_layers = [l for l in autoencoder.layers]\n",
    "    hidden = autoencoder.input[0]\n",
    "    for i in range(1, len(ae_layers)):\n",
    "        if \"noise\" in ae_layers[i].name:\n",
    "            next\n",
    "        elif \"dropout\" in ae_layers[i].name:\n",
    "            next\n",
    "        else:\n",
    "            hidden = ae_layers[i](hidden)\n",
    "        if \"encoder_3\" in ae_layers[i].name:  # only get encoder layers\n",
    "             break\n",
    "    encoder = Model(inputs=autoencoder.input, outputs=hidden, name='encoder')\n",
    "    encoder.summary()\n",
    "\n",
    "    \n",
    "    #step 2 intialize clusters:\n",
    "    \n",
    "    #récupérons l'autoencoder\n",
    "    #encoder= Model(inputs=autoencoder.input, outputs=autoencoder.get_layer(\"hidden\").output)\n",
    "    if method==\"leiden\":\n",
    "        print(\"Initializing cluster centers with leiden : \")\n",
    "        res, y_pred, n_cluster, cluster_centers = auto_leiden(encoder, x_train, size_factors_train, y_train, res=res, plot=False)\n",
    "        print('Le nombre de clusters est : ', n_cluster)\n",
    "    elif method==\"kmeans\":\n",
    "        print(\"Initializing cluster centers with k-means : \")\n",
    "        if n_cluster==\"auto\":\n",
    "            y_pred, n_cluster, cluster_centers=auto_kmeans(encoder, x_train, size_factors_train, obs, plot=False)\n",
    "            print('Le nombre de clusters est : ', n_cluster)\n",
    "        else :\n",
    "            kmeans=KMeans(n_clusters=n_cluster, n_init=20)\n",
    "            y_pred=kmeans.fit_predict(encoder.predict([x_train, size_factors]))\n",
    "            cluster_centers=kmeans.cluster_centers_\n",
    "        \n",
    "    y_pred_last_train=np.copy(y_pred)\n",
    "    \n",
    "    clustering_layer = ClusteringLayer(n_cluster, alpha=alpha, name='clustering')(hidden)\n",
    "    model= Model(inputs=[autoencoder.input[0], autoencoder.input[1]],\n",
    "                           outputs=[clustering_layer, autoencoder.output])\n",
    "    model.summary()\n",
    "    model.compile(loss={'clustering': KLDivergence, 'output': zero_inflated_negative_binomial_loss}, optimizer='adam',loss_weights={'clustering': loss_weights[0], 'output': loss_weights[1]}, metrics={'clustering': KLDivergence, 'output': zero_inflated_negative_binomial_loss})\n",
    "    print(\"Set clustering weights\")\n",
    "    model.get_layer(name='clustering').set_weights([cluster_centers])\n",
    "    print(\"Done\")\n",
    "    \n",
    "    #step 3 deep clustering\n",
    "    print(\"..Starting Deep Clustering\")\n",
    "    loss=[0,0,0]\n",
    "    val_loss=[0,0,0]\n",
    "    index=0\n",
    "    save_interval = int(x_counts.shape[0] / batch_size) * 5 \n",
    "    \n",
    "    #Création du dictionnaire pour le monitoring\n",
    "    history={\n",
    "        \"res\":res,\n",
    "        \"clusters\": n_cluster,\n",
    "        \"weight\": loss_weights[0],\n",
    "        \"NMI\" :[],\n",
    "        \"ARI\" :[],\n",
    "        \"CA\" :[],\n",
    "        \"val_NMI\":[],\n",
    "        \"val_ARI\":[],\n",
    "        \"val_CA\":[],\n",
    "        \"loss\":[],\n",
    "        \"val_loss\":[],\n",
    "        \"clustering_loss\":[],\n",
    "        \"val_clustering_loss\":[],\n",
    "        \"zinb_loss\":[],\n",
    "        \"val_zinb_loss\":[]\n",
    "    }\n",
    "        \n",
    "    #initiate pdf files\n",
    "    pdf_filename_train = 'data/weight_test/plots/pbmc/pbmc_plots_train_weight_%.4f.pdf' % loss_weights[0]\n",
    "    #pdf_filename_train = check_existing_filename(pdf_filename_train)\n",
    "    pdf_pages_train = PdfPages(pdf_filename_train)\n",
    "    \n",
    "    pdf_filename_test = 'data/weight_test/plots/pbmc/pbmc_plots_test_weight_%.4f.pdf' % loss_weights[0]\n",
    "    #pdf_filename_test = check_existing_filename(pdf_filename_test)\n",
    "    pdf_pages_test = PdfPages(pdf_filename_test)\n",
    "    \n",
    "    for iteration in range(int(max_iter)):\n",
    "       \n",
    "        #if iteration % update_interval==0:\n",
    "        \n",
    "        if index==0:\n",
    "            q_train,_= model.predict([x_train, size_factors_train], verbose=0)\n",
    "            p_train=target_distribution(q_train)\n",
    "            q_test,_= model.predict([x_test, size_factors_test], verbose=0)\n",
    "            p_test=target_distribution(q_test)\n",
    "            \n",
    "            loss=model.evaluate(x=[x_train, size_factors_train], y=[p_train, raw_train], batch_size=batch_size, verbose=0)\n",
    "            val_loss=model.evaluate(x=[x_test, size_factors_test], y=[p_test, raw_test], batch_size=batch_size, verbose=0)\n",
    "            \n",
    "            y_pred_train=q_train.argmax(1)\n",
    "            y_pred_test=q_test.argmax(1)\n",
    "            if y is not None :\n",
    "                ca=np.round(cluster_acc(y_train, y_pred_train), 5)\n",
    "                nmi=np.round(normalized_mutual_info_score(y_train, y_pred_train), 5)\n",
    "                ari=np.round(adjusted_rand_score(y_train, y_pred_train), 5)\n",
    "                val_ca=np.round(cluster_acc(y_test, y_pred_test), 5)\n",
    "                val_nmi=np.round(normalized_mutual_info_score(y_test, y_pred_test), 5)\n",
    "                val_ari=np.round(adjusted_rand_score(y_test, y_pred_test), 5)\n",
    "                print('Iter-%d: CA=%.4f, NMI= %.4f, ARI= %.4f; L= %.5f, Lc= %.5f,  Lr= %.5f'\n",
    "                          % (iteration, ca, nmi, ari, loss[0], loss[1], loss[2]))\n",
    "                print('CA=%.4f, val_NMI= %.4f, val_ARI= %.4f; val_L= %.5f, val_Lc= %.5f,  val_Lr= %.5f'\n",
    "                          % (val_ca, val_nmi, val_ari, val_loss[0], val_loss[1], val_loss[2]))\n",
    "          \n",
    "                #maj du dictionnaire \n",
    "                history[\"CA\"].append(ca)\n",
    "                history[\"NMI\"].append(nmi)\n",
    "                history[\"ARI\"].append(ari)\n",
    "                history[\"val_CA\"].append(val_ca)\n",
    "                history[\"val_NMI\"].append(val_nmi)\n",
    "                history[\"val_ARI\"].append(val_ari)\n",
    "                history[\"loss\"].append(loss[0])\n",
    "                history[\"clustering_loss\"].append(loss[1])\n",
    "                history[\"zinb_loss\"].append(loss[2])\n",
    "                history[\"val_loss\"].append(val_loss[0])\n",
    "                history[\"val_clustering_loss\"].append(val_loss[1])\n",
    "                history[\"val_zinb_loss\"].append(val_loss[2])\n",
    "                \n",
    "                if iteration==0:\n",
    "                    history['CA_initial']=ca\n",
    "                    history['ARI_initial']=ari\n",
    "                    history['NMI_initial']=nmi\n",
    "                    history['val_CA_initial']=val_ca\n",
    "                    history['val_ARI_initial']=val_ari\n",
    "                    history['val_NMI_initial']=val_nmi\n",
    "                    \n",
    "            \n",
    "            #save a plot\n",
    "            save_plot_umap(model, x_train, size_factors_train, y_train, y_pred_train, res, iteration, pdf_pages_train, \"train\")\n",
    "            save_plot_umap(model, x_test, size_factors_test, y_test, y_pred_test, res, iteration, pdf_pages_test, \"test\")\n",
    "\n",
    "\n",
    "                \n",
    "            #stop criterion\n",
    "            delta_label=np.sum(y_pred_train != y_pred_last_train).astype(np.float32)/y_pred_train.shape[0]\n",
    "            y_pred_last_train=np.copy(y_pred_train)\n",
    "            if iteration >0 and delta_label<tol:\n",
    "                print('delta_label ', delta_label, '< tol ', tol)\n",
    "                print('Reached tolerance threshold. Stopping training.')\n",
    "                break\n",
    "    \n",
    "        if (index + 1)*batch_size > x_train.shape[0]:\n",
    "            model.train_on_batch(x=[x_train[index * batch_size::], size_factors_train[index * batch_size:]],\n",
    "                                                 y=[p_train[index * batch_size::], raw_train[index * batch_size::]])\n",
    "            index=0\n",
    "        else:\n",
    "            model.train_on_batch(x=[x_train[index * batch_size:(index + 1) * batch_size], \n",
    "                                                    size_factors_train[index * batch_size:(index + 1) * batch_size]],\n",
    "                                                 y=[p_train[index * batch_size:(index + 1) * batch_size],\n",
    "                                                    raw_train[index * batch_size:(index + 1) * batch_size]])\n",
    "            index += 1\n",
    "        \n",
    "        #if iteration % save_interval == 0:\n",
    "            # save scDeepCluster model checkpoints\n",
    "            #print('saving model to: ''/weights' + str(iteration) + '.h5')\n",
    "            #model.save_weights('/weights' + str(iteration) + '.h5')\n",
    "            #print('saving model to: model/weights.weights.h5')\n",
    "            #model.save_weights('model/weights.weights.h5')\n",
    "    \n",
    "        #iteration+=1\n",
    "    \n",
    "    ca = np.round(cluster_acc(y_train, y_pred_train), 5)\n",
    "    nmi = np.round(normalized_mutual_info_score(y_train, y_pred_train), 5)\n",
    "    ari = np.round(adjusted_rand_score(y_train, y_pred_train), 5)\n",
    "    val_ca = np.round(cluster_acc(y_test, y_pred_test), 5)\n",
    "    val_nmi = np.round(normalized_mutual_info_score(y_test, y_pred_test), 5)\n",
    "    val_ari = np.round(adjusted_rand_score(y_test, y_pred_test), 5)\n",
    "    print('Final: CA=%.4f, NMI= %.4f, ARI= %.4f' % (ca, nmi, ari))\n",
    "    print('Final: val_CA=%.4f, val_NMI= %.4f, val_ARI= %.4f' % (val_ca, val_nmi, val_ari))\n",
    "    duration=int(time.time() - t0)\n",
    "    print('Clustering time: %d seconds.' % duration )\n",
    "    history[\"training_time\"]=duration\n",
    "    history[\"nbr_iteration\"]=iteration\n",
    "    history['CA_final']=ca\n",
    "    history['ARI_final']=ari\n",
    "    history['NMI_final']=nmi\n",
    "    history['val_CA_final']=val_ca\n",
    "    history['val_ARI_final']=val_ari\n",
    "    history['val_NMI_final']=val_nmi\n",
    "                    \n",
    "    \n",
    "    #save dictionnary\n",
    "    save_results_to_csv(history, \"data/weight_test/pbmc_weights_diff_AE_clustering_loss_2.csv\")\n",
    "    \n",
    "    pdf_pages_train.close()\n",
    "    pdf_pages_test.close()\n",
    "    \n",
    "    return y_pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36d28239-1b00-4283-bcf4-da2f78e69211",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update interval 27\n",
      "Size of train set :  (3416, 2000)\n",
      "Size of test set :  (855, 2000)\n",
      "..pretraining autoencoder : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3291572/350713899.py:117: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  size_factors_train=size_factors[train_idx]\n",
      "/tmp/ipykernel_3291572/350713899.py:118: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  size_factors_test=size_factors[test_idx]\n",
      "/tmp/ipykernel_3291572/350713899.py:121: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train=y[train_idx]\n",
      "/tmp/ipykernel_3291572/350713899.py:122: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_test=y[test_idx]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_ZINB\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"autoencoder_ZINB\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │ gaussian_noise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ gaussian_noise_1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ gaussian_noise_2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ encoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ decoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ decoder_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">514,000</span> │ decoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ size_factors        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ outputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                     │                   │            │ size_factors[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pi (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">514,000</span> │ decoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dispersion (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">514,000</span> │ decoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ outputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ pi[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                     │                   │            │ dispersion[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ Inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_1 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m512,256\u001b[0m │ gaussian_noise[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ encoder_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_2 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ gaussian_noise_1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ encoder_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_3 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ gaussian_noise_2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_1 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m1,056\u001b[0m │ encoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_2 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m2,112\u001b[0m │ decoder_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_3 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m16,640\u001b[0m │ decoder_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mean (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │    \u001b[38;5;34m514,000\u001b[0m │ decoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ size_factors        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ outputs (\u001b[38;5;33mLambda\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                     │                   │            │ size_factors[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pi (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │    \u001b[38;5;34m514,000\u001b[0m │ decoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dispersion (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │    \u001b[38;5;34m514,000\u001b[0m │ decoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ outputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ pi[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                     │                   │            │ dispersion[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,092,592</span> (7.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,092,592\u001b[0m (7.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,092,592</span> (7.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,092,592\u001b[0m (7.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.6397 - val_loss: 0.3948\n",
      "Epoch 2/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.3894 - val_loss: 0.3636\n",
      "Epoch 3/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.3501 - val_loss: 0.3347\n",
      "Epoch 4/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.3327 - val_loss: 0.3248\n",
      "Epoch 5/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.3223 - val_loss: 0.3189\n",
      "Epoch 6/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.3152 - val_loss: 0.3158\n",
      "Epoch 7/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.3116 - val_loss: 0.3142\n",
      "Epoch 8/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.3098 - val_loss: 0.3140\n",
      "Epoch 9/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.3094 - val_loss: 0.3125\n",
      "Epoch 10/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.3079 - val_loss: 0.3122\n",
      "Epoch 11/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.3066 - val_loss: 0.3114\n",
      "Epoch 12/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.3034 - val_loss: 0.3106\n",
      "Epoch 13/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.3074 - val_loss: 0.3102\n",
      "Epoch 14/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.3029 - val_loss: 0.3092\n",
      "Epoch 15/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.3032 - val_loss: 0.3094\n",
      "Epoch 16/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.3024 - val_loss: 0.3095\n",
      "Epoch 17/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.3021 - val_loss: 0.3094\n",
      "Epoch 18/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.3010 - val_loss: 0.3089\n",
      "Epoch 19/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.3005 - val_loss: 0.3081\n",
      "Epoch 20/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.2994 - val_loss: 0.3081\n",
      "Epoch 21/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.2993 - val_loss: 0.3097\n",
      "Epoch 22/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.3005 - val_loss: 0.3083\n",
      "Epoch 23/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.3000 - val_loss: 0.3066\n",
      "Epoch 24/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.3000 - val_loss: 0.3091\n",
      "Epoch 25/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.2982 - val_loss: 0.3077\n",
      "Epoch 26/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.2977 - val_loss: 0.3064\n",
      "Epoch 27/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.2965 - val_loss: 0.3083\n",
      "Epoch 28/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.2977 - val_loss: 0.3061\n",
      "Epoch 29/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.2955 - val_loss: 0.3066\n",
      "Epoch 30/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.2965 - val_loss: 0.3071\n",
      "Epoch 31/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.2950 - val_loss: 0.3065\n",
      "Epoch 32/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.2960 - val_loss: 0.3076\n",
      "Epoch 33/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.2945 - val_loss: 0.3061\n",
      "Epoch 34/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.2933 - val_loss: 0.3074\n",
      "Epoch 35/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.2944 - val_loss: 0.3064\n",
      "Epoch 36/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.2934 - val_loss: 0.3052\n",
      "Epoch 37/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.2932 - val_loss: 0.3057\n",
      "Epoch 38/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.2904 - val_loss: 0.3093\n",
      "Epoch 39/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.2919 - val_loss: 0.3100\n",
      "Epoch 40/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.2923 - val_loss: 0.3072\n",
      "Epoch 41/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.2923 - val_loss: 0.3053\n",
      "Epoch 42/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.2918 - val_loss: 0.3046\n",
      "Epoch 43/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.2908 - val_loss: 0.3054\n",
      "Epoch 44/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.2907 - val_loss: 0.3079\n",
      "Epoch 45/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.2903 - val_loss: 0.3083\n",
      "Epoch 46/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.2908 - val_loss: 0.3060\n",
      "Epoch 47/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.2900 - val_loss: 0.3074\n",
      "Epoch 48/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.2895 - val_loss: 0.3078\n",
      "Epoch 49/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.2882 - val_loss: 0.3054\n",
      "Epoch 50/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.2882 - val_loss: 0.3057\n",
      "Epoch 51/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.2895 - val_loss: 0.3056\n",
      "Epoch 52/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.2880 - val_loss: 0.3065\n",
      "Epoch 52: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │ Inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ encoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ size_factors        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ encoder_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_1 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m512,256\u001b[0m │ Inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_2 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ encoder_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ size_factors        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_3 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ encoder_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">530,784</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m530,784\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">530,784</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m530,784\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing cluster centers with leiden : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3291572/350713899.py:76: FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg.\n",
      "\n",
      " To achieve the future defaults please pass: flavor=\"igraph\" and n_iterations=2.  directed must also be False to work with igraph's implementation.\n",
      "  sc.tl.leiden(adata_latent, key_added=\"leiden_res_%.4f\" % (res), resolution=res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre de clusters est :  8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │ gaussian_noise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ Inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ gaussian_noise_1… │\n",
       "│                     │                   │            │ encoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ gaussian_noise_2… │\n",
       "│                     │                   │            │ encoder_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ encoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ decoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ decoder_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">514,000</span> │ decoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ size_factors        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ outputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                     │                   │            │ size_factors[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pi (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">514,000</span> │ decoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dispersion (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">514,000</span> │ decoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ clustering          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ encoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ClusteringLayer</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ outputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ pi[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                     │                   │            │ dispersion[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ Inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_1 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m512,256\u001b[0m │ gaussian_noise[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ Inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ encoder_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_2 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ gaussian_noise_1… │\n",
       "│                     │                   │            │ encoder_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ encoder_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_3 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ gaussian_noise_2… │\n",
       "│                     │                   │            │ encoder_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_1 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m1,056\u001b[0m │ encoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_2 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m2,112\u001b[0m │ decoder_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_3 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m16,640\u001b[0m │ decoder_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mean (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │    \u001b[38;5;34m514,000\u001b[0m │ decoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ size_factors        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ outputs (\u001b[38;5;33mLambda\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                     │                   │            │ size_factors[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pi (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │    \u001b[38;5;34m514,000\u001b[0m │ decoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dispersion (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │    \u001b[38;5;34m514,000\u001b[0m │ decoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ clustering          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m256\u001b[0m │ encoder_3[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mClusteringLayer\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ outputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ pi[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                     │                   │            │ dispersion[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,092,848</span> (7.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,092,848\u001b[0m (7.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,092,848</span> (7.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,092,848\u001b[0m (7.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set clustering weights\n",
      "Done\n",
      "..Starting Deep Clustering\n",
      "Iter-0: CA=0.8009, NMI= 0.7493, ARI= 0.7363; L= 0.28861, Lc= 0.19431,  Lr= 0.28447\n",
      "CA=0.7930, val_NMI= 0.7700, val_ARI= 0.7377; val_L= 0.31022, val_Lc= 0.18442,  val_Lr= 0.30315\n",
      "WARNING:tensorflow:5 out of the last 732 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x1538038fd8a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 733 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x1538038fd8a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iter-14: CA=0.8027, NMI= 0.7477, ARI= 0.7365; L= 0.28979, Lc= 0.19394,  Lr= 0.28565\n",
      "CA=0.7965, val_NMI= 0.7656, val_ARI= 0.7359; val_L= 0.30994, val_Lc= 0.18276,  val_Lr= 0.30292\n",
      "Iter-28: CA=0.8062, NMI= 0.7499, ARI= 0.7400; L= 0.28964, Lc= 0.19154,  Lr= 0.28562\n",
      "CA=0.7977, val_NMI= 0.7687, val_ARI= 0.7390; val_L= 0.31087, val_Lc= 0.18133,  val_Lr= 0.30376\n",
      "Iter-42: CA=0.8083, NMI= 0.7480, ARI= 0.7403; L= 0.29181, Lc= 0.18944,  Lr= 0.28757\n",
      "CA=0.8058, val_NMI= 0.7747, val_ARI= 0.7483; val_L= 0.31438, val_Lc= 0.18066,  val_Lr= 0.30739\n",
      "Iter-56: CA=0.8097, NMI= 0.7479, ARI= 0.7430; L= 0.28758, Lc= 0.18763,  Lr= 0.28340\n",
      "CA=0.8105, val_NMI= 0.7730, val_ARI= 0.7528; val_L= 0.30710, val_Lc= 0.17823,  val_Lr= 0.30019\n",
      "Iter-70: CA=0.8138, NMI= 0.7503, ARI= 0.7506; L= 0.28735, Lc= 0.18544,  Lr= 0.28318\n",
      "CA=0.8117, val_NMI= 0.7773, val_ARI= 0.7623; val_L= 0.30703, val_Lc= 0.17639,  val_Lr= 0.30022\n",
      "Iter-84: CA=0.8132, NMI= 0.7503, ARI= 0.7483; L= 0.29176, Lc= 0.18310,  Lr= 0.28752\n",
      "CA=0.8105, val_NMI= 0.7798, val_ARI= 0.7588; val_L= 0.31517, val_Lc= 0.17655,  val_Lr= 0.30807\n",
      "Iter-98: CA=0.8124, NMI= 0.7505, ARI= 0.7481; L= 0.28849, Lc= 0.18078,  Lr= 0.28424\n",
      "CA=0.8152, val_NMI= 0.7826, val_ARI= 0.7672; val_L= 0.31078, val_Lc= 0.17449,  val_Lr= 0.30389\n",
      "Iter-112: CA=0.8138, NMI= 0.7493, ARI= 0.7503; L= 0.28814, Lc= 0.18090,  Lr= 0.28390\n",
      "CA=0.8140, val_NMI= 0.7770, val_ARI= 0.7640; val_L= 0.30698, val_Lc= 0.17274,  val_Lr= 0.30021\n",
      "Iter-126: CA=0.8129, NMI= 0.7498, ARI= 0.7486; L= 0.28933, Lc= 0.17782,  Lr= 0.28523\n",
      "CA=0.8129, val_NMI= 0.7815, val_ARI= 0.7640; val_L= 0.31209, val_Lc= 0.17352,  val_Lr= 0.30517\n",
      "Iter-140: CA=0.8147, NMI= 0.7501, ARI= 0.7510; L= 0.28761, Lc= 0.17633,  Lr= 0.28338\n",
      "CA=0.8094, val_NMI= 0.7748, val_ARI= 0.7605; val_L= 0.31057, val_Lc= 0.17162,  val_Lr= 0.30366\n",
      "Iter-154: CA=0.8150, NMI= 0.7492, ARI= 0.7520; L= 0.28605, Lc= 0.17528,  Lr= 0.28188\n",
      "CA=0.8129, val_NMI= 0.7791, val_ARI= 0.7724; val_L= 0.30769, val_Lc= 0.17034,  val_Lr= 0.30099\n",
      "Iter-168: CA=0.8150, NMI= 0.7497, ARI= 0.7520; L= 0.28620, Lc= 0.17428,  Lr= 0.28204\n",
      "CA=0.8129, val_NMI= 0.7796, val_ARI= 0.7734; val_L= 0.30893, val_Lc= 0.17009,  val_Lr= 0.30212\n",
      "Iter-182: CA=0.8141, NMI= 0.7506, ARI= 0.7501; L= 0.29247, Lc= 0.17362,  Lr= 0.28814\n",
      "CA=0.8082, val_NMI= 0.7806, val_ARI= 0.7716; val_L= 0.31825, val_Lc= 0.17060,  val_Lr= 0.31129\n",
      "Iter-196: CA=0.8126, NMI= 0.7495, ARI= 0.7479; L= 0.28868, Lc= 0.17351,  Lr= 0.28432\n",
      "CA=0.8070, val_NMI= 0.7837, val_ARI= 0.7724; val_L= 0.31233, val_Lc= 0.16948,  val_Lr= 0.30549\n",
      "Iter-210: CA=0.8165, NMI= 0.7527, ARI= 0.7532; L= 0.28825, Lc= 0.17399,  Lr= 0.28395\n",
      "CA=0.8105, val_NMI= 0.7852, val_ARI= 0.7726; val_L= 0.30888, val_Lc= 0.17001,  val_Lr= 0.30220\n",
      "Iter-224: CA=0.8162, NMI= 0.7507, ARI= 0.7524; L= 0.28794, Lc= 0.17321,  Lr= 0.28364\n",
      "CA=0.8164, val_NMI= 0.7808, val_ARI= 0.7733; val_L= 0.31087, val_Lc= 0.17101,  val_Lr= 0.30402\n",
      "Iter-238: CA=0.8176, NMI= 0.7521, ARI= 0.7533; L= 0.28708, Lc= 0.17312,  Lr= 0.28272\n",
      "CA=0.8199, val_NMI= 0.7852, val_ARI= 0.7800; val_L= 0.31053, val_Lc= 0.17133,  val_Lr= 0.30368\n",
      "Iter-252: CA=0.8170, NMI= 0.7513, ARI= 0.7545; L= 0.28735, Lc= 0.17316,  Lr= 0.28297\n",
      "CA=0.8210, val_NMI= 0.7867, val_ARI= 0.7817; val_L= 0.31159, val_Lc= 0.17222,  val_Lr= 0.30468\n",
      "Iter-266: CA=0.8173, NMI= 0.7515, ARI= 0.7540; L= 0.28666, Lc= 0.17179,  Lr= 0.28229\n",
      "CA=0.8187, val_NMI= 0.7860, val_ARI= 0.7812; val_L= 0.31063, val_Lc= 0.16981,  val_Lr= 0.30378\n",
      "Iter-280: CA=0.8170, NMI= 0.7520, ARI= 0.7553; L= 0.28761, Lc= 0.17294,  Lr= 0.28318\n",
      "CA=0.8164, val_NMI= 0.7914, val_ARI= 0.7835; val_L= 0.31283, val_Lc= 0.17024,  val_Lr= 0.30589\n",
      "Iter-294: CA=0.8167, NMI= 0.7506, ARI= 0.7541; L= 0.29043, Lc= 0.17601,  Lr= 0.28579\n",
      "CA=0.8105, val_NMI= 0.7869, val_ARI= 0.7795; val_L= 0.31698, val_Lc= 0.17225,  val_Lr= 0.30991\n",
      "Iter-308: CA=0.8179, NMI= 0.7521, ARI= 0.7574; L= 0.28697, Lc= 0.17397,  Lr= 0.28247\n",
      "CA=0.8105, val_NMI= 0.7831, val_ARI= 0.7720; val_L= 0.31112, val_Lc= 0.17025,  val_Lr= 0.30424\n",
      "Iter-322: CA=0.8173, NMI= 0.7500, ARI= 0.7548; L= 0.28768, Lc= 0.17606,  Lr= 0.28315\n",
      "CA=0.8175, val_NMI= 0.7820, val_ARI= 0.7735; val_L= 0.31005, val_Lc= 0.17151,  val_Lr= 0.30316\n",
      "Iter-336: CA=0.8179, NMI= 0.7496, ARI= 0.7544; L= 0.29024, Lc= 0.17658,  Lr= 0.28563\n",
      "CA=0.8175, val_NMI= 0.7774, val_ARI= 0.7682; val_L= 0.31573, val_Lc= 0.17502,  val_Lr= 0.30855\n",
      "Iter-350: CA=0.8197, NMI= 0.7526, ARI= 0.7572; L= 0.28802, Lc= 0.17307,  Lr= 0.28341\n",
      "CA=0.8222, val_NMI= 0.7859, val_ARI= 0.7789; val_L= 0.31346, val_Lc= 0.17172,  val_Lr= 0.30642\n",
      "Iter-364: CA=0.8200, NMI= 0.7555, ARI= 0.7608; L= 0.28613, Lc= 0.17196,  Lr= 0.28157\n",
      "CA=0.8222, val_NMI= 0.7913, val_ARI= 0.7907; val_L= 0.30958, val_Lc= 0.16922,  val_Lr= 0.30284\n",
      "Iter-378: CA=0.8188, NMI= 0.7541, ARI= 0.7589; L= 0.28636, Lc= 0.17026,  Lr= 0.28185\n",
      "CA=0.8199, val_NMI= 0.7949, val_ARI= 0.7908; val_L= 0.31184, val_Lc= 0.16994,  val_Lr= 0.30497\n",
      "Iter-392: CA=0.8182, NMI= 0.7532, ARI= 0.7578; L= 0.28990, Lc= 0.16891,  Lr= 0.28529\n",
      "CA=0.8117, val_NMI= 0.7907, val_ARI= 0.7798; val_L= 0.31782, val_Lc= 0.16998,  val_Lr= 0.31076\n",
      "Iter-406: CA=0.8170, NMI= 0.7516, ARI= 0.7548; L= 0.28643, Lc= 0.16895,  Lr= 0.28182\n",
      "CA=0.8094, val_NMI= 0.7853, val_ARI= 0.7721; val_L= 0.31276, val_Lc= 0.16863,  val_Lr= 0.30585\n",
      "Iter-420: CA=0.8167, NMI= 0.7508, ARI= 0.7543; L= 0.28544, Lc= 0.17046,  Lr= 0.28080\n",
      "CA=0.8140, val_NMI= 0.7849, val_ARI= 0.7669; val_L= 0.30922, val_Lc= 0.16793,  val_Lr= 0.30248\n",
      "Iter-434: CA=0.8156, NMI= 0.7490, ARI= 0.7502; L= 0.28757, Lc= 0.17059,  Lr= 0.28291\n",
      "CA=0.8129, val_NMI= 0.7854, val_ARI= 0.7633; val_L= 0.31448, val_Lc= 0.17014,  val_Lr= 0.30764\n",
      "Iter-448: CA=0.8162, NMI= 0.7495, ARI= 0.7513; L= 0.28797, Lc= 0.16899,  Lr= 0.28321\n",
      "CA=0.8175, val_NMI= 0.7873, val_ARI= 0.7702; val_L= 0.31595, val_Lc= 0.16991,  val_Lr= 0.30903\n",
      "Iter-462: CA=0.8194, NMI= 0.7547, ARI= 0.7576; L= 0.28400, Lc= 0.16660,  Lr= 0.27940\n",
      "CA=0.8164, val_NMI= 0.7909, val_ARI= 0.7738; val_L= 0.31014, val_Lc= 0.16766,  val_Lr= 0.30333\n",
      "Iter-476: CA=0.8194, NMI= 0.7559, ARI= 0.7584; L= 0.28560, Lc= 0.17091,  Lr= 0.28088\n",
      "CA=0.8175, val_NMI= 0.7926, val_ARI= 0.7776; val_L= 0.31019, val_Lc= 0.17054,  val_Lr= 0.30343\n",
      "Iter-490: CA=0.8208, NMI= 0.7571, ARI= 0.7593; L= 0.28685, Lc= 0.17078,  Lr= 0.28209\n",
      "CA=0.8210, val_NMI= 0.7949, val_ARI= 0.7805; val_L= 0.31398, val_Lc= 0.17247,  val_Lr= 0.30716\n",
      "Iter-504: CA=0.8223, NMI= 0.7597, ARI= 0.7611; L= 0.28916, Lc= 0.17078,  Lr= 0.28429\n",
      "CA=0.8210, val_NMI= 0.7925, val_ARI= 0.7764; val_L= 0.31792, val_Lc= 0.17239,  val_Lr= 0.31128\n",
      "Iter-518: CA=0.8220, NMI= 0.7595, ARI= 0.7611; L= 0.28592, Lc= 0.17314,  Lr= 0.28102\n",
      "CA=0.8210, val_NMI= 0.7946, val_ARI= 0.7767; val_L= 0.31176, val_Lc= 0.17090,  val_Lr= 0.30521\n",
      "Iter-532: CA=0.8220, NMI= 0.7591, ARI= 0.7603; L= 0.28577, Lc= 0.17276,  Lr= 0.28086\n",
      "CA=0.8199, val_NMI= 0.7931, val_ARI= 0.7751; val_L= 0.31177, val_Lc= 0.17049,  val_Lr= 0.30521\n",
      "Iter-546: CA=0.8211, NMI= 0.7574, ARI= 0.7579; L= 0.28737, Lc= 0.17186,  Lr= 0.28246\n",
      "CA=0.8187, val_NMI= 0.7948, val_ARI= 0.7761; val_L= 0.31521, val_Lc= 0.17043,  val_Lr= 0.30856\n",
      "Iter-560: CA=0.8203, NMI= 0.7556, ARI= 0.7568; L= 0.28711, Lc= 0.17300,  Lr= 0.28214\n",
      "CA=0.8140, val_NMI= 0.7850, val_ARI= 0.7696; val_L= 0.31372, val_Lc= 0.17081,  val_Lr= 0.30700\n",
      "Iter-574: CA=0.8211, NMI= 0.7559, ARI= 0.7569; L= 0.28591, Lc= 0.17286,  Lr= 0.28095\n",
      "CA=0.8175, val_NMI= 0.7874, val_ARI= 0.7776; val_L= 0.31116, val_Lc= 0.17012,  val_Lr= 0.30446\n",
      "Iter-588: CA=0.8214, NMI= 0.7554, ARI= 0.7575; L= 0.28609, Lc= 0.17443,  Lr= 0.28112\n",
      "CA=0.8234, val_NMI= 0.7883, val_ARI= 0.7828; val_L= 0.31357, val_Lc= 0.17326,  val_Lr= 0.30679\n",
      "Iter-602: CA=0.8235, NMI= 0.7568, ARI= 0.7605; L= 0.28502, Lc= 0.17338,  Lr= 0.28005\n",
      "CA=0.8234, val_NMI= 0.7919, val_ARI= 0.7863; val_L= 0.31251, val_Lc= 0.17119,  val_Lr= 0.30585\n",
      "Iter-616: CA=0.8223, NMI= 0.7554, ARI= 0.7592; L= 0.28421, Lc= 0.17226,  Lr= 0.27925\n",
      "CA=0.8164, val_NMI= 0.7932, val_ARI= 0.7818; val_L= 0.31113, val_Lc= 0.16678,  val_Lr= 0.30450\n",
      "Iter-630: CA=0.8217, NMI= 0.7527, ARI= 0.7581; L= 0.28530, Lc= 0.17408,  Lr= 0.28025\n",
      "CA=0.8140, val_NMI= 0.7899, val_ARI= 0.7772; val_L= 0.31233, val_Lc= 0.16737,  val_Lr= 0.30559\n",
      "Iter-644: CA=0.8208, NMI= 0.7531, ARI= 0.7565; L= 0.28602, Lc= 0.17468,  Lr= 0.28090\n",
      "CA=0.8140, val_NMI= 0.7864, val_ARI= 0.7727; val_L= 0.31447, val_Lc= 0.16927,  val_Lr= 0.30746\n",
      "Iter-658: CA=0.8208, NMI= 0.7526, ARI= 0.7557; L= 0.28685, Lc= 0.17792,  Lr= 0.28158\n",
      "CA=0.8152, val_NMI= 0.7828, val_ARI= 0.7670; val_L= 0.31424, val_Lc= 0.17108,  val_Lr= 0.30714\n",
      "Iter-672: CA=0.8203, NMI= 0.7529, ARI= 0.7553; L= 0.28661, Lc= 0.17819,  Lr= 0.28134\n",
      "CA=0.8164, val_NMI= 0.7855, val_ARI= 0.7747; val_L= 0.31250, val_Lc= 0.16991,  val_Lr= 0.30563\n",
      "Iter-686: CA=0.8211, NMI= 0.7551, ARI= 0.7593; L= 0.28859, Lc= 0.18007,  Lr= 0.28334\n",
      "CA=0.8164, val_NMI= 0.7912, val_ARI= 0.7782; val_L= 0.31472, val_Lc= 0.17190,  val_Lr= 0.30771\n",
      "Iter-700: CA=0.8223, NMI= 0.7564, ARI= 0.7604; L= 0.28931, Lc= 0.18117,  Lr= 0.28390\n",
      "CA=0.8175, val_NMI= 0.7884, val_ARI= 0.7804; val_L= 0.31557, val_Lc= 0.17197,  val_Lr= 0.30838\n",
      "Iter-714: CA=0.8223, NMI= 0.7552, ARI= 0.7602; L= 0.29248, Lc= 0.18452,  Lr= 0.28693\n",
      "CA=0.8210, val_NMI= 0.7896, val_ARI= 0.7821; val_L= 0.31887, val_Lc= 0.17539,  val_Lr= 0.31140\n",
      "Iter-728: CA=0.8208, NMI= 0.7539, ARI= 0.7589; L= 0.29182, Lc= 0.18599,  Lr= 0.28622\n",
      "CA=0.8199, val_NMI= 0.7883, val_ARI= 0.7823; val_L= 0.31813, val_Lc= 0.17593,  val_Lr= 0.31081\n",
      "Iter-742: CA=0.8220, NMI= 0.7548, ARI= 0.7598; L= 0.28990, Lc= 0.18158,  Lr= 0.28452\n",
      "CA=0.8187, val_NMI= 0.7904, val_ARI= 0.7823; val_L= 0.31571, val_Lc= 0.17313,  val_Lr= 0.30877\n",
      "Iter-756: CA=0.8220, NMI= 0.7552, ARI= 0.7596; L= 0.28765, Lc= 0.18101,  Lr= 0.28227\n",
      "CA=0.8199, val_NMI= 0.7837, val_ARI= 0.7777; val_L= 0.31375, val_Lc= 0.17395,  val_Lr= 0.30669\n",
      "Iter-770: CA=0.8226, NMI= 0.7557, ARI= 0.7589; L= 0.28646, Lc= 0.17999,  Lr= 0.28115\n",
      "CA=0.8187, val_NMI= 0.7817, val_ARI= 0.7711; val_L= 0.31279, val_Lc= 0.17501,  val_Lr= 0.30581\n",
      "Iter-784: CA=0.8229, NMI= 0.7556, ARI= 0.7586; L= 0.28786, Lc= 0.18078,  Lr= 0.28245\n",
      "CA=0.8210, val_NMI= 0.7875, val_ARI= 0.7712; val_L= 0.31455, val_Lc= 0.17610,  val_Lr= 0.30767\n",
      "Iter-798: CA=0.8241, NMI= 0.7599, ARI= 0.7616; L= 0.28993, Lc= 0.18131,  Lr= 0.28438\n",
      "CA=0.8140, val_NMI= 0.7853, val_ARI= 0.7681; val_L= 0.31662, val_Lc= 0.17536,  val_Lr= 0.30979\n",
      "Iter-812: CA=0.8235, NMI= 0.7584, ARI= 0.7594; L= 0.28932, Lc= 0.18174,  Lr= 0.28371\n",
      "CA=0.8129, val_NMI= 0.7825, val_ARI= 0.7613; val_L= 0.31551, val_Lc= 0.17617,  val_Lr= 0.30867\n",
      "Iter-826: CA=0.8232, NMI= 0.7552, ARI= 0.7599; L= 0.28510, Lc= 0.17517,  Lr= 0.27978\n",
      "CA=0.8164, val_NMI= 0.7838, val_ARI= 0.7649; val_L= 0.31382, val_Lc= 0.17185,  val_Lr= 0.30701\n",
      "Iter-840: CA=0.8252, NMI= 0.7573, ARI= 0.7629; L= 0.28316, Lc= 0.17288,  Lr= 0.27787\n",
      "CA=0.8210, val_NMI= 0.7895, val_ARI= 0.7715; val_L= 0.31299, val_Lc= 0.17069,  val_Lr= 0.30609\n",
      "Iter-854: CA=0.8246, NMI= 0.7570, ARI= 0.7620; L= 0.28247, Lc= 0.17423,  Lr= 0.27708\n",
      "CA=0.8175, val_NMI= 0.7841, val_ARI= 0.7689; val_L= 0.31212, val_Lc= 0.17129,  val_Lr= 0.30515\n",
      "Iter-868: CA=0.8235, NMI= 0.7582, ARI= 0.7609; L= 0.28264, Lc= 0.17490,  Lr= 0.27717\n",
      "CA=0.8175, val_NMI= 0.7890, val_ARI= 0.7753; val_L= 0.31331, val_Lc= 0.17134,  val_Lr= 0.30637\n",
      "Iter-882: CA=0.8229, NMI= 0.7576, ARI= 0.7602; L= 0.28417, Lc= 0.17482,  Lr= 0.27863\n",
      "CA=0.8175, val_NMI= 0.7905, val_ARI= 0.7791; val_L= 0.31590, val_Lc= 0.17130,  val_Lr= 0.30894\n",
      "Iter-896: CA=0.8232, NMI= 0.7580, ARI= 0.7607; L= 0.28430, Lc= 0.17436,  Lr= 0.27871\n",
      "CA=0.8175, val_NMI= 0.7914, val_ARI= 0.7816; val_L= 0.31664, val_Lc= 0.16967,  val_Lr= 0.30959\n",
      "Iter-910: CA=0.8232, NMI= 0.7564, ARI= 0.7601; L= 0.28337, Lc= 0.17414,  Lr= 0.27779\n",
      "CA=0.8164, val_NMI= 0.7892, val_ARI= 0.7757; val_L= 0.31630, val_Lc= 0.16923,  val_Lr= 0.30929\n",
      "Iter-924: CA=0.8214, NMI= 0.7560, ARI= 0.7577; L= 0.28386, Lc= 0.17594,  Lr= 0.27823\n",
      "CA=0.8152, val_NMI= 0.7818, val_ARI= 0.7677; val_L= 0.31706, val_Lc= 0.17156,  val_Lr= 0.31005\n",
      "Iter-938: CA=0.8229, NMI= 0.7569, ARI= 0.7603; L= 0.28295, Lc= 0.17449,  Lr= 0.27742\n",
      "CA=0.8175, val_NMI= 0.7824, val_ARI= 0.7676; val_L= 0.31495, val_Lc= 0.17238,  val_Lr= 0.30802\n",
      "Iter-952: CA=0.8241, NMI= 0.7585, ARI= 0.7609; L= 0.28280, Lc= 0.17329,  Lr= 0.27728\n",
      "CA=0.8140, val_NMI= 0.7818, val_ARI= 0.7652; val_L= 0.31572, val_Lc= 0.17262,  val_Lr= 0.30880\n",
      "Iter-966: CA=0.8244, NMI= 0.7570, ARI= 0.7601; L= 0.28204, Lc= 0.17177,  Lr= 0.27651\n",
      "CA=0.8129, val_NMI= 0.7815, val_ARI= 0.7647; val_L= 0.31562, val_Lc= 0.17075,  val_Lr= 0.30878\n",
      "Iter-980: CA=0.8238, NMI= 0.7567, ARI= 0.7594; L= 0.28108, Lc= 0.17151,  Lr= 0.27554\n",
      "CA=0.8117, val_NMI= 0.7783, val_ARI= 0.7605; val_L= 0.31442, val_Lc= 0.16848,  val_Lr= 0.30765\n",
      "Iter-994: CA=0.8232, NMI= 0.7568, ARI= 0.7591; L= 0.28051, Lc= 0.17175,  Lr= 0.27492\n",
      "CA=0.8140, val_NMI= 0.7833, val_ARI= 0.7652; val_L= 0.31449, val_Lc= 0.16803,  val_Lr= 0.30773\n",
      "Iter-1008: CA=0.8235, NMI= 0.7571, ARI= 0.7593; L= 0.28107, Lc= 0.17230,  Lr= 0.27541\n",
      "CA=0.8117, val_NMI= 0.7788, val_ARI= 0.7581; val_L= 0.31603, val_Lc= 0.16927,  val_Lr= 0.30927\n",
      "Iter-1022: CA=0.8238, NMI= 0.7586, ARI= 0.7598; L= 0.28238, Lc= 0.17399,  Lr= 0.27659\n",
      "CA=0.8152, val_NMI= 0.7814, val_ARI= 0.7623; val_L= 0.31826, val_Lc= 0.17174,  val_Lr= 0.31149\n",
      "Iter-1036: CA=0.8220, NMI= 0.7562, ARI= 0.7576; L= 0.28069, Lc= 0.17259,  Lr= 0.27495\n",
      "CA=0.8129, val_NMI= 0.7804, val_ARI= 0.7605; val_L= 0.31607, val_Lc= 0.17067,  val_Lr= 0.30921\n",
      "Iter-1050: CA=0.8232, NMI= 0.7577, ARI= 0.7589; L= 0.27963, Lc= 0.17151,  Lr= 0.27397\n",
      "CA=0.8152, val_NMI= 0.7882, val_ARI= 0.7688; val_L= 0.31494, val_Lc= 0.16895,  val_Lr= 0.30808\n",
      "Iter-1064: CA=0.8232, NMI= 0.7577, ARI= 0.7603; L= 0.28045, Lc= 0.17351,  Lr= 0.27469\n",
      "CA=0.8187, val_NMI= 0.7899, val_ARI= 0.7778; val_L= 0.31571, val_Lc= 0.16869,  val_Lr= 0.30880\n",
      "Iter-1078: CA=0.8232, NMI= 0.7574, ARI= 0.7604; L= 0.27991, Lc= 0.17264,  Lr= 0.27413\n",
      "CA=0.8210, val_NMI= 0.7935, val_ARI= 0.7833; val_L= 0.31541, val_Lc= 0.16809,  val_Lr= 0.30849\n",
      "Iter-1092: CA=0.8232, NMI= 0.7566, ARI= 0.7590; L= 0.27978, Lc= 0.16975,  Lr= 0.27403\n",
      "CA=0.8199, val_NMI= 0.7900, val_ARI= 0.7811; val_L= 0.31702, val_Lc= 0.16786,  val_Lr= 0.31017\n",
      "Iter-1106: CA=0.8217, NMI= 0.7543, ARI= 0.7558; L= 0.28266, Lc= 0.17073,  Lr= 0.27678\n",
      "CA=0.8187, val_NMI= 0.7872, val_ARI= 0.7732; val_L= 0.32133, val_Lc= 0.16950,  val_Lr= 0.31442\n",
      "Iter-1120: CA=0.8223, NMI= 0.7548, ARI= 0.7563; L= 0.28133, Lc= 0.17080,  Lr= 0.27542\n",
      "CA=0.8164, val_NMI= 0.7850, val_ARI= 0.7673; val_L= 0.32031, val_Lc= 0.16849,  val_Lr= 0.31335\n",
      "Iter-1134: CA=0.8238, NMI= 0.7562, ARI= 0.7592; L= 0.27842, Lc= 0.17351,  Lr= 0.27261\n",
      "CA=0.8199, val_NMI= 0.7876, val_ARI= 0.7724; val_L= 0.31316, val_Lc= 0.16801,  val_Lr= 0.30630\n",
      "Iter-1148: CA=0.8232, NMI= 0.7564, ARI= 0.7587; L= 0.28008, Lc= 0.17536,  Lr= 0.27420\n",
      "CA=0.8164, val_NMI= 0.7872, val_ARI= 0.7680; val_L= 0.31438, val_Lc= 0.17047,  val_Lr= 0.30747\n",
      "Iter-1162: CA=0.8229, NMI= 0.7554, ARI= 0.7577; L= 0.28474, Lc= 0.17251,  Lr= 0.27878\n",
      "CA=0.8152, val_NMI= 0.7853, val_ARI= 0.7668; val_L= 0.32327, val_Lc= 0.17180,  val_Lr= 0.31608\n",
      "Iter-1176: CA=0.8223, NMI= 0.7557, ARI= 0.7571; L= 0.27892, Lc= 0.16965,  Lr= 0.27307\n",
      "CA=0.8164, val_NMI= 0.7825, val_ARI= 0.7686; val_L= 0.31678, val_Lc= 0.16932,  val_Lr= 0.30977\n",
      "Iter-1190: CA=0.8229, NMI= 0.7565, ARI= 0.7578; L= 0.27776, Lc= 0.17182,  Lr= 0.27190\n",
      "CA=0.8164, val_NMI= 0.7790, val_ARI= 0.7637; val_L= 0.31500, val_Lc= 0.17009,  val_Lr= 0.30806\n",
      "Iter-1204: CA=0.8226, NMI= 0.7562, ARI= 0.7572; L= 0.27726, Lc= 0.17051,  Lr= 0.27138\n",
      "CA=0.8164, val_NMI= 0.7789, val_ARI= 0.7633; val_L= 0.31594, val_Lc= 0.16893,  val_Lr= 0.30905\n",
      "delta_label  0.000585480093676815 < tol  0.001\n",
      "Reached tolerance threshold. Stopping training.\n",
      "Final: CA=0.8226, NMI= 0.7562, ARI= 0.7572\n",
      "Final: val_CA=0.8164, val_NMI= 0.7789, val_ARI= 0.7633\n",
      "Clustering time: 1900 seconds.\n",
      "Update interval 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3291572/350713899.py:117: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  size_factors_train=size_factors[train_idx]\n",
      "/tmp/ipykernel_3291572/350713899.py:118: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  size_factors_test=size_factors[test_idx]\n",
      "/tmp/ipykernel_3291572/350713899.py:121: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train=y[train_idx]\n",
      "/tmp/ipykernel_3291572/350713899.py:122: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_test=y[test_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set :  (3416, 2000)\n",
      "Size of test set :  (855, 2000)\n",
      "..pretraining autoencoder : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_ZINB\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"autoencoder_ZINB\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │ gaussian_noise_3… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_4    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ gaussian_noise_4… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_5    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ gaussian_noise_5… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ encoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ decoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ decoder_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">514,000</span> │ decoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ size_factors        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ outputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                     │                   │            │ size_factors[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pi (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">514,000</span> │ decoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dispersion (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">514,000</span> │ decoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ outputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ pi[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                     │                   │            │ dispersion[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ Inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_1 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m512,256\u001b[0m │ gaussian_noise_3… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_4    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ encoder_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_2 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ gaussian_noise_4… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_5    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ encoder_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_3 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ gaussian_noise_5… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_1 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m1,056\u001b[0m │ encoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_2 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m2,112\u001b[0m │ decoder_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_3 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m16,640\u001b[0m │ decoder_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mean (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │    \u001b[38;5;34m514,000\u001b[0m │ decoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ size_factors        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ outputs (\u001b[38;5;33mLambda\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                     │                   │            │ size_factors[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pi (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │    \u001b[38;5;34m514,000\u001b[0m │ decoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dispersion (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │    \u001b[38;5;34m514,000\u001b[0m │ decoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ outputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ pi[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                     │                   │            │ dispersion[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,092,592</span> (7.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,092,592\u001b[0m (7.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,092,592</span> (7.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,092,592\u001b[0m (7.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.6213 - val_loss: 0.3925\n",
      "Epoch 2/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.3882 - val_loss: 0.3662\n",
      "Epoch 3/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.3538 - val_loss: 0.3432\n",
      "Epoch 4/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.3393 - val_loss: 0.3310\n",
      "Epoch 5/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.3273 - val_loss: 0.3247\n",
      "Epoch 6/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.3217 - val_loss: 0.3189\n",
      "Epoch 7/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.3144 - val_loss: 0.3158\n",
      "Epoch 8/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.3128 - val_loss: 0.3143\n",
      "Epoch 9/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.3087 - val_loss: 0.3130\n",
      "Epoch 10/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.3084 - val_loss: 0.3131\n",
      "Epoch 11/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.3064 - val_loss: 0.3116\n",
      "Epoch 12/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.3063 - val_loss: 0.3115\n",
      "Epoch 13/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.3043 - val_loss: 0.3104\n",
      "Epoch 14/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - loss: 0.3042 - val_loss: 0.3089\n",
      "Epoch 15/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - loss: 0.3022 - val_loss: 0.3095\n",
      "Epoch 16/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - loss: 0.3031 - val_loss: 0.3089\n",
      "Epoch 17/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - loss: 0.3013 - val_loss: 0.3091\n",
      "Epoch 18/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - loss: 0.3017 - val_loss: 0.3082\n",
      "Epoch 19/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - loss: 0.3000 - val_loss: 0.3080\n",
      "Epoch 20/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - loss: 0.3000 - val_loss: 0.3089\n",
      "Epoch 21/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - loss: 0.3003 - val_loss: 0.3070\n",
      "Epoch 22/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - loss: 0.2992 - val_loss: 0.3079\n",
      "Epoch 23/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.3005 - val_loss: 0.3074\n",
      "Epoch 24/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 0.2984 - val_loss: 0.3067\n",
      "Epoch 25/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 0.2981 - val_loss: 0.3076\n",
      "Epoch 26/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - loss: 0.2973 - val_loss: 0.3058\n",
      "Epoch 27/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - loss: 0.2959 - val_loss: 0.3070\n",
      "Epoch 28/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 0.2942 - val_loss: 0.3059\n",
      "Epoch 29/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - loss: 0.2933 - val_loss: 0.3067\n",
      "Epoch 30/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - loss: 0.2950 - val_loss: 0.3061\n",
      "Epoch 31/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - loss: 0.2941 - val_loss: 0.3062\n",
      "Epoch 32/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 0.2960 - val_loss: 0.3062\n",
      "Epoch 33/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - loss: 0.2942 - val_loss: 0.3073\n",
      "Epoch 34/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - loss: 0.2936 - val_loss: 0.3073\n",
      "Epoch 35/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - loss: 0.2926 - val_loss: 0.3041\n",
      "Epoch 36/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - loss: 0.2940 - val_loss: 0.3054\n",
      "Epoch 37/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - loss: 0.2930 - val_loss: 0.3055\n",
      "Epoch 38/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - loss: 0.2928 - val_loss: 0.3080\n",
      "Epoch 39/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - loss: 0.2910 - val_loss: 0.3053\n",
      "Epoch 40/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - loss: 0.2926 - val_loss: 0.3070\n",
      "Epoch 41/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - loss: 0.2904 - val_loss: 0.3055\n",
      "Epoch 42/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - loss: 0.2901 - val_loss: 0.3061\n",
      "Epoch 43/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 0.2912 - val_loss: 0.3095\n",
      "Epoch 44/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - loss: 0.2894 - val_loss: 0.3055\n",
      "Epoch 45/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - loss: 0.2919 - val_loss: 0.3077\n",
      "Epoch 45: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │ Inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ encoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ size_factors        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ encoder_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_1 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m512,256\u001b[0m │ Inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_2 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ encoder_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ size_factors        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_3 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ encoder_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">530,784</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m530,784\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">530,784</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m530,784\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing cluster centers with leiden : \n",
      "Le nombre de clusters est :  8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_351\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_351\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">512,256</span> │ gaussian_noise_3… │\n",
       "│                     │                   │            │ Inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_4    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ gaussian_noise_4… │\n",
       "│                     │                   │            │ encoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_5    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ gaussian_noise_5… │\n",
       "│                     │                   │            │ encoder_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ encoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ decoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ decoder_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">514,000</span> │ decoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ size_factors        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ outputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                     │                   │            │ size_factors[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pi (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">514,000</span> │ decoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dispersion (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">514,000</span> │ decoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ clustering          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ encoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ClusteringLayer</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ outputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ pi[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                     │                   │            │ dispersion[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ Inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_1 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m512,256\u001b[0m │ gaussian_noise_3… │\n",
       "│                     │                   │            │ Inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_4    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ encoder_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_2 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ gaussian_noise_4… │\n",
       "│                     │                   │            │ encoder_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise_5    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ encoder_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_3 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ gaussian_noise_5… │\n",
       "│                     │                   │            │ encoder_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_1 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m1,056\u001b[0m │ encoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_2 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m2,112\u001b[0m │ decoder_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_3 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m16,640\u001b[0m │ decoder_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mean (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │    \u001b[38;5;34m514,000\u001b[0m │ decoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ size_factors        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ outputs (\u001b[38;5;33mLambda\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                     │                   │            │ size_factors[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pi (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │    \u001b[38;5;34m514,000\u001b[0m │ decoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dispersion (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │    \u001b[38;5;34m514,000\u001b[0m │ decoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ clustering          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m256\u001b[0m │ encoder_3[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mClusteringLayer\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ outputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ pi[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                     │                   │            │ dispersion[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,092,848</span> (7.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,092,848\u001b[0m (7.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,092,848</span> (7.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,092,848\u001b[0m (7.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set clustering weights\n",
      "Done\n",
      "..Starting Deep Clustering\n",
      "Iter-0: CA=0.6821, NMI= 0.7222, ARI= 0.5837; L= 0.29184, Lc= 0.19629,  Lr= 0.28764\n",
      "CA=0.6456, val_NMI= 0.7226, val_ARI= 0.5656; val_L= 0.31142, val_Lc= 0.18749,  val_Lr= 0.30443\n",
      "Iter-14: CA=0.6815, NMI= 0.7234, ARI= 0.5844; L= 0.29785, Lc= 0.19680,  Lr= 0.29363\n",
      "CA=0.6421, val_NMI= 0.7250, val_ARI= 0.5667; val_L= 0.31670, val_Lc= 0.18888,  val_Lr= 0.30958\n",
      "Iter-28: CA=0.6874, NMI= 0.7251, ARI= 0.5857; L= 0.29131, Lc= 0.19493,  Lr= 0.28707\n",
      "CA=0.6526, val_NMI= 0.7227, val_ARI= 0.5661; val_L= 0.30796, val_Lc= 0.18478,  val_Lr= 0.30113\n",
      "Iter-42: CA=0.6882, NMI= 0.7251, ARI= 0.5853; L= 0.29050, Lc= 0.19269,  Lr= 0.28625\n",
      "CA=0.6550, val_NMI= 0.7227, val_ARI= 0.5664; val_L= 0.30770, val_Lc= 0.18300,  val_Lr= 0.30089\n",
      "Iter-56: CA=0.6868, NMI= 0.7240, ARI= 0.5835; L= 0.29017, Lc= 0.19114,  Lr= 0.28592\n",
      "CA=0.6596, val_NMI= 0.7284, val_ARI= 0.5703; val_L= 0.30731, val_Lc= 0.18151,  val_Lr= 0.30055\n",
      "Iter-70: CA=0.6891, NMI= 0.7238, ARI= 0.5850; L= 0.29059, Lc= 0.18816,  Lr= 0.28639\n",
      "CA=0.6573, val_NMI= 0.7243, val_ARI= 0.5698; val_L= 0.30887, val_Lc= 0.17998,  val_Lr= 0.30213\n",
      "Iter-84: CA=0.6897, NMI= 0.7255, ARI= 0.5868; L= 0.29029, Lc= 0.18671,  Lr= 0.28604\n",
      "CA=0.6573, val_NMI= 0.7238, val_ARI= 0.5699; val_L= 0.30816, val_Lc= 0.17942,  val_Lr= 0.30150\n",
      "Iter-98: CA=0.6912, NMI= 0.7245, ARI= 0.5882; L= 0.29172, Lc= 0.18617,  Lr= 0.28739\n",
      "CA=0.6620, val_NMI= 0.7262, val_ARI= 0.5715; val_L= 0.30798, val_Lc= 0.17904,  val_Lr= 0.30142\n",
      "Iter-112: CA=0.6938, NMI= 0.7232, ARI= 0.5906; L= 0.29287, Lc= 0.18694,  Lr= 0.28848\n",
      "CA=0.6702, val_NMI= 0.7296, val_ARI= 0.5786; val_L= 0.30972, val_Lc= 0.18065,  val_Lr= 0.30315\n",
      "Iter-126: CA=0.6950, NMI= 0.7227, ARI= 0.5929; L= 0.29714, Lc= 0.19194,  Lr= 0.29252\n",
      "CA=0.6725, val_NMI= 0.7333, val_ARI= 0.5824; val_L= 0.31585, val_Lc= 0.18516,  val_Lr= 0.30929\n",
      "Iter-140: CA=0.6947, NMI= 0.7217, ARI= 0.5917; L= 0.29487, Lc= 0.18558,  Lr= 0.29038\n",
      "CA=0.6772, val_NMI= 0.7280, val_ARI= 0.5811; val_L= 0.31120, val_Lc= 0.17868,  val_Lr= 0.30468\n",
      "Iter-154: CA=0.6976, NMI= 0.7259, ARI= 0.5939; L= 0.29631, Lc= 0.19239,  Lr= 0.29173\n",
      "CA=0.6725, val_NMI= 0.7271, val_ARI= 0.5746; val_L= 0.31146, val_Lc= 0.18258,  val_Lr= 0.30477\n",
      "Iter-168: CA=0.6985, NMI= 0.7282, ARI= 0.5967; L= 0.29444, Lc= 0.18804,  Lr= 0.28996\n",
      "CA=0.6714, val_NMI= 0.7315, val_ARI= 0.5780; val_L= 0.31004, val_Lc= 0.17951,  val_Lr= 0.30334\n",
      "Iter-182: CA=0.6999, NMI= 0.7269, ARI= 0.5979; L= 0.29418, Lc= 0.18606,  Lr= 0.28972\n",
      "CA=0.6737, val_NMI= 0.7270, val_ARI= 0.5782; val_L= 0.30944, val_Lc= 0.18041,  val_Lr= 0.30270\n",
      "Iter-196: CA=0.7017, NMI= 0.7297, ARI= 0.5981; L= 0.29486, Lc= 0.18496,  Lr= 0.29033\n",
      "CA=0.6795, val_NMI= 0.7271, val_ARI= 0.5753; val_L= 0.31046, val_Lc= 0.18066,  val_Lr= 0.30367\n",
      "Iter-210: CA=0.6991, NMI= 0.7276, ARI= 0.5943; L= 0.29534, Lc= 0.18542,  Lr= 0.29077\n",
      "CA=0.6737, val_NMI= 0.7346, val_ARI= 0.5738; val_L= 0.31100, val_Lc= 0.18065,  val_Lr= 0.30432\n",
      "Iter-224: CA=0.6958, NMI= 0.7253, ARI= 0.5927; L= 0.29897, Lc= 0.18637,  Lr= 0.29420\n",
      "CA=0.6643, val_NMI= 0.7294, val_ARI= 0.5741; val_L= 0.31390, val_Lc= 0.18166,  val_Lr= 0.30728\n",
      "Iter-238: CA=0.6985, NMI= 0.7270, ARI= 0.5983; L= 0.29965, Lc= 0.18838,  Lr= 0.29482\n",
      "CA=0.6655, val_NMI= 0.7281, val_ARI= 0.5771; val_L= 0.31512, val_Lc= 0.18430,  val_Lr= 0.30825\n",
      "Iter-252: CA=0.6961, NMI= 0.7249, ARI= 0.5948; L= 0.29725, Lc= 0.18710,  Lr= 0.29255\n",
      "CA=0.6667, val_NMI= 0.7258, val_ARI= 0.5775; val_L= 0.31344, val_Lc= 0.18130,  val_Lr= 0.30650\n",
      "Iter-266: CA=0.6950, NMI= 0.7264, ARI= 0.5944; L= 0.29649, Lc= 0.18923,  Lr= 0.29186\n",
      "CA=0.6643, val_NMI= 0.7294, val_ARI= 0.5799; val_L= 0.31276, val_Lc= 0.17910,  val_Lr= 0.30588\n",
      "Iter-280: CA=0.6991, NMI= 0.7271, ARI= 0.6013; L= 0.29853, Lc= 0.19061,  Lr= 0.29380\n",
      "CA=0.6737, val_NMI= 0.7252, val_ARI= 0.5824; val_L= 0.31425, val_Lc= 0.18156,  val_Lr= 0.30758\n",
      "Iter-294: CA=0.7046, NMI= 0.7285, ARI= 0.6073; L= 0.30149, Lc= 0.19495,  Lr= 0.29649\n",
      "CA=0.6865, val_NMI= 0.7296, val_ARI= 0.5913; val_L= 0.31797, val_Lc= 0.18979,  val_Lr= 0.31114\n",
      "Iter-308: CA=0.7032, NMI= 0.7294, ARI= 0.6069; L= 0.29943, Lc= 0.19380,  Lr= 0.29453\n",
      "CA=0.6877, val_NMI= 0.7334, val_ARI= 0.5961; val_L= 0.31635, val_Lc= 0.18847,  val_Lr= 0.30959\n",
      "Iter-322: CA=0.7037, NMI= 0.7298, ARI= 0.6040; L= 0.29673, Lc= 0.18482,  Lr= 0.29204\n",
      "CA=0.6807, val_NMI= 0.7300, val_ARI= 0.5833; val_L= 0.31544, val_Lc= 0.18420,  val_Lr= 0.30847\n",
      "Iter-336: CA=0.7055, NMI= 0.7305, ARI= 0.6028; L= 0.29516, Lc= 0.18398,  Lr= 0.29044\n",
      "CA=0.7006, val_NMI= 0.7361, val_ARI= 0.5930; val_L= 0.31436, val_Lc= 0.18279,  val_Lr= 0.30735\n",
      "Iter-350: CA=0.7052, NMI= 0.7300, ARI= 0.6039; L= 0.29454, Lc= 0.18115,  Lr= 0.28978\n",
      "CA=0.7029, val_NMI= 0.7372, val_ARI= 0.5975; val_L= 0.31482, val_Lc= 0.18341,  val_Lr= 0.30769\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.02\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m         y_pred, model\u001b[38;5;241m=\u001b[39m\u001b[43mfit_and_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount_data_hvg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_ann\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mdata_ann\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_count_hvg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleiden\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_cluster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m             \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m27\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 279\u001b[0m, in \u001b[0;36mfit_and_split\u001b[0;34m(x_counts, obs, size_factors, raw_counts, alpha, n_cluster, res, method, noise, batch_size, max_iter, tol, update_interval, loss_weights, ae_weights, pretrained)\u001b[0m\n\u001b[1;32m    275\u001b[0m         history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_NMI_initial\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mval_nmi\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m#save a plot\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m \u001b[43msave_plot_umap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_factors_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdf_pages_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m save_plot_umap(model, x_test, size_factors_test, y_test, y_pred_test, res, iteration, pdf_pages_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m#stop criterion\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 29\u001b[0m, in \u001b[0;36msave_plot_umap\u001b[0;34m(model, x, size_factors, y, y_pred, res, iteration, pdf_pages, train_test)\u001b[0m\n\u001b[1;32m     26\u001b[0m adata_latent\u001b[38;5;241m.\u001b[39mobs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m     28\u001b[0m sc\u001b[38;5;241m.\u001b[39mpp\u001b[38;5;241m.\u001b[39mneighbors(adata_latent)\n\u001b[0;32m---> 29\u001b[0m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mumap\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata_latent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Génération du UMAP avec Scanpy\u001b[39;00m\n\u001b[1;32m     32\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80\u001b[0m, in \u001b[0;36mlegacy_api.<locals>.wrapper.<locals>.fn_compatible\u001b[0;34m(*args_all, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_compatible\u001b[39m(\u001b[38;5;241m*\u001b[39margs_all: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m R:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args_all) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n_positional:\n\u001b[0;32m---> 80\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     args_pos: P\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m     83\u001b[0m     args_pos, args_rest \u001b[38;5;241m=\u001b[39m args_all[:n_positional], args_all[n_positional:]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scanpy/tools/_umap.py:207\u001b[0m, in \u001b[0;36mumap\u001b[0;34m(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key)\u001b[0m\n\u001b[1;32m    205\u001b[0m     default_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m neighbors[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnectivities\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m    206\u001b[0m     n_epochs \u001b[38;5;241m=\u001b[39m default_epochs \u001b[38;5;28;01mif\u001b[39;00m maxiter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m maxiter\n\u001b[0;32m--> 207\u001b[0m     X_umap, _ \u001b[38;5;241m=\u001b[39m \u001b[43msimplicial_set_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneighbors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconnectivities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtocoo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnegative_sample_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnegative_sample_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneigh_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetric\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meuclidean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneigh_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetric_kwds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdensmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdensmap_kwds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbosity\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrapids\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    227\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`method=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrapids\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `rapids_singlecell.tl.louvain` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/umap/umap_.py:1193\u001b[0m, in \u001b[0;36msimplicial_set_embedding\u001b[0;34m(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, densmap, densmap_kwds, output_dens, output_metric, output_metric_kwds, euclidean_output, parallel, verbose, tqdm_kwds)\u001b[0m\n\u001b[1;32m   1186\u001b[0m embedding \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;241m10.0\u001b[39m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;241m*\u001b[39m (embedding \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(embedding, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39mmax(embedding, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(embedding, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m   1190\u001b[0m )\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m euclidean_output:\n\u001b[0;32m-> 1193\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_layout_euclidean\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_vertices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs_per_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m        \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrng_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnegative_sample_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdensmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdensmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdensmap_kwds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdensmap_kwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_kwds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_kwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmove_other\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1215\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m optimize_layout_generic(\n\u001b[1;32m   1216\u001b[0m         embedding,\n\u001b[1;32m   1217\u001b[0m         embedding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1233\u001b[0m         move_other\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1234\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/umap/layouts.py:380\u001b[0m, in \u001b[0;36moptimize_layout_euclidean\u001b[0;34m(head_embedding, tail_embedding, head, tail, n_epochs, n_vertices, epochs_per_sample, a, b, rng_state, gamma, initial_alpha, negative_sample_rate, parallel, verbose, densmap, densmap_kwds, tqdm_kwds, move_other)\u001b[0m\n\u001b[1;32m    377\u001b[0m     dens_re_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    378\u001b[0m     dens_re_cov \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 380\u001b[0m \u001b[43moptimize_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtail_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_vertices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs_per_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrng_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmove_other\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs_per_negative_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch_of_next_negative_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch_of_next_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdensmap_flag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdens_phi_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdens_re_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdens_re_cov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdens_re_std\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdens_re_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdens_lambda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdens_R\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdens_mu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdens_mu_tot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m alpha \u001b[38;5;241m=\u001b[39m initial_alpha \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[38;5;28mfloat\u001b[39m(n) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(n_epochs)))\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;129;01mand\u001b[39;00m n \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mint\u001b[39m(n_epochs \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for w in [0.02]:\n",
    "    for i in range (2):\n",
    "        y_pred, model=fit_and_split(count_data_hvg, data_ann.obs,  data_ann.obs.size_factors, raw_count_hvg, res=0.30, method=\"leiden\", alpha=1.0, noise=0.5, n_cluster=\"auto\", batch_size=256,\n",
    "             max_iter=5e3, tol=1e-3, update_interval=27, loss_weights=[w,1.0],\n",
    "            pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1415bc68-c04d-4d08-a775-a64a4278231e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec2af4e-6cd0-4a5d-a89f-a59f29f1da1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_scivar",
   "language": "python",
   "name": "env_scivar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
