{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953226f9",
   "metadata": {},
   "source": [
    "# Implementation of Contrastive-sc using PBMC 10X 4k dataset in order to reproduce paper results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f30b30",
   "metadata": {},
   "source": [
    "## Import useful modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be2d3346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scanpy in /shared/home/tberthet/.local/lib/python3.12/site-packages (1.10.1)\n",
      "Requirement already satisfied: anndata>=0.8 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.10.7)\n",
      "Requirement already satisfied: h5py>=3.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (3.11.0)\n",
      "Requirement already satisfied: joblib in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (1.4.2)\n",
      "Requirement already satisfied: legacy-api-wrap>=1.4 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (1.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (3.8.4)\n",
      "Requirement already satisfied: natsort in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (8.4.0)\n",
      "Requirement already satisfied: networkx>=2.7 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (3.3)\n",
      "Requirement already satisfied: numba>=0.56 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.59.1)\n",
      "Requirement already satisfied: numpy>=1.23 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from scanpy) (1.26.4)\n",
      "Requirement already satisfied: packaging>=21.3 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from scanpy) (23.2)\n",
      "Requirement already satisfied: pandas>=1.5 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from scanpy) (2.2.0)\n",
      "Requirement already satisfied: patsy in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.5.6)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.5.12)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.8 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (1.13.0)\n",
      "Requirement already satisfied: seaborn>=0.13 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.13.2)\n",
      "Requirement already satisfied: session-info in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (1.0.0)\n",
      "Requirement already satisfied: statsmodels>=0.13 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.14.2)\n",
      "Requirement already satisfied: tqdm in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (4.66.4)\n",
      "Requirement already satisfied: umap-learn!=0.5.0,>=0.5 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scanpy) (0.5.6)\n",
      "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from anndata>=0.8->scanpy) (1.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (2.8.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from numba>=0.56->scanpy) (0.42.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas>=1.5->scanpy) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas>=1.5->scanpy) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scikit-learn>=0.24->scanpy) (3.5.0)\n",
      "Requirement already satisfied: six in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from patsy->scanpy) (1.16.0)\n",
      "Requirement already satisfied: stdlib-list in /shared/home/tberthet/.local/lib/python3.12/site-packages (from session-info->scanpy) (0.10.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in /shared/home/tberthet/.local/lib/python3.12/site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /shared/home/tberthet/.local/lib/python3.12/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (69.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: rich in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /shared/home/tberthet/.local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (1.26.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /shared/home/tberthet/.local/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /shared/ifbstor1/software/miniconda/envs/jupyterlab-3.5.0/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: igraph in /shared/home/tberthet/.local/lib/python3.12/site-packages (0.11.5)\n",
      "Requirement already satisfied: texttable>=1.6.2 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from igraph) (1.7.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: leidenalg in /shared/home/tberthet/.local/lib/python3.12/site-packages (0.10.2)\n",
      "Requirement already satisfied: igraph<0.12,>=0.10.0 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from leidenalg) (0.11.5)\n",
      "Requirement already satisfied: texttable>=1.6.2 in /shared/home/tberthet/.local/lib/python3.12/site-packages (from igraph<0.12,>=0.10.0->leidenalg) (1.7.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement csv (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for csv\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement random (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for random\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scanpy\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip3 install igraph\n",
    "!pip3 install leidenalg\n",
    "!pip install os\n",
    "!pip install csv\n",
    "!pip install random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "436ae1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-06 18:06:13.608708: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-06 18:06:20.291292: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Layer\n",
    "from keras.models import load_model, Model\n",
    "from keras import backend as K\n",
    "from keras.losses import KLDivergence\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, accuracy_score, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import seaborn as sns\n",
    "from layers import ConstantDispersionLayer, SliceLayer, ColWiseMultLayer\n",
    "import keras\n",
    "from keras.layers import Layer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import math\n",
    "import random\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac9baf76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c088e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8432bf",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eaf695",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4287976f",
   "metadata": {},
   "source": [
    "Import dataset PBMC 4k and check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b855d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16643</th>\n",
       "      <th>16644</th>\n",
       "      <th>16645</th>\n",
       "      <th>16646</th>\n",
       "      <th>16647</th>\n",
       "      <th>16648</th>\n",
       "      <th>16649</th>\n",
       "      <th>16650</th>\n",
       "      <th>16651</th>\n",
       "      <th>16652</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4271 rows × 16653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3      4      5      6      7      8      9      \\\n",
       "0       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3       0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0   \n",
       "4       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "4266    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4267    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4268    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0   \n",
       "4269    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4270    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      ...  16643  16644  16645  16646  16647  16648  16649  16650  16651  \\\n",
       "0     ...    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1     ...    0.0   14.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2     ...    0.0    7.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3     ...    0.0    8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4     ...    0.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "4266  ...    0.0   10.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0   \n",
       "4267  ...    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4268  ...    1.0   20.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0   \n",
       "4269  ...    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4270  ...    0.0    9.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      16652  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "4266    0.0  \n",
       "4267    0.0  \n",
       "4268    0.0  \n",
       "4269    0.0  \n",
       "4270    0.0  \n",
       "\n",
       "[4271 rows x 16653 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=\"./dataset/10X_PBMC.h5\"\n",
    "with h5py.File(filename, 'r') as f :\n",
    "    data_X=f['X'][:]\n",
    "    data_Y=f['Y'][:]\n",
    "    df_X=pd.DataFrame(data_X)\n",
    "    df_Y=pd.DataFrame(data_Y)\n",
    "    \n",
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38e162be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4271 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label\n",
       "0        2\n",
       "1        2\n",
       "2        2\n",
       "3        8\n",
       "4        3\n",
       "...    ...\n",
       "4266     6\n",
       "4267     5\n",
       "4268     7\n",
       "4269     3\n",
       "4270     2\n",
       "\n",
       "[4271 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Y.columns=['label']\n",
    "df_Y[\"label\"]=df_Y['label'].astype(str)\n",
    "df_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2334f9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1292\n",
       "2     702\n",
       "3     606\n",
       "4     459\n",
       "5     450\n",
       "6     332\n",
       "7     295\n",
       "8     135\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Y[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8599d6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/home/tberthet/.local/lib/python3.12/site-packages/anndata/_core/aligned_df.py:67: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/shared/home/tberthet/.local/lib/python3.12/site-packages/anndata/_core/aligned_df.py:67: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 4271 × 16653"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann=sc.AnnData(df_X)\n",
    "data_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793be40a-49d4-4ddd-80e5-7ebf023a83b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ann.obs=df_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98b9b4",
   "metadata": {},
   "source": [
    "### Filter data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b8b136",
   "metadata": {},
   "source": [
    "On filtre les données de manière peu stricte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a97bdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/home/tberthet/.local/lib/python3.12/site-packages/anndata/_core/aligned_df.py:67: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "sc.pp.filter_cells(data_ann, min_genes=1)\n",
    "sc.pp.filter_genes(data_ann, min_cells=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d666545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of the raw matrix before normalizing\n",
    "data_ann.raw = data_ann.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dbcce11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 4271 × 16653\n",
       "    obs: 'label', 'n_genes'\n",
       "    var: 'n_cells'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d30f5",
   "metadata": {},
   "source": [
    "### Normalize and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "219882fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize\n",
    "sc.pp.normalize_total(data_ann)\n",
    "\n",
    "#compute size factor\n",
    "data_ann.obs['size_factors'] = data_ann.obs.n_genes / np.median(data_ann.obs.n_genes)\n",
    "#data_ann.obs['size_factors'] = 1.0\n",
    "\n",
    "#log transform\n",
    "sc.pp.log1p(data_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee941d8b-91a2-4fcc-95bf-4d785f65eb99",
   "metadata": {},
   "source": [
    "Features selection : selection of high variable genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "038d051f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1280x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc.pp.highly_variable_genes(data_ann, n_top_genes=500, batch_key=\"label\")\n",
    "sc.pl.highly_variable_genes(data_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "490890e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "sc.pp.scale(data_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb6129",
   "metadata": {},
   "source": [
    "### Explore the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60b31b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       ...,\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., 16.46698363,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "930af5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16653"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann.n_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "744468b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       ...,\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., 16.46698363,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358],\n",
       "       [-0.04478425, -0.36973775, -0.22519336, ..., -0.04429302,\n",
       "        -0.05613264, -0.09001358]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2814ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_cells</th>\n",
       "      <th>highly_variable</th>\n",
       "      <th>means</th>\n",
       "      <th>dispersions</th>\n",
       "      <th>dispersions_norm</th>\n",
       "      <th>highly_variable_nbatches</th>\n",
       "      <th>highly_variable_intersection</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>-0.013101</td>\n",
       "      <td>-0.060134</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.028724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570</td>\n",
       "      <td>False</td>\n",
       "      <td>0.135255</td>\n",
       "      <td>-0.001270</td>\n",
       "      <td>0.209814</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.091207</td>\n",
       "      <td>0.246681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225</td>\n",
       "      <td>False</td>\n",
       "      <td>0.050292</td>\n",
       "      <td>-0.021517</td>\n",
       "      <td>0.112911</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.034340</td>\n",
       "      <td>0.152490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>-0.149268</td>\n",
       "      <td>-0.466780</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.033887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106</td>\n",
       "      <td>False</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>0.030561</td>\n",
       "      <td>0.267766</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>0.106600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16648</th>\n",
       "      <td>322</td>\n",
       "      <td>False</td>\n",
       "      <td>0.070651</td>\n",
       "      <td>0.029831</td>\n",
       "      <td>0.317225</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.050375</td>\n",
       "      <td>0.184955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16649</th>\n",
       "      <td>78</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018880</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.153966</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.011738</td>\n",
       "      <td>0.090542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16650</th>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>-0.250185</td>\n",
       "      <td>-1.141559</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.023021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16651</th>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>-0.137269</td>\n",
       "      <td>-0.271806</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.036117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16652</th>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>0.083313</td>\n",
       "      <td>0.514094</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.068266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16653 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_cells  highly_variable     means  dispersions  dispersions_norm  \\\n",
       "0            9            False  0.002611    -0.013101         -0.060134   \n",
       "1          570            False  0.135255    -0.001270          0.209814   \n",
       "2          225            False  0.050292    -0.021517          0.112911   \n",
       "3           12            False  0.001860    -0.149268         -0.466780   \n",
       "4          106            False  0.024858     0.030561          0.267766   \n",
       "...        ...              ...       ...          ...               ...   \n",
       "16648      322            False  0.070651     0.029831          0.317225   \n",
       "16649       78            False  0.018880     0.000764          0.153966   \n",
       "16650        9            False  0.001481    -0.250185         -1.141559   \n",
       "16651       15            False  0.003912    -0.137269         -0.271806   \n",
       "16652       38             True  0.010352     0.083313          0.514094   \n",
       "\n",
       "       highly_variable_nbatches  highly_variable_intersection      mean  \\\n",
       "0                             0                         False  0.001286   \n",
       "1                             0                         False  0.091207   \n",
       "2                             0                         False  0.034340   \n",
       "3                             0                         False  0.001729   \n",
       "4                             1                         False  0.016371   \n",
       "...                         ...                           ...       ...   \n",
       "16648                         1                         False  0.050375   \n",
       "16649                         1                         False  0.011738   \n",
       "16650                         0                         False  0.001020   \n",
       "16651                         0                         False  0.002027   \n",
       "16652                         2                         False  0.006145   \n",
       "\n",
       "            std  \n",
       "0      0.028724  \n",
       "1      0.246681  \n",
       "2      0.152490  \n",
       "3      0.033887  \n",
       "4      0.106600  \n",
       "...         ...  \n",
       "16648  0.184955  \n",
       "16649  0.090542  \n",
       "16650  0.023021  \n",
       "16651  0.036117  \n",
       "16652  0.068266  \n",
       "\n",
       "[16653 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09ca4c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n_genes</th>\n",
       "      <th>size_factors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>748</td>\n",
       "      <td>0.607636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1052</td>\n",
       "      <td>0.854590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>739</td>\n",
       "      <td>0.600325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>874</td>\n",
       "      <td>0.709992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>951</td>\n",
       "      <td>0.772543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>6</td>\n",
       "      <td>1807</td>\n",
       "      <td>1.467912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>5</td>\n",
       "      <td>1249</td>\n",
       "      <td>1.014622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>7</td>\n",
       "      <td>2223</td>\n",
       "      <td>1.805849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>3</td>\n",
       "      <td>983</td>\n",
       "      <td>0.798538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>2</td>\n",
       "      <td>1211</td>\n",
       "      <td>0.983753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4271 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  n_genes  size_factors\n",
       "0        2      748      0.607636\n",
       "1        2     1052      0.854590\n",
       "2        2      739      0.600325\n",
       "3        8      874      0.709992\n",
       "4        3      951      0.772543\n",
       "...    ...      ...           ...\n",
       "4266     6     1807      1.467912\n",
       "4267     5     1249      1.014622\n",
       "4268     7     2223      1.805849\n",
       "4269     3      983      0.798538\n",
       "4270     2     1211      0.983753\n",
       "\n",
       "[4271 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6701e828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ann.raw.X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc43f6a-384b-491e-a14b-c06fb68e7e0d",
   "metadata": {},
   "source": [
    "### Get only the data corresponding to the high variable genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e453889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.43124879, -0.14809046, -0.19217715, ...,  1.68828923,\n",
       "         1.55773585, -0.09001358],\n",
       "       [-0.53800062, -0.14809046, -0.19217715, ...,  1.13904774,\n",
       "         0.75317683, -0.09001358],\n",
       "       [-0.53800062, -0.14809046, -0.19217715, ...,  2.07421344,\n",
       "         1.7336189 , -0.09001358],\n",
       "       ...,\n",
       "       [ 1.1276868 , -0.14809046, -0.19217715, ..., -0.83583182,\n",
       "        -0.56730305, -0.09001358],\n",
       "       [ 1.59388979, -0.14809046, -0.19217715, ..., -0.82391394,\n",
       "        -1.13425163, -0.09001358],\n",
       "       [-0.53800062, -0.14809046, -0.19217715, ...,  1.19314461,\n",
       "         1.33492008, -0.09001358]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the preprocessed count matrix of the high variables genes only\n",
    "highly_variable_genes = data_ann.var[data_ann.var['highly_variable']].index.tolist()\n",
    "count_data_hvg = data_ann[:, highly_variable_genes].X\n",
    "count_data_hvg=count_data_hvg.toarray()\n",
    "count_data_hvg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbb7e32",
   "metadata": {},
   "source": [
    "## Create autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b527479-ce6c-4bf1-b518-4f159ac35a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contrastive_encoder(input_dim, dims, dropout=0.8):\n",
    "    \"\"\"\n",
    "    Create the encoder architecture\n",
    "    \n",
    "    Inputs :\n",
    "        input_dim (int) : input shape\n",
    "        dims (list of int) : size of the enoder layers\n",
    "        dropout (float from 0 to 1) : rate of dropout\n",
    "    \"\"\"\n",
    "    Inputs = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dropout(rate=dropout)(Inputs)  # L'argument input_shape n'est pas nécessaire ici\n",
    "    for i in range(len(dims) - 1):\n",
    "        x = layers.Dense(dims[i], kernel_initializer='glorot_uniform')(x)\n",
    "        x = layers.BatchNormalization(epsilon=1e-5, momentum=0.1)(x)\n",
    "        x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Dense(dims[-1],  kernel_initializer='glorot_uniform')(x)\n",
    "    x = layers.Lambda(lambda y: tf.nn.l2_normalize(y, axis=1))(x)\n",
    "    model = Model(Inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6343118-ae3e-45b4-83b2-16212e8b6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SupConLoss(features, labels=None, mask=None, temperature=0.07, base_temperature=0.07, contrast_mode='all'):\n",
    "    \"\"\"\n",
    "    Computes the Supervised Contrastive Loss \n",
    "\n",
    "    Inputs:\n",
    "        features (tf.Tensor): Feature representations of shape [batch_size, n_views, ...].\n",
    "        labels (tf.Tensor): Ground truth labels of shape [batch_size]. Default is None.\n",
    "        mask (tf.Tensor): Contrastive mask of shape [batch_size, batch_size]. Default is None.\n",
    "        temperature (float): Temperature scaling parameter. Default is 0.07.\n",
    "        base_temperature (float): Base temperature scaling parameter. Default is 0.07.\n",
    "        contrast_mode (str): Mode of contrastive computation, either 'one' or 'all'. Default is 'all'.\n",
    "\n",
    "    Output:\n",
    "        loss: The computed loss value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the features have at least 3 dimensions\n",
    "    if len(features.shape) < 3:\n",
    "        raise ValueError('`features` needs to be [bsz, n_views, ...], at least 3 dimensions are required')\n",
    "    \n",
    "    # Reshape features if they have more than 3 dimensions\n",
    "    if len(features.shape) > 3:\n",
    "        features = tf.reshape(features, [tf.shape(features)[0], tf.shape(features)[1], -1]) \n",
    "    \n",
    "    batch_size = tf.shape(features)[0]\n",
    "\n",
    "    # Ensure only one of `labels` or `mask` is provided\n",
    "    if labels is not None and mask is not None:\n",
    "        raise ValueError('Cannot define both `labels` and `mask`')\n",
    "    elif labels is None and mask is None:\n",
    "        # If neither `labels` nor `mask` are provided, use an identity matrix as mask\n",
    "        mask = tf.eye(batch_size, dtype=tf.float32)\n",
    "    elif labels is not None:\n",
    "        # Create mask based on labels\n",
    "        labels = tf.reshape(labels, (-1, 1))\n",
    "        if labels.shape[0] != batch_size:\n",
    "            raise ValueError('Num of labels does not match num of features')\n",
    "        mask = tf.cast(tf.equal(labels, tf.transpose(labels)), dtype=tf.float32)\n",
    "    else:\n",
    "        # If only `mask` is provided, use it as is\n",
    "        mask = tf.eye(batch_size, dtype=tf.float32)\n",
    "    \n",
    "    contrast_count = features.shape[1]\n",
    "    contrast_feature = tf.reshape(tf.concat(tf.unstack(features, axis=1), axis=0), [-1, tf.shape(features)[2]])\n",
    "    \n",
    "    # Determine the anchor features based on contrast mode\n",
    "    if contrast_mode == 'one':\n",
    "        anchor_feature = features[:, 0]\n",
    "        anchor_count = 1\n",
    "    elif contrast_mode == \"all\":\n",
    "        anchor_feature = contrast_feature\n",
    "        anchor_count = contrast_count\n",
    "    else:\n",
    "        raise ValueError(f'Unknown mode : {contrast_mode}')\n",
    "        \n",
    "    # Compute the logits\n",
    "    anchor_dot_contrast = tf.math.divide(tf.linalg.matmul(anchor_feature, contrast_feature, transpose_b=True), temperature)\n",
    "    \n",
    "    # Subtract the maximum logit for numerical stability\n",
    "    logits_max = tf.reduce_max(anchor_dot_contrast, axis=1, keepdims=True)\n",
    "    logits = anchor_dot_contrast - logits_max\n",
    "    \n",
    "    # Tile the mask\n",
    "    mask = tf.tile(mask, [anchor_count, contrast_count])\n",
    "    \n",
    "    # Create logits mask to exclude self-contrast cases\n",
    "    logits_mask = tf.ones_like(mask) - tf.eye(batch_size * anchor_count, dtype=tf.float32)\n",
    "    mask *= logits_mask\n",
    "    \n",
    "    # Compute the exponential logits\n",
    "    exp_logits = tf.exp(logits) * logits_mask\n",
    "    \n",
    "    # Compute the log-probabilities\n",
    "    log_prob = logits - tf.math.log(tf.reduce_sum(exp_logits, axis=1, keepdims=True))\n",
    "    \n",
    "    # Compute the mean of log-probabilities for positive samples\n",
    "    mean_log_prob_pos = tf.reduce_sum(mask * log_prob, axis=1) / tf.reduce_sum(mask, axis=1)\n",
    "    \n",
    "    # Compute the final loss\n",
    "    loss = -(temperature / base_temperature) * mean_log_prob_pos\n",
    "    loss = tf.reshape(loss, [anchor_count, batch_size])\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07efb1ec-6e32-45e2-a341-ad69ca77ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_kmeans(encoder, x_counts, obs,n='auto',  plot=False):\n",
    "    \"\"\"\n",
    "    Apply K-means clustering on the latent space latent to maximise the sum of the metrics\n",
    "    \n",
    "    Inputs :\n",
    "        encoder : the encoder model\n",
    "        x_counts : the input count matrix\n",
    "        obs : true labels\n",
    "        n : if auto, look for the best number of clusters otherwise use the n value given\n",
    "        plot (bool) : if True show some plots, none otherwise\n",
    "    \n",
    "    Outputs :\n",
    "        y_pred : clusters assignments from K-means clustering\n",
    "        n (int) : the number of clusters\n",
    "        kmeans.cluster_centers_ : clusters centers\n",
    "    \"\"\"\n",
    "    y=obs\n",
    "    ari=[]\n",
    "    nmi=[]\n",
    "    ca=[]\n",
    "    x=[]\n",
    "    if n==\"auto\":\n",
    "        #apply K-means for 1 to 20 clusters\n",
    "        for n in range (1,20):\n",
    "            kmeans=KMeans(n_clusters=n, n_init=30, verbose=0)\n",
    "            y_pred=kmeans.fit_predict(encoder.predict(x_counts, verbose=0))\n",
    "            ari.append(adjusted_rand_score(y, y_pred))\n",
    "            nmi.append(normalized_mutual_info_score(y, y_pred))\n",
    "            ca.append(cluster_acc(y, y_pred))\n",
    "            x.append(n)\n",
    "        #choose the number of clusters that maximize the sum of the metrics\n",
    "        somme_metriques = [x + y + z for x, y, z in zip(ari, nmi, ca)]\n",
    "        n=(somme_metriques.index(max(somme_metriques))+1)\n",
    "    \n",
    "    kmeans=KMeans(n_clusters=n, n_init=20)\n",
    "    y_pred=kmeans.fit_predict(encoder.predict(x_counts))\n",
    "    \n",
    "    #display some plots if needed\n",
    "    if plot==True:\n",
    "        predict_data=encoder.predict(x_counts)\n",
    "        adata_latent = sc.AnnData(predict_data)\n",
    "        obs_df = pd.DataFrame({'label': y})\n",
    "        adata_latent.obs=obs_df\n",
    "        adata_latent.obs[\"kmeans\"]=y_pred\n",
    "        sc.pp.neighbors(adata_latent)\n",
    "        sc.tl.umap(adata_latent)\n",
    "        sc.pl.umap(adata_latent, color='label')\n",
    "        plt.plot(x,ari)\n",
    "        plt.plot(x,nmi)\n",
    "        plt.plot(x,ca)\n",
    "        plt.xlabel(\"nombre de clusters\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.legend(labels=[\"ARI\", \"NMI\", \"CA\"])\n",
    "        ari = adjusted_rand_score(y, y_pred)\n",
    "        print(\"Indice de Rand ajusté (ARI) :\", ari)\n",
    "        nmi = normalized_mutual_info_score(y, y_pred)\n",
    "        print(\"Normalized mutual info (NMI) :\", nmi)\n",
    "        ca=cluster_acc(y, y_pred)\n",
    "        print(\"Clustering accuracy (CA) :\", ca)\n",
    "        sc.pl.umap( adata_latent, color=[\"kmeans\"], legend_loc=\"on data\")\n",
    "        plt.plot()\n",
    "    return y_pred, n, kmeans.cluster_centers_\n",
    "\n",
    "def auto_leiden(encoder, x_counts, y, res=\"auto\", plot=False):\n",
    "    \"\"\"\n",
    "    Apply Leiden clustering on the latent space latent to maximise the sum of the metrics\n",
    "    \n",
    "    Inputs :\n",
    "        encoder : the encoder model\n",
    "        x_counts : the input count matrix\n",
    "        y : the true labels\n",
    "        res : if auto choose the resolution to maximize the sum of metrics \n",
    "            otherwise apply Leiden algorithm with the indicated resolution\n",
    "        plot (bool) : if True show some plots, none otherwise\n",
    "    \n",
    "    Outputs :\n",
    "        res : the retained resolution\n",
    "        predict : the clusters assignments\n",
    "        n_clusters (int) : the number of clusters\n",
    "        cluster_centers : the clusters centers \n",
    "    \"\"\"\n",
    "    #create an anndata from the data in the latent space\n",
    "    predict_data=encoder.predict(x_counts, verbose=0)\n",
    "    adata_latent = sc.AnnData(predict_data)\n",
    "    obs_df = pd.DataFrame({'label': y})\n",
    "    adata_latent.obs=obs_df\n",
    "    \n",
    "    #compute neigbors and UMAP \n",
    "    sc.pp.neighbors(adata_latent, use_rep='X')\n",
    "    sc.tl.umap(adata_latent)\n",
    "    list_ari=[]\n",
    "    list_nmi=[]\n",
    "    list_ca=[]\n",
    "    x=[]\n",
    "    \n",
    "    if res==\"auto\":\n",
    "        #search for the best resolution\n",
    "        for i in range (1,10):\n",
    "            sc.tl.leiden(adata_latent, key_added=\"leiden\", resolution=i/100)\n",
    "            predict_cluster=adata_latent.obs[\"leiden\"]\n",
    "            list_ari.append(adjusted_rand_score(y, predict_cluster))\n",
    "            list_nmi.append(normalized_mutual_info_score(y, predict_cluster))\n",
    "            list_ca.append(cluster_acc(y, predict_cluster))\n",
    "            x.append(i/100)\n",
    "        for i in range (1,11):\n",
    "            sc.tl.leiden(adata_latent, key_added=\"leiden\", resolution=i/10)\n",
    "            predict_cluster=adata_latent.obs[\"leiden\"]\n",
    "            list_ari.append(adjusted_rand_score(y, predict_cluster))\n",
    "            list_nmi.append(normalized_mutual_info_score(y, predict_cluster))\n",
    "            list_ca.append(cluster_acc(y, predict_cluster))\n",
    "            x.append(i/10)\n",
    "         #select the best resolution value\n",
    "        somme_metriques = [x + y + z for x, y, z in zip(list_ari, list_nmi, list_ca)]\n",
    "        res=x[somme_metriques.index(max(somme_metriques))]\n",
    "        print(\"La résolution est de : \", res)\n",
    "    #compute for the best resolution\n",
    "    sc.tl.leiden(adata_latent, key_added=\"leiden_res_%.4f\" % (res), resolution=res)\n",
    "    predict=adata_latent.obs[\"leiden_res_%.4f\" % (res)]\n",
    "    \n",
    "    \n",
    "    #compute cluster center for initialization\n",
    "    init_pred=np.asarray(predict,dtype=int)\n",
    "    features=pd.DataFrame(adata_latent.X,index=np.arange(0,adata_latent.shape[0]))\n",
    "    Group=pd.Series(init_pred,index=np.arange(0,adata_latent.shape[0]),name=\"Group\")\n",
    "    Mergefeature=pd.concat([features,Group],axis=1)\n",
    "    cluster_centers=np.asarray(Mergefeature.groupby(\"Group\").mean())\n",
    "    n_clusters=len(np.unique(init_pred))\n",
    "    \n",
    "    #display plots if required\n",
    "    if plot==True:\n",
    "        sc.pl.umap(adata_latent, color='label')\n",
    "        plt.plot(x,list_ari)\n",
    "        plt.plot(x,list_nmi)\n",
    "        plt.plot(x,list_ca)\n",
    "        plt.xlabel(\"nombre de clusters\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.legend(labels=[\"ARI\", \"NMI\", \"CA\"])\n",
    "        plt.plot()\n",
    "        sc.pl.umap( adata_latent, color=[\"leiden_res_%.4f\" % (res)], legend_loc=\"on data\")\n",
    "        ari = adjusted_rand_score(y, predict)\n",
    "        print(\"Indice de Rand ajusté (ARI) :\", ari)\n",
    "        nmi = normalized_mutual_info_score(y, predict)\n",
    "        print(\"Normalized mutual info (NMI) :\", nmi)\n",
    "        ca=cluster_acc(y, predict)\n",
    "        print(\"Clustering accuracy (CA) :\", ca)\n",
    " \n",
    "        #crosstab = pd.crosstab(predict,y)\n",
    "        #sns.heatmap(crosstab, annot=True, cmap='Blues')\n",
    "        #plt.ylabel('Clusters prédits')\n",
    "        #plt.xlabel('Annotations réelles')\n",
    "        #plt.title('Matrice de confusion')\n",
    "        #plt.show()\n",
    "    return res, predict, n_clusters, cluster_centers\n",
    "\n",
    "def cluster_embedding(model, X, y, method=None, res='auto', n='auto', plot=False):\n",
    "    \"\"\"\n",
    "    Realize the clustering according to the method (K-means or Leiden)\n",
    "    \n",
    "    Inputs :\n",
    "        model : the encoder model\n",
    "        X : the input count matrix\n",
    "        y : the true labels\n",
    "        method : the choosen method (leiden or kmeans)\n",
    "        res (float)= the resolution for Leiden\n",
    "        n (int) = the number of clusters for Kmeans\n",
    "        plot (bool) : if yes, display some plots\n",
    "        \n",
    "    Outputs :\n",
    "        res : the  selected resolution for Leiden\n",
    "        y_pred : clustering assignments\n",
    "        n_clusters (int) : number of clusters\n",
    "        clusters_centers : centroids coordinates\n",
    "        \n",
    "    \"\"\"\n",
    "    if method=='leiden':\n",
    "        res, y_pred, n_clusters, cluster_centers=auto_leiden(encoder=model, x_counts=X, y=y, res=res, plot=plot)\n",
    "        return res, y_pred, n_clusters, cluster_centers\n",
    "    elif method=='kmeans':\n",
    "        y_pred, n_clusters, cluster_centers=auto_kmeans(encoder=model, x_counts=X, obs=y,n=n,  plot=plot)\n",
    "        return res, y_pred, n_clusters, cluster_centers\n",
    "    else:\n",
    "        raise ValueError(f'Unknown method : {method}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d68133a2-7d95-42c7-94c9-00b61d3e7f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy. Require scikit-learn installed\n",
    "    # Arguments\n",
    "        y: true labels, numpy.array with shape `(n_samples,)`\n",
    "        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
    "    # Return\n",
    "        accuracy, in [0,1]\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "   \n",
    "    y_pred = np.asarray(y_pred)\n",
    "    \n",
    "    #Make sure it's an array of str\n",
    "    y_true= y_true.astype(str)\n",
    "    y_pred = y_pred.astype(str)\n",
    "    \n",
    "    # find unique labels\n",
    "    labels = np.unique(np.concatenate((y_true, y_pred)))\n",
    "    n_labels = len(labels)\n",
    "\n",
    "    # Build the confusion matrix (cost matrix)\n",
    "    cost_matrix = np.zeros((n_labels, n_labels), dtype=int)\n",
    "    for i, label_true in enumerate(labels):\n",
    "        for j, label_pred in enumerate(labels):\n",
    "            cost_matrix[i, j] = np.sum((y_true == label_true) & (y_pred == label_pred))\n",
    "\n",
    "    #solve the optimal bipartite correspondance problem\n",
    "    row_ind, col_ind = linear_assignment(cost_matrix.max() - cost_matrix)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    accuracy = np.sum([cost_matrix[i, j] for i, j in zip(row_ind, col_ind)]) / y_true.size\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33279965-f488-455d-abe5-a03c6d37d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "ef save_results_to_csv(history, filename):\n",
    "        \"\"\"\n",
    "    Save results in a CSV file\n",
    "    \n",
    "    Inputs :\n",
    "        history (dictionary): data to be saved in a csv file\n",
    "        filename (str): file path to the csv file\n",
    "    \"\"\"\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    with open(filename, mode='a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            writer.writerow(history.keys())\n",
    "        writer.writerow(history.values())\n",
    "        \n",
    "def check_existing_filename(filename):\n",
    "    \"\"\"\n",
    "    Check if the file corresponding to the file name already exists,\n",
    "    if so change the filename\n",
    "    \n",
    "    input : \n",
    "        filename (str) : file path \n",
    "        \n",
    "    Output :\n",
    "        filename (str) : final filename\n",
    "    \"\"\"\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    counter = 1\n",
    "    while os.path.exists(filename):\n",
    "        filename = f\"{base}_{counter}{ext}\"\n",
    "        counter += 1\n",
    "    return filename\n",
    "\n",
    "def save_plot_umap(model, x, y, y_pred, res, epoch, pdf_pages, train_val=\"train\"):\n",
    "    \"\"\"\n",
    "    Save UMAP plot of true labels and predicted labels on the same page of a PDF file\n",
    "    \n",
    "    Inputs :\n",
    "        model : the encoder model\n",
    "        x : the input count matrix of the model\n",
    "        y : the true labels\n",
    "        y_pred : the predicted labels\n",
    "        res (float): the leiden resolution\n",
    "        epoch (int): the number of epoch of the model has been trained\n",
    "        pdf_pages (str): the PDF file path\n",
    "        train_test (str) : type of data used for the plot (train, val or test)\n",
    "    \"\"\"\n",
    "    #Data retrieval and projection into latent space   \n",
    "    predict_data=model.predict(x, verbose=0)\n",
    "    obs_df = pd.DataFrame({'label': y})\n",
    "    \n",
    "    #Preparing data for Scanpy\n",
    "    adata_latent = sc.AnnData(X=predict_data)\n",
    "    adata_latent.obs = obs_df\n",
    "    adata_latent.obs['predict'] = y_pred.astype(str)\n",
    "\n",
    "    sc.pp.neighbors(adata_latent, use_rep='X')\n",
    "    sc.tl.umap(adata_latent)\n",
    "    \n",
    "    # UMAP generation with Scanpy\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    sc.pl.umap(adata_latent, color='label', ax=axs[0], show=False)\n",
    "    axs[0].set_title(f'UMAP projection - Labels ({train_val}) (Res: {res}, Iter: {epoch})')\n",
    "    sc.pl.umap(adata_latent, color='predict', ax=axs[1], show=False)\n",
    "    axs[1].set_title(f'UMAP projection - Predictions ({train_val}) (Res: {res}, Iter: {epoch})')\n",
    "\n",
    "    #save in the pdf\n",
    "    pdf_pages.savefig(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9bb7c64-9b41-4c10-a92e-73854ffefea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_hyperparameters(lr_space, dropout_space, batch_size_space):\n",
    "    \"\"\"\n",
    "    Sample a set of hyperparameters \n",
    "    \n",
    "    Inputs :\n",
    "        lr_space (list of float) : learning rate space of sample\n",
    "        dropout_space (list of float from 0 to 1) : dropout rate space to sample\n",
    "        batch_size_space (list of int) : batch size space to sample\n",
    "        \n",
    "    Outputs :\n",
    "        lr (float) : the randomly selected learning rate value\n",
    "        dropout (float from 0 to 1) : the randomly selected dropout rate value\n",
    "        batch_size (int) : the randomly selected batch size\n",
    "    \"\"\"\n",
    "    lr=random.choice(lr_space)\n",
    "    dropout=random.choice(dropout_space)\n",
    "    batch_size=random.choice(batch_size_space)\n",
    "    return lr, dropout, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6f8149b-54ba-467e-9830-c41dc6fa4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_scheduler(epoch, lr, epochs=500, lr_decay_rate=0.1):\n",
    "    \"\"\"\n",
    "    Compute the learning rate according to a cosine scheduler\n",
    "    \n",
    "    Inputs :\n",
    "        epoch (int) : the epoch the model has currently been trained \n",
    "        lr (float) : the current learning rate\n",
    "        epochs (int) : the total number of epochs\n",
    "        lr_decay_rate (float) :  the decay rate of the learning rate\n",
    "    \n",
    "    Output :\n",
    "        new_lr (float) : the new learning rate\n",
    "    \"\"\"\n",
    "    eta_min = lr * (lr_decay_rate ** 3)\n",
    "    new_lr = eta_min + (lr - eta_min) * (1 + math.cos(math.pi * epoch / epochs)) / 2\n",
    "    return new_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd57ecc-85ff-48b6-ba26-def224a97243",
   "metadata": {},
   "source": [
    "## The main train function for Contrastive-sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "599b945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, Y=None, n='auto', res='auto', nb_epochs=30, lr=0.4, \n",
    "                temperature=0.07, dropout=0.9, evaluate_training=False, eval_interval=1, \n",
    "                layers=[256, 64, 32], noise=0, method='leiden', batch_size=200, \n",
    "               X_test=None, Y_test=None, early_stopping=True, plot_loss=False, \n",
    "                csv_path=\"data/contrastive-sc/PBMC_repro/contrastive_sc_pbmc\"):\n",
    "    \"\"\"\n",
    "    Main function for Contrastive-sc\n",
    "    \n",
    "    Inputs :\n",
    "        X = input count matrix train\n",
    "        Y = true labels train\n",
    "        n = number of clusters for Kmeans\n",
    "        res = resolution for Leiden\n",
    "        nb_epochs (int) = number of epochs\n",
    "        lr (float) = inital learning rate\n",
    "        temperature (float) = the temperature parameter for the contrastive loss\n",
    "        dropout (float) = dropout rate\n",
    "        evaluate_training (bool) = if yes compute metrics\n",
    "        eval_interval (int) = the interval at which the evalutation must be done\n",
    "        layers (list of int) = size of the encoder layers\n",
    "        noise (float from 0 to 1) = standard deviation of the gaussian noise\n",
    "        method : method of clustering (leiden of kmeans)\n",
    "        batch_size (int) = batch size\n",
    "        X_test = input count matrix test\n",
    "        Y_test = true labels test\n",
    "        early_stopping (bool) = if yes set up an early stopping\n",
    "        plot_loss (bool) = if yes plot the loss value according to the number of epochs\n",
    "        csv_path (str) = the csv path where the results will be saved\n",
    "        \n",
    "    Outputs :\n",
    "        model = the trained model\n",
    "        result = the clustering result\n",
    "    \"\"\"\n",
    "    # Define the dimensions of the model layers\n",
    "    dims = [X.shape[1]]+layers\n",
    "    \n",
    "    # Create the model\n",
    "    model= create_contrastive_encoder(input_dim=X.shape[1], dims=layers, dropout=dropout)\n",
    "    model.summary()\n",
    "    \n",
    "    # Define the optimizer\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    \n",
    "    # Initialize list for storing loss values\n",
    "    losses=[]\n",
    "    \n",
    "    # Create indices for shuffling the data\n",
    "    idx=np.arange(len(X))\n",
    "    \n",
    "    # Create a dictionary for monitoring training\n",
    "    history={\n",
    "        \"dropout\": dropout,\n",
    "        \"noise\": noise, \n",
    "        \"lr\": lr,\n",
    "        \"method\": method,\n",
    "        'batch_size' : batch_size,\n",
    "        'temperature' : temperature, \n",
    "        \"loss\":[],\n",
    "        \"val_loss\":[]\n",
    "    }\n",
    "\n",
    "    \n",
    "    for epoch in range (nb_epochs):\n",
    "        # Update the learning rate using a cosine scheduler\n",
    "        lr = cosine_scheduler(epoch, lr, epochs=nb_epochs, lr_decay_rate=0.1)\n",
    "        optimizer.learning_rate.assign(lr)\n",
    "        # Shuffle the  indices\n",
    "        np.random.shuffle(idx)\n",
    "        loss_=0\n",
    "\n",
    "        # Iterate over the batches\n",
    "        for pre_index in range (len(X)//batch_size+1):\n",
    "            c_idx=np.arange(pre_index*batch_size, min(len(X), (pre_index+1)*batch_size))\n",
    "            if len(c_idx)==0:\n",
    "                continue\n",
    "            c_idx=idx[c_idx]\n",
    "            c_inp=X[c_idx]\n",
    "            # Generate input pairs with or without noise\n",
    "            if noise is None or noise == 0 :\n",
    "                input1=tf.convert_to_tensor(c_inp, dtype=tf.float32)\n",
    "                input2=tf.convert_to_tensor(c_inp, dtype=tf.float32)\n",
    "            else : \n",
    "                noise_vec = np.random.normal(loc=0, scale=noise, size=c_inp.shape)\n",
    "                input1 = tf.convert_to_tensor(c_inp + noise_vec, dtype=tf.float32)\n",
    "                noise_vec = np.random.normal(loc=0, scale=noise, size=c_inp.shape)\n",
    "                input2 = tf.convert_to_tensor(c_inp + noise_vec, dtype=tf.float32)\n",
    "            # Compute the loss and gradients\n",
    "            with tf.GradientTape() as tape :\n",
    "                anchors_output=model(input1,  training=True)\n",
    "                neighbors_output=model(input2,  training=True)\n",
    "                features = tf.stack([anchors_output, neighbors_output], axis=1)\n",
    "                total_loss= SupConLoss(features=features, temperature=temperature)\n",
    "                loss_+=total_loss.numpy()\n",
    "            \n",
    "            gradients = tape.gradient(total_loss, model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        \n",
    "        print(f\"{epoch}). Loss : {loss_}\")\n",
    "        losses.append(loss_)\n",
    "        \n",
    "        # Implement early stopping\n",
    "        if early_stopping and X_test is not None:\n",
    "            indice_max=val_losses.index(min(val_losses))\n",
    "            if abs(indice_max-len(val_losses)-1)>5:\n",
    "                break\n",
    "                \n",
    "    # Plot the loss curves if required        \n",
    "    if plot_loss:\n",
    "        x=[i for i in range (len(losses))]\n",
    "        plt.plot(x, losses)\n",
    "        plt.legend(labels=['loss'])\n",
    "        plt.plot()\n",
    "    \n",
    "    # Evaluate training performance if required\n",
    "    if evaluate_training and Y is not None :\n",
    "        #result = model.predict(X)\n",
    "        res, result, n_cluster, cluster_centers =cluster_embedding(model, X, Y, method=method, res=res, n=n, plot=False)\n",
    "        ca=np.round(cluster_acc(Y, result), 5)\n",
    "        nmi=np.round(normalized_mutual_info_score(Y, result), 5)\n",
    "        ari=np.round(adjusted_rand_score(Y, result), 5)\n",
    "        print( f\"ARI {ari}, NMI: {nmi}, CA : {ca}, clusters : {n_cluster}\")\n",
    "        history[\"res\"]=res\n",
    "        history[\"clusters\"]=n_cluster\n",
    "        history['NMI final']=nmi\n",
    "        history['ARI final']=ari\n",
    "        history['CA final']=ca\n",
    "    \n",
    "    # Save training history\n",
    "    history[\"loss\"]=losses\n",
    "    history['final_loss']=loss_\n",
    "\n",
    "        \n",
    "    # Save results to CSV\n",
    "    save_results_to_csv(history, csv_path + \".csv\")\n",
    "\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037a76d8-b42f-4f3e-8bd7-45bdba41aed7",
   "metadata": {},
   "source": [
    "Train the model on all the dataset (no split) either using Leiden (res=1) or Kmeans (n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "335e23cb-61f6-4f46-a334-5aa64514f00b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,460</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m100,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │           \u001b[38;5;34m800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m8,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m2,460\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_7 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,660</span> (436.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,660\u001b[0m (436.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,180</span> (434.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,180\u001b[0m (434.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m480\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 131.80688667297363\n",
      "1). Loss : 125.56054019927979\n",
      "2). Loss : 120.59931993484497\n",
      "3). Loss : 118.22778511047363\n",
      "4). Loss : 115.81950092315674\n",
      "5). Loss : 114.28992938995361\n",
      "6). Loss : 113.91922283172607\n",
      "7). Loss : 112.69853830337524\n",
      "8). Loss : 112.62277126312256\n",
      "9). Loss : 112.4144697189331\n",
      "10). Loss : 111.64666843414307\n",
      "11). Loss : 111.48147392272949\n",
      "12). Loss : 111.7500524520874\n",
      "13). Loss : 111.2247405052185\n",
      "14). Loss : 111.35542488098145\n",
      "15). Loss : 111.82925605773926\n",
      "16). Loss : 111.5056414604187\n",
      "17). Loss : 111.62239599227905\n",
      "18). Loss : 111.15428400039673\n",
      "19). Loss : 111.50354194641113\n",
      "20). Loss : 111.17766380310059\n",
      "21). Loss : 111.22843551635742\n",
      "22). Loss : 111.1158595085144\n",
      "23). Loss : 111.20309495925903\n",
      "24). Loss : 111.85796475410461\n",
      "25). Loss : 111.37042713165283\n",
      "26). Loss : 111.63532304763794\n",
      "27). Loss : 111.76938676834106\n",
      "28). Loss : 111.61803245544434\n",
      "29). Loss : 111.13756513595581\n",
      "ARI 0.54419, NMI: 0.67375, CA : 0.60852, clusters : 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,460</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m100,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │           \u001b[38;5;34m800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m8,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m2,460\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_8 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,660</span> (436.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,660\u001b[0m (436.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,180</span> (434.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,180\u001b[0m (434.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m480\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 130.32004070281982\n",
      "1). Loss : 122.86363983154297\n",
      "2). Loss : 119.3888578414917\n",
      "3). Loss : 115.55173921585083\n",
      "4). Loss : 113.95687246322632\n",
      "5). Loss : 113.77497482299805\n",
      "6). Loss : 113.32846593856812\n",
      "7). Loss : 112.6471381187439\n",
      "8). Loss : 112.78334665298462\n",
      "9). Loss : 112.70308923721313\n",
      "10). Loss : 111.32541227340698\n",
      "11). Loss : 112.13372707366943\n",
      "12). Loss : 111.56396293640137\n",
      "13). Loss : 111.60115385055542\n",
      "14). Loss : 111.5280818939209\n",
      "15). Loss : 111.22930479049683\n",
      "16). Loss : 111.18221521377563\n",
      "17). Loss : 111.35911321640015\n",
      "18). Loss : 111.55382919311523\n",
      "19). Loss : 111.55820751190186\n",
      "20). Loss : 111.39952373504639\n",
      "21). Loss : 111.29964637756348\n",
      "22). Loss : 111.2352614402771\n",
      "23). Loss : 110.97267436981201\n",
      "24). Loss : 110.17980551719666\n",
      "25). Loss : 111.25627183914185\n",
      "26). Loss : 111.43940496444702\n",
      "27). Loss : 111.01596593856812\n",
      "28). Loss : 111.17746686935425\n",
      "29). Loss : 111.33523607254028\n",
      "ARI 0.56812, NMI: 0.69617, CA : 0.67759, clusters : 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,460</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m100,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │           \u001b[38;5;34m800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m8,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m2,460\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_9 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,660</span> (436.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,660\u001b[0m (436.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,180</span> (434.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,180\u001b[0m (434.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m480\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 131.66999530792236\n",
      "1). Loss : 126.73233032226562\n",
      "2). Loss : 119.68342113494873\n",
      "3). Loss : 116.59878253936768\n",
      "4). Loss : 115.06437683105469\n",
      "5). Loss : 113.53848028182983\n",
      "6). Loss : 113.76968479156494\n",
      "7). Loss : 112.65793037414551\n",
      "8). Loss : 112.4666018486023\n",
      "9). Loss : 112.54654693603516\n",
      "10). Loss : 111.78485488891602\n",
      "11). Loss : 111.50783061981201\n",
      "12). Loss : 111.58683800697327\n",
      "13). Loss : 111.16507458686829\n",
      "14). Loss : 111.43208169937134\n",
      "15). Loss : 111.64905834197998\n",
      "16). Loss : 111.27359104156494\n",
      "17). Loss : 110.93735718727112\n",
      "18). Loss : 110.79636287689209\n",
      "19). Loss : 110.76952886581421\n",
      "20). Loss : 111.57131171226501\n",
      "21). Loss : 111.4480652809143\n",
      "22). Loss : 110.77863788604736\n",
      "23). Loss : 111.24753093719482\n",
      "24). Loss : 110.58900618553162\n",
      "25). Loss : 111.0737829208374\n",
      "26). Loss : 111.05357646942139\n",
      "27). Loss : 111.02358102798462\n",
      "28). Loss : 110.5373477935791\n",
      "29). Loss : 111.85001420974731\n",
      "ARI 0.54152, NMI: 0.69078, CA : 0.63358, clusters : 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,460</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m100,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │           \u001b[38;5;34m800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_18 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m8,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_19 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m2,460\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_10 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,660</span> (436.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,660\u001b[0m (436.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,180</span> (434.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,180\u001b[0m (434.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m480\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 131.54553127288818\n",
      "1). Loss : 123.77933073043823\n",
      "2). Loss : 119.33284139633179\n",
      "3). Loss : 117.12029027938843\n",
      "4). Loss : 114.6766996383667\n",
      "5). Loss : 113.77717781066895\n",
      "6). Loss : 113.61538553237915\n",
      "7). Loss : 112.93340539932251\n",
      "8). Loss : 112.79694318771362\n",
      "9). Loss : 112.35099458694458\n",
      "10). Loss : 112.95951509475708\n",
      "11). Loss : 112.11354160308838\n",
      "12). Loss : 111.76774454116821\n",
      "13). Loss : 111.1720654964447\n",
      "14). Loss : 111.49998044967651\n",
      "15). Loss : 111.99318647384644\n",
      "16). Loss : 111.1083014011383\n",
      "17). Loss : 111.4261064529419\n",
      "18). Loss : 111.48151779174805\n",
      "19). Loss : 111.83526611328125\n",
      "20). Loss : 111.50844717025757\n",
      "21). Loss : 111.49766373634338\n",
      "22). Loss : 111.60259962081909\n",
      "23). Loss : 111.67214965820312\n",
      "24). Loss : 111.65877056121826\n",
      "25). Loss : 111.49891567230225\n",
      "26). Loss : 110.8655481338501\n",
      "27). Loss : 111.3561840057373\n",
      "28). Loss : 111.49166989326477\n",
      "29). Loss : 111.94758033752441\n",
      "ARI 0.56834, NMI: 0.68931, CA : 0.65137, clusters : 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,460</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m100,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │           \u001b[38;5;34m800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_20 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m8,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_21 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m2,460\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_11 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,660</span> (436.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,660\u001b[0m (436.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,180</span> (434.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,180\u001b[0m (434.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m480\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 131.8519139289856\n",
      "1). Loss : 127.26053524017334\n",
      "2). Loss : 122.51389169692993\n",
      "3). Loss : 118.55234146118164\n",
      "4). Loss : 115.47662115097046\n",
      "5). Loss : 114.56411552429199\n",
      "6). Loss : 112.8663821220398\n",
      "7). Loss : 113.27617025375366\n",
      "8). Loss : 112.78149628639221\n",
      "9). Loss : 112.44056701660156\n",
      "10). Loss : 112.55565214157104\n",
      "11). Loss : 112.07487773895264\n",
      "12). Loss : 111.21933507919312\n",
      "13). Loss : 111.72079944610596\n",
      "14). Loss : 111.4745864868164\n",
      "15). Loss : 111.82996940612793\n",
      "16). Loss : 111.36047005653381\n",
      "17). Loss : 111.37115001678467\n",
      "18). Loss : 111.6465950012207\n",
      "19). Loss : 111.01426815986633\n",
      "20). Loss : 111.4956283569336\n",
      "21). Loss : 111.28837275505066\n",
      "22). Loss : 111.59242486953735\n",
      "23). Loss : 111.65384817123413\n",
      "24). Loss : 111.35385179519653\n",
      "25). Loss : 111.60772705078125\n",
      "26). Loss : 111.48922348022461\n",
      "27). Loss : 111.15312385559082\n",
      "28). Loss : 111.50477647781372\n",
      "29). Loss : 111.59353613853455\n",
      "ARI 0.54744, NMI: 0.6722, CA : 0.64786, clusters : 11\n"
     ]
    }
   ],
   "source": [
    "for i in range (5):\n",
    "    model, results=train_model(count_data_hvg, Y=data_ann.obs[\"label\"], n='auto', res=1.0, nb_epochs=30, lr=0.4, \n",
    "                temperature=0.07, dropout=0.9, evaluate_training=True, eval_interval=1, \n",
    "                layers=[200,40,60], noise=0, method='leiden', batch_size=200, \n",
    "                early_stopping=False, plot_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eec2af4e-6cd0-4a5d-a89f-a59f29f1da1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_23\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_23\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,460</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m100,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │           \u001b[38;5;34m800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_22 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m8,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_23 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m2,460\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_12 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,660</span> (436.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,660\u001b[0m (436.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,180</span> (434.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,180\u001b[0m (434.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m480\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 129.61850786209106\n",
      "1). Loss : 121.77791976928711\n",
      "2). Loss : 116.73139333724976\n",
      "3). Loss : 114.4088544845581\n",
      "4). Loss : 113.68604326248169\n",
      "5). Loss : 113.61827039718628\n",
      "6). Loss : 113.12961483001709\n",
      "7). Loss : 112.85258603096008\n",
      "8). Loss : 112.6901159286499\n",
      "9). Loss : 112.23585033416748\n",
      "10). Loss : 111.76159191131592\n",
      "11). Loss : 111.6672797203064\n",
      "12). Loss : 111.59693908691406\n",
      "13). Loss : 110.60819625854492\n",
      "14). Loss : 111.03762578964233\n",
      "15). Loss : 110.89816570281982\n",
      "16). Loss : 111.45511436462402\n",
      "17). Loss : 110.80472350120544\n",
      "18). Loss : 111.05507469177246\n",
      "19). Loss : 111.44829320907593\n",
      "20). Loss : 110.6939206123352\n",
      "21). Loss : 110.9842677116394\n",
      "22). Loss : 111.05669593811035\n",
      "23). Loss : 110.83582782745361\n",
      "24). Loss : 111.64532136917114\n",
      "25). Loss : 111.38437509536743\n",
      "26). Loss : 111.46942472457886\n",
      "27). Loss : 110.65613174438477\n",
      "28). Loss : 111.19760751724243\n",
      "29). Loss : 111.02070045471191\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "ARI 0.69906, NMI: 0.71618, CA : 0.75228, clusters : 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_25\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_25\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_24          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_25          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,460</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m100,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_24          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │           \u001b[38;5;34m800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_24 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m8,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_25          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_25 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m2,460\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_13 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,660</span> (436.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,660\u001b[0m (436.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,180</span> (434.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,180\u001b[0m (434.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m480\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 131.19783449172974\n",
      "1). Loss : 124.84294891357422\n",
      "2). Loss : 119.01232528686523\n",
      "3). Loss : 115.66089200973511\n",
      "4). Loss : 114.05675172805786\n",
      "5). Loss : 113.88150548934937\n",
      "6). Loss : 113.19038915634155\n",
      "7). Loss : 112.72029876708984\n",
      "8). Loss : 112.00840044021606\n",
      "9). Loss : 111.76764059066772\n",
      "10). Loss : 112.59102249145508\n",
      "11). Loss : 111.47150897979736\n",
      "12). Loss : 111.3482756614685\n",
      "13). Loss : 111.47231149673462\n",
      "14). Loss : 111.03197860717773\n",
      "15). Loss : 111.6594729423523\n",
      "16). Loss : 110.96061658859253\n",
      "17). Loss : 111.18564987182617\n",
      "18). Loss : 111.08984565734863\n",
      "19). Loss : 110.8391215801239\n",
      "20). Loss : 111.07522678375244\n",
      "21). Loss : 111.13303565979004\n",
      "22). Loss : 111.66534996032715\n",
      "23). Loss : 111.6787371635437\n",
      "24). Loss : 111.2065200805664\n",
      "25). Loss : 110.88129234313965\n",
      "26). Loss : 111.60753440856934\n",
      "27). Loss : 110.40116930007935\n",
      "28). Loss : 111.11423778533936\n",
      "29). Loss : 110.80885672569275\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "ARI 0.67755, NMI: 0.7269, CA : 0.73706, clusters : 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_27\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_27\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_26          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_27          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,460</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m100,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_26          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │           \u001b[38;5;34m800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_26 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m8,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_27          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_27 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m2,460\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_14 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,660</span> (436.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,660\u001b[0m (436.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,180</span> (434.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,180\u001b[0m (434.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m480\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 129.73368167877197\n",
      "1). Loss : 122.04626417160034\n",
      "2). Loss : 118.55830192565918\n",
      "3). Loss : 116.20248031616211\n",
      "4). Loss : 115.07745599746704\n",
      "5). Loss : 113.91049337387085\n",
      "6). Loss : 113.58634662628174\n",
      "7). Loss : 112.8102536201477\n",
      "8). Loss : 112.42734050750732\n",
      "9). Loss : 112.36638164520264\n",
      "10). Loss : 112.08237600326538\n",
      "11). Loss : 111.45223116874695\n",
      "12). Loss : 111.61065530776978\n",
      "13). Loss : 112.50010013580322\n",
      "14). Loss : 111.5877833366394\n",
      "15). Loss : 111.60232734680176\n",
      "16). Loss : 111.60289669036865\n",
      "17). Loss : 111.54700517654419\n",
      "18). Loss : 111.88221597671509\n",
      "19). Loss : 111.08807325363159\n",
      "20). Loss : 111.43112373352051\n",
      "21). Loss : 111.03463506698608\n",
      "22). Loss : 111.03744292259216\n",
      "23). Loss : 111.74747800827026\n",
      "24). Loss : 111.42534160614014\n",
      "25). Loss : 111.2845196723938\n",
      "26). Loss : 111.5337085723877\n",
      "27). Loss : 111.4546217918396\n",
      "28). Loss : 111.56886196136475\n",
      "29). Loss : 111.23215913772583\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "ARI 0.62899, NMI: 0.71092, CA : 0.71833, clusters : 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_29\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_29\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_28          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_29          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,460</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m100,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_28          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │           \u001b[38;5;34m800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_28 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m8,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_29          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_29 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m2,460\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_15 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,660</span> (436.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,660\u001b[0m (436.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,180</span> (434.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,180\u001b[0m (434.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m480\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 131.2964425086975\n",
      "1). Loss : 124.76621770858765\n",
      "2). Loss : 118.22173976898193\n",
      "3). Loss : 116.06132364273071\n",
      "4). Loss : 114.58846759796143\n",
      "5). Loss : 114.2431993484497\n",
      "6). Loss : 113.413987159729\n",
      "7). Loss : 112.80597519874573\n",
      "8). Loss : 112.92663025856018\n",
      "9). Loss : 112.40576696395874\n",
      "10). Loss : 112.02891826629639\n",
      "11). Loss : 111.3075704574585\n",
      "12). Loss : 111.84062433242798\n",
      "13). Loss : 111.8610360622406\n",
      "14). Loss : 111.11339259147644\n",
      "15). Loss : 111.45506572723389\n",
      "16). Loss : 110.8871693611145\n",
      "17). Loss : 111.36991596221924\n",
      "18). Loss : 111.54081344604492\n",
      "19). Loss : 112.02962589263916\n",
      "20). Loss : 111.36458730697632\n",
      "21). Loss : 111.49918413162231\n",
      "22). Loss : 110.71895837783813\n",
      "23). Loss : 111.01022481918335\n",
      "24). Loss : 111.49662399291992\n",
      "25). Loss : 111.42662048339844\n",
      "26). Loss : 111.47281265258789\n",
      "27). Loss : 111.32930040359497\n",
      "28). Loss : 111.44140148162842\n",
      "29). Loss : 111.06527185440063\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "ARI 0.70716, NMI: 0.72965, CA : 0.78202, clusters : 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_31\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_31\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_30          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_31          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,460</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_15 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m100,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_30          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │           \u001b[38;5;34m800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_30 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m8,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_31          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_31 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m2,460\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_16 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,660</span> (436.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,660\u001b[0m (436.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,180</span> (434.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,180\u001b[0m (434.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m480\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0). Loss : 128.91132497787476\n",
      "1). Loss : 122.165198802948\n",
      "2). Loss : 119.84671068191528\n",
      "3). Loss : 116.21960592269897\n",
      "4). Loss : 114.1482949256897\n",
      "5). Loss : 113.82776212692261\n",
      "6). Loss : 112.87688255310059\n",
      "7). Loss : 112.16433119773865\n",
      "8). Loss : 112.84009885787964\n",
      "9). Loss : 112.3051872253418\n",
      "10). Loss : 111.51995801925659\n",
      "11). Loss : 111.97385883331299\n",
      "12). Loss : 111.52078771591187\n",
      "13). Loss : 111.65074586868286\n",
      "14). Loss : 111.56772422790527\n",
      "15). Loss : 111.11288499832153\n",
      "16). Loss : 111.47987174987793\n",
      "17). Loss : 110.95339488983154\n",
      "18). Loss : 111.36247777938843\n",
      "19). Loss : 111.16701889038086\n",
      "20). Loss : 111.45956802368164\n",
      "21). Loss : 111.35295248031616\n",
      "22). Loss : 110.89030766487122\n",
      "23). Loss : 111.07798337936401\n",
      "24). Loss : 111.54980230331421\n",
      "25). Loss : 111.45112895965576\n",
      "26). Loss : 111.86429691314697\n",
      "27). Loss : 110.96398782730103\n",
      "28). Loss : 111.3997631072998\n",
      "29). Loss : 111.52556896209717\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "ARI 0.62251, NMI: 0.70826, CA : 0.71693, clusters : 8\n"
     ]
    }
   ],
   "source": [
    "for i in range (5):\n",
    "    model, results=train_model(count_data_hvg, Y=data_ann.obs[\"label\"], n=8, res=\"auto\", nb_epochs=30, lr=0.4, \n",
    "                temperature=0.07, dropout=0.9, evaluate_training=True, eval_interval=1, \n",
    "                layers=[200,40,60], noise=0, method='kmeans', batch_size=200, \n",
    "                early_stopping=False, plot_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4156f7b9-1da9-4166-a1a0-d9f5ab44af92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_scivar",
   "language": "python",
   "name": "env_scivar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
